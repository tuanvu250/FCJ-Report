<!DOCTYPE html>
<html lang="en" class="js csstransforms3d">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="generator" content="Hugo 0.150.0">
    <meta
  name="description"
  content=""
/>
<meta name="author" content="thienlh@thienlu.com" />

    <link rel="icon" href="../../images/favicon.png" type="image/png">

    <title>Blog 1 :: Internship Report</title>

    
    <link href="../../css/nucleus.css?1765049781" rel="stylesheet">
    <link href="../../css/fontawesome-all.min.css?1765049781" rel="stylesheet">
    <link href="../../css/hybrid.css?1765049781" rel="stylesheet">
    <link href="../../css/featherlight.min.css?1765049781" rel="stylesheet">
    <link href="../../css/perfect-scrollbar.min.css?1765049781" rel="stylesheet">
    <link href="../../css/auto-complete.css?1765049781" rel="stylesheet">
    <link href="../../css/atom-one-dark-reasonable.css?1765049781" rel="stylesheet">
    <link href="../../css/theme.css?1765049781" rel="stylesheet">
    <link href="../../css/hugo-theme.css?1765049781" rel="stylesheet">
    
    <link href="../../css/theme-workshop.css?1765049781" rel="stylesheet">
    
    

    <script src="../../js/jquery-3.3.1.min.js?1765049781"></script>

    <style>
      :root #header + #content > #left > #rlblock_left{
          display:none !important;
      }
      
    </style>
    

  </head>
  <body class="" data-url="../../3-blogstranslated/3.1-blog1/">
    <nav
  id="sidebar"
  class="showVisitedLinks"
>
   
  <div id="header-wrapper">
    <div id="header"><a id="logo" href="../../">
  <svg
    id="Layer_1"
    data-name="Layer 1"
    xmlns="http://www.w3.org/2000/svg"
    viewBox="0 0 60 30"
    width="30%"
  >
    <defs>
      <style>
        .cls-1 {
          fill: #fff;
        }
        .cls-2 {
          fill: #f90;
          fill-rule: evenodd;
        }
      </style>
    </defs>
    <title>AWS-Logo_White-Color</title>
    <path
      class="cls-1"
      d="M14.09,10.85a4.7,4.7,0,0,0,.19,1.48,7.73,7.73,0,0,0,.54,1.19.77.77,0,0,1,.12.38.64.64,0,0,1-.32.49l-1,.7a.83.83,0,0,1-.44.15.69.69,0,0,1-.49-.23,3.8,3.8,0,0,1-.6-.77q-.25-.42-.51-1a6.14,6.14,0,0,1-4.89,2.3,4.54,4.54,0,0,1-3.32-1.19,4.27,4.27,0,0,1-1.22-3.2A4.28,4.28,0,0,1,3.61,7.75,6.06,6.06,0,0,1,7.69,6.46a12.47,12.47,0,0,1,1.76.13q.92.13,1.91.36V5.73a3.65,3.65,0,0,0-.79-2.66A3.81,3.81,0,0,0,7.86,2.3a7.71,7.71,0,0,0-1.79.22,12.78,12.78,0,0,0-1.79.57,4.55,4.55,0,0,1-.58.22l-.26,0q-.35,0-.35-.52V2a1.09,1.09,0,0,1,.12-.58,1.2,1.2,0,0,1,.47-.35A10.88,10.88,0,0,1,5.77.32,10.19,10.19,0,0,1,8.36,0a6,6,0,0,1,4.35,1.35,5.49,5.49,0,0,1,1.38,4.09ZM7.34,13.38a5.36,5.36,0,0,0,1.72-.31A3.63,3.63,0,0,0,10.63,12,2.62,2.62,0,0,0,11.19,11a5.63,5.63,0,0,0,.16-1.44v-.7a14.35,14.35,0,0,0-1.53-.28,12.37,12.37,0,0,0-1.56-.1,3.84,3.84,0,0,0-2.47.67A2.34,2.34,0,0,0,5,11a2.35,2.35,0,0,0,.61,1.76A2.4,2.4,0,0,0,7.34,13.38Zm13.35,1.8a1,1,0,0,1-.64-.16,1.3,1.3,0,0,1-.35-.65L15.81,1.51a3,3,0,0,1-.15-.67.36.36,0,0,1,.41-.41H17.7a1,1,0,0,1,.65.16,1.4,1.4,0,0,1,.33.65l2.79,11,2.59-11A1.17,1.17,0,0,1,24.39.6a1.1,1.1,0,0,1,.67-.16H26.4a1.1,1.1,0,0,1,.67.16,1.17,1.17,0,0,1,.32.65L30,12.39,32.88,1.25A1.39,1.39,0,0,1,33.22.6a1,1,0,0,1,.65-.16h1.54a.36.36,0,0,1,.41.41,1.36,1.36,0,0,1,0,.26,3.64,3.64,0,0,1-.12.41l-4,12.86a1.3,1.3,0,0,1-.35.65,1,1,0,0,1-.64.16H29.25a1,1,0,0,1-.67-.17,1.26,1.26,0,0,1-.32-.67L25.67,3.64,23.11,14.34a1.26,1.26,0,0,1-.32.67,1,1,0,0,1-.67.17Zm21.36.44a11.28,11.28,0,0,1-2.56-.29,7.44,7.44,0,0,1-1.92-.67,1,1,0,0,1-.61-.93v-.84q0-.52.38-.52a.9.9,0,0,1,.31.06l.42.17a8.77,8.77,0,0,0,1.83.58,9.78,9.78,0,0,0,2,.2,4.48,4.48,0,0,0,2.43-.55,1.76,1.76,0,0,0,.86-1.57,1.61,1.61,0,0,0-.45-1.16A4.29,4.29,0,0,0,43,9.22l-2.41-.76A5.15,5.15,0,0,1,38,6.78a3.94,3.94,0,0,1-.83-2.41,3.7,3.7,0,0,1,.45-1.85,4.47,4.47,0,0,1,1.19-1.37A5.27,5.27,0,0,1,40.51.29,7.4,7.4,0,0,1,42.6,0a8.87,8.87,0,0,1,1.12.07q.57.07,1.08.19t.95.26a4.27,4.27,0,0,1,.7.29,1.59,1.59,0,0,1,.49.41.94.94,0,0,1,.15.55v.79q0,.52-.38.52a1.76,1.76,0,0,1-.64-.2,7.74,7.74,0,0,0-3.2-.64,4.37,4.37,0,0,0-2.21.47,1.6,1.6,0,0,0-.79,1.48,1.58,1.58,0,0,0,.49,1.18,4.94,4.94,0,0,0,1.83.92L44.55,7a5.08,5.08,0,0,1,2.57,1.6A3.76,3.76,0,0,1,47.9,11a4.21,4.21,0,0,1-.44,1.93,4.4,4.4,0,0,1-1.21,1.47,5.43,5.43,0,0,1-1.85.93A8.25,8.25,0,0,1,42.05,15.62Z"
    ></path>
    <path
      class="cls-2"
      d="M45.19,23.81C39.72,27.85,31.78,30,25,30A36.64,36.64,0,0,1,.22,20.57c-.51-.46-.06-1.09.56-.74A49.78,49.78,0,0,0,25.53,26.4,49.23,49.23,0,0,0,44.4,22.53C45.32,22.14,46.1,23.14,45.19,23.81Z"
    ></path>
    <path
      class="cls-2"
      d="M47.47,21.21c-.7-.9-4.63-.42-6.39-.21-.53.06-.62-.4-.14-.74,3.13-2.2,8.27-1.57,8.86-.83s-.16,5.89-3.09,8.35c-.45.38-.88.18-.68-.32C46.69,25.8,48.17,22.11,47.47,21.21Z"
    ></path>
  </svg>
</a>
</div>
     <div class="searchbox">
    <label for="search-by"><i class="fas fa-search"></i></label>
    <input data-search-input id="search-by" type="search" placeholder="Search...">
    <span data-search-clear=""><i class="fas fa-times"></i></span>
</div>

<script type="text/javascript" src="../../js/lunr.min.js?1765049781"></script>
<script type="text/javascript" src="../../js/auto-complete.js?1765049781"></script>
<script type="text/javascript">
    
        var baseurl = "https:\/\/tuanvu250.github.io\/FCJ-Report\/";
    
</script>
<script type="text/javascript" src="../../js/search.js?1765049781"></script>
 
  </div>

  <div class="highlightable">
    <ul class="topics">
               
<li
  data-nav-id="/1-worklog/"
  title="Worklog"
  class="dd-item 
        
        
        
        "
>
  <a href="../../1-worklog/">
     <b> 1. </b> Worklog 
    <i class="fas fa-check read-icon"></i>
    
  </a>
   
  <ul>
          
            
<li
  data-nav-id="/1-worklog/1.1-week1/"
  title="Week 1 Worklog"
  class="dd-item 
        
        
        
        "
>
  <a href="../../1-worklog/1.1-week1/">
     <b> 1.1. </b> Week 1 Worklog 
    <i class="fas fa-check read-icon"></i>
    
  </a>
   
</li>
    
            
<li
  data-nav-id="/1-worklog/1.2-week2/"
  title="Week 2 Worklog"
  class="dd-item 
        
        
        
        "
>
  <a href="../../1-worklog/1.2-week2/">
     <b> 1.2. </b> Week 2 Worklog 
    <i class="fas fa-check read-icon"></i>
    
  </a>
   
</li>
    
            
<li
  data-nav-id="/1-worklog/1.3-week3/"
  title="Week 3 Worklog"
  class="dd-item 
        
        
        
        "
>
  <a href="../../1-worklog/1.3-week3/">
     <b> 1.3. </b> Week 3 Worklog 
    <i class="fas fa-check read-icon"></i>
    
  </a>
   
</li>
    
            
<li
  data-nav-id="/1-worklog/1.4-week4/"
  title="Week 4 Worklog"
  class="dd-item 
        
        
        
        "
>
  <a href="../../1-worklog/1.4-week4/">
     <b> 1.4. </b> Week 4 Worklog 
    <i class="fas fa-check read-icon"></i>
    
  </a>
   
</li>
    
            
<li
  data-nav-id="/1-worklog/1.5-week5/"
  title="Week 5 Worklog"
  class="dd-item 
        
        
        
        "
>
  <a href="../../1-worklog/1.5-week5/">
     <b> 1.5. </b> Week 5 Worklog 
    <i class="fas fa-check read-icon"></i>
    
  </a>
   
</li>
    
            
<li
  data-nav-id="/1-worklog/1.6-week6/"
  title="Week 6 Worklog"
  class="dd-item 
        
        
        
        "
>
  <a href="../../1-worklog/1.6-week6/">
     <b> 1.6. </b> Week 6 Worklog 
    <i class="fas fa-check read-icon"></i>
    
  </a>
   
</li>
    
            
<li
  data-nav-id="/1-worklog/1.7-week7/"
  title="Week 7 Worklog"
  class="dd-item 
        
        
        
        "
>
  <a href="../../1-worklog/1.7-week7/">
     <b> 1.7. </b> Week 7 Worklog 
    <i class="fas fa-check read-icon"></i>
    
  </a>
   
</li>
    
            
<li
  data-nav-id="/1-worklog/1.8-week8/"
  title="Week 8 Worklog"
  class="dd-item 
        
        
        
        "
>
  <a href="../../1-worklog/1.8-week8/">
     <b> 1.8. </b> Week 8 Worklog 
    <i class="fas fa-check read-icon"></i>
    
  </a>
   
</li>
    
            
<li
  data-nav-id="/1-worklog/1.9-week9/"
  title="Week 9 Worklog"
  class="dd-item 
        
        
        
        "
>
  <a href="../../1-worklog/1.9-week9/">
     <b> 1.9. </b> Week 9 Worklog 
    <i class="fas fa-check read-icon"></i>
    
  </a>
   
</li>
    
            
<li
  data-nav-id="/1-worklog/1.10-week10/"
  title="Week 10 Worklog"
  class="dd-item 
        
        
        
        "
>
  <a href="../../1-worklog/1.10-week10/">
     <b> 1.10. </b> Week 10 Worklog 
    <i class="fas fa-check read-icon"></i>
    
  </a>
   
</li>
    
            
<li
  data-nav-id="/1-worklog/1.11-week11/"
  title="Week 11 Worklog"
  class="dd-item 
        
        
        
        "
>
  <a href="../../1-worklog/1.11-week11/">
     <b> 1.11. </b> Week 11 Worklog 
    <i class="fas fa-check read-icon"></i>
    
  </a>
   
</li>
    
            
<li
  data-nav-id="/1-worklog/1.12-week12/"
  title="Week 12 Worklog"
  class="dd-item 
        
        
        
        "
>
  <a href="../../1-worklog/1.12-week12/">
     <b> 1.12. </b> Week 12 Worklog 
    <i class="fas fa-check read-icon"></i>
    
  </a>
   
</li>
     
  </ul>
  
</li>
           
<li
  data-nav-id="/2-proposal/"
  title="Proposal"
  class="dd-item 
        
        
        
        "
>
  <a href="../../2-proposal/">
     <b> 2. </b> Proposal 
    <i class="fas fa-check read-icon"></i>
    
  </a>
   
</li>
           
<li
  data-nav-id="/3-blogstranslated/"
  title="Translated Blogs"
  class="dd-item 
        parent
        
        
        "
>
  <a href="../../3-blogstranslated/">
     <b> 3. </b> Translated Blogs 
    <i class="fas fa-check read-icon"></i>
    
  </a>
   
  <ul>
          
            
<li
  data-nav-id="/3-blogstranslated/3.1-blog1/"
  title="Blog 1"
  class="dd-item 
        
        active
        
        "
>
  <a href="../../3-blogstranslated/3.1-blog1/">
     <b> 3.1. </b> Blog 1 
    <i class="fas fa-check read-icon"></i>
    
  </a>
   
</li>
    
            
<li
  data-nav-id="/3-blogstranslated/3.2-blog2/"
  title="Blog 2"
  class="dd-item 
        
        
        
        "
>
  <a href="../../3-blogstranslated/3.2-blog2/">
     <b> 3.2. </b> Blog 2 
    <i class="fas fa-check read-icon"></i>
    
  </a>
   
</li>
    
            
<li
  data-nav-id="/3-blogstranslated/3.3-blog3/"
  title="Blog 3"
  class="dd-item 
        
        
        
        "
>
  <a href="../../3-blogstranslated/3.3-blog3/">
     <b> 3.3. </b> Blog 3 
    <i class="fas fa-check read-icon"></i>
    
  </a>
   
</li>
     
  </ul>
  
</li>
           
<li
  data-nav-id="/4-eventparticipated/"
  title="Events Participated"
  class="dd-item 
        
        
        
        "
>
  <a href="../../4-eventparticipated/">
     <b> 4. </b> Events Participated 
    <i class="fas fa-check read-icon"></i>
    
  </a>
   
  <ul>
          
            
<li
  data-nav-id="/4-eventparticipated/4.1-event1/"
  title="Event 1"
  class="dd-item 
        
        
        
        "
>
  <a href="../../4-eventparticipated/4.1-event1/">
     <b> 4.1. </b> Event 1 
    <i class="fas fa-check read-icon"></i>
    
  </a>
   
</li>
    
            
<li
  data-nav-id="/4-eventparticipated/4.2-event2/"
  title="Event 2"
  class="dd-item 
        
        
        
        "
>
  <a href="../../4-eventparticipated/4.2-event2/">
     <b> 4.2. </b> Event 2 
    <i class="fas fa-check read-icon"></i>
    
  </a>
   
</li>
    
            
<li
  data-nav-id="/4-eventparticipated/4.3-event3/"
  title="Event 3"
  class="dd-item 
        
        
        
        "
>
  <a href="../../4-eventparticipated/4.3-event3/">
     <b> 4.3. </b> Event 3 
    <i class="fas fa-check read-icon"></i>
    
  </a>
   
</li>
    
            
<li
  data-nav-id="/4-eventparticipated/4.4-event4/"
  title="Event 4"
  class="dd-item 
        
        
        
        "
>
  <a href="../../4-eventparticipated/4.4-event4/">
     <b> 4.4. </b> Event 4 
    <i class="fas fa-check read-icon"></i>
    
  </a>
   
</li>
    
            
<li
  data-nav-id="/4-eventparticipated/4.5-event5/"
  title="Event 5"
  class="dd-item 
        
        
        
        "
>
  <a href="../../4-eventparticipated/4.5-event5/">
     <b> 4.5. </b> Event 5 
    <i class="fas fa-check read-icon"></i>
    
  </a>
   
</li>
    
            
<li
  data-nav-id="/4-eventparticipated/4.6-event6/"
  title="Event 6"
  class="dd-item 
        
        
        
        "
>
  <a href="../../4-eventparticipated/4.6-event6/">
     <b> 4.6. </b> Event 6 
    <i class="fas fa-check read-icon"></i>
    
  </a>
   
</li>
     
  </ul>
  
</li>
           
<li
  data-nav-id="/5-workshop/"
  title="Workshop"
  class="dd-item 
        
        
        
        "
>
  <a href="../../5-workshop/">
     <b> 5. </b> Workshop 
    <i class="fas fa-check read-icon"></i>
    
  </a>
   
  <ul>
          
            
<li
  data-nav-id="/5-workshop/5.1-workshop-overview/"
  title="Introduction"
  class="dd-item 
        
        
        
        "
>
  <a href="../../5-workshop/5.1-workshop-overview/">
     <b> 5.1. </b> Introduction 
    <i class="fas fa-check read-icon"></i>
    
  </a>
   
  <ul>
          
            
<li
  data-nav-id="/5-workshop/5.1-workshop-overview/5.1.1-whatisrag/"
  title="What is Retrieval-Augmented Generation (RAG)"
  class="dd-item 
        
        
        
        "
>
  <a href="../../5-workshop/5.1-workshop-overview/5.1.1-whatisrag/">
     <b> 5.1.1 </b> What is Retrieval-Augmented Generation (RAG) 
    <i class="fas fa-check read-icon"></i>
    
  </a>
   
</li>
    
            
<li
  data-nav-id="/5-workshop/5.1-workshop-overview/5.1.2-services/"
  title="Services"
  class="dd-item 
        
        
        
        "
>
  <a href="../../5-workshop/5.1-workshop-overview/5.1.2-services/">
     <b> 5.1.2 </b> Services 
    <i class="fas fa-check read-icon"></i>
    
  </a>
   
</li>
     
  </ul>
  
</li>
    
            
<li
  data-nav-id="/5-workshop/5.2-prerequiste/"
  title="Prerequiste"
  class="dd-item 
        
        
        
        "
>
  <a href="../../5-workshop/5.2-prerequiste/">
     <b> 5.2. </b> Prerequiste 
    <i class="fas fa-check read-icon"></i>
    
  </a>
   
  <ul>
          
            
<li
  data-nav-id="/5-workshop/5.2-prerequiste/5.2.1-model-access/"
  title="Verify Model Access"
  class="dd-item 
        
        
        
        "
>
  <a href="../../5-workshop/5.2-prerequiste/5.2.1-model-access/">
     <b> 5.2.1 </b> Verify Model Access 
    <i class="fas fa-check read-icon"></i>
    
  </a>
   
</li>
    
            
<li
  data-nav-id="/5-workshop/5.2-prerequiste/5.2.2-prepare-data/"
  title="Prepare source data"
  class="dd-item 
        
        
        
        "
>
  <a href="../../5-workshop/5.2-prerequiste/5.2.2-prepare-data/">
     <b> 5.2.2 </b> Prepare source data 
    <i class="fas fa-check read-icon"></i>
    
  </a>
   
</li>
     
  </ul>
  
</li>
    
            
<li
  data-nav-id="/5-workshop/5.3-knowledge-base/"
  title="Create and Configure Knowledge Base"
  class="dd-item 
        
        
        
        "
>
  <a href="../../5-workshop/5.3-knowledge-base/">
     <b> 5.3. </b> Create and Configure Knowledge Base 
    <i class="fas fa-check read-icon"></i>
    
  </a>
   
  <ul>
          
            
<li
  data-nav-id="/5-workshop/5.3-knowledge-base/5.3.1-create-kb/"
  title="Initialize Knowledge Base"
  class="dd-item 
        
        
        
        "
>
  <a href="../../5-workshop/5.3-knowledge-base/5.3.1-create-kb/">
     <b> 5.3.1 </b> Initialize Knowledge Base 
    <i class="fas fa-check read-icon"></i>
    
  </a>
   
</li>
    
            
<li
  data-nav-id="/5-workshop/5.3-knowledge-base/5.3.2-sync-data/"
  title="Check Vector Store and Data Synchronization"
  class="dd-item 
        
        
        
        "
>
  <a href="../../5-workshop/5.3-knowledge-base/5.3.2-sync-data/">
     <b> 5.3.2 </b> Check Vector Store and Data Synchronization 
    <i class="fas fa-check read-icon"></i>
    
  </a>
   
</li>
     
  </ul>
  
</li>
    
            
<li
  data-nav-id="/5-workshop/5.4-test-chatbox/"
  title="Testing Chatbot (RAG)"
  class="dd-item 
        
        
        
        "
>
  <a href="../../5-workshop/5.4-test-chatbox/">
     <b> 5.4. </b> Testing Chatbot (RAG) 
    <i class="fas fa-check read-icon"></i>
    
  </a>
   
</li>
    
            
<li
  data-nav-id="/5-workshop/5.5-client-integration/"
  title="Client Application Integration (Optional)"
  class="dd-item 
        
        
        
        "
>
  <a href="../../5-workshop/5.5-client-integration/">
     <b> 5.5. </b> Client Application Integration (Optional) 
    <i class="fas fa-check read-icon"></i>
    
  </a>
   
</li>
    
            
<li
  data-nav-id="/5-workshop/5.6-update-data/"
  title="Update data"
  class="dd-item 
        
        
        
        "
>
  <a href="../../5-workshop/5.6-update-data/">
     <b> 5.6. </b> Update data 
    <i class="fas fa-check read-icon"></i>
    
  </a>
   
</li>
    
            
<li
  data-nav-id="/5-workshop/5.7-cleanup/"
  title="Clean Resources"
  class="dd-item 
        
        
        
        "
>
  <a href="../../5-workshop/5.7-cleanup/">
     <b> 5.7. </b> Clean Resources 
    <i class="fas fa-check read-icon"></i>
    
  </a>
   
</li>
     
  </ul>
  
</li>
           
<li
  data-nav-id="/6-self-evaluation/"
  title="Self-Assessment"
  class="dd-item 
        
        
        
        "
>
  <a href="../../6-self-evaluation/">
     <b> 6. </b> Self-Assessment 
    <i class="fas fa-check read-icon"></i>
    
  </a>
   
</li>
           
<li
  data-nav-id="/7-feedback/"
  title="Sharing and Feedback"
  class="dd-item 
        
        
        
        "
>
  <a href="../../7-feedback/">
     <b> 7. </b> Sharing and Feedback 
    <i class="fas fa-check read-icon"></i>
    
  </a>
   
</li>
    
    </ul>

     
    <section id="shortcuts">
      <h3>
        More
      </h3>
      <ul>
        
        <li>
          <a class="padding" href="https://www.facebook.com/groups/awsstudygroupfcj/"
            ><i class='fab fa-facebook'></i> AWS Study Group</a
          >
        </li>
        
      </ul>
    </section>
     
    <section id="prefooter">
      <hr />
      <ul>
        
        <li>
          <a class="padding">
            <i class="fas fa-language fa-fw"></i>
            <div class="select-style">
              <select id="select-language" onchange="location = this.value;">
                       
                <option
                  id="en"
                  value="https://tuanvu250.github.io/FCJ-Report/3-blogstranslated/3.1-blog1/"
                  selected
                >
                  English
                </option>
                            
                <option
                  id="vi"
                  value="https://tuanvu250.github.io/FCJ-Report/vi/3-blogstranslated/3.1-blog1/"
                >
                  Tiếng Việt
                </option>
                   
              </select>
              <svg
                version="1.1"
                id="Capa_1"
                xmlns="http://www.w3.org/2000/svg"
                xmlns:xlink="http://www.w3.org/1999/xlink"
                x="0px"
                y="0px"
                width="255px"
                height="255px"
                viewBox="0 0 255 255"
                style="enable-background: new 0 0 255 255"
                xml:space="preserve"
              >
                <g>
                  <g id="arrow-drop-down">
                    <polygon points="0,63.75 127.5,191.25 255,63.75 		" />
                  </g>
                </g>
              </svg>
            </div>
          </a>
        </li>
         
        <li>
          <a class="padding" href="#" data-clear-history-toggle=""
            ><i class="fas fa-history fa-fw"></i> Clear History</a
          >
        </li>
        
      </ul>
    </section>
    
    <section id="footer"><left>
    
    <b> Workshop</b> <br>
    <img src="https://hitwebcounter.com/counter/counter.php?page=7920860&style=0038&nbdigits=9&type=page&initCount=0"
        title="Migrate" Alt="web counter" border="0" /></a> <br>
    <b> <a href="https://cloudjourney.awsstudygroup.com/">Cloud Journey</a></b> <br>
    <img src="https://hitwebcounter.com/counter/counter.php?page=7830807&style=0038&nbdigits=9&type=page&initCount=0"
        title="Total CLoud Journey" Alt="web counter" border="0" />

</left>
<left>
    <br>
    <br>
    <b>Last Updated</b><br>
    <i>
        <span id="lastUpdated" style="color:orange;"></span>
    </i>

    <script>
        
        const today = new Date();
        
        const formattedDate = today.toLocaleDateString('en-GB');
        
        document.getElementById('lastUpdated').textContent = formattedDate;
    </script>
</left>
<left>
    <br>
    <br>
    <b> Team </b> <br>

    <i> <a href="https://www.facebook.com/groups/660548818043427" style="color:orange">First Cloud Journey </a> <br>

    </i>
</left>

<script async defer src="https://buttons.github.io/buttons.js"></script></section>
  </div>
</nav>




        <section id="body">
        <div id="overlay"></div>
        <div class="padding highlightable">
              
              <div>
                <div id="top-bar">
                
                
                <div id="breadcrumbs" itemscope="" itemtype="http://data-vocabulary.org/Breadcrumb">
                    <span id="sidebar-toggle-span">
                        <a href="#" id="sidebar-toggle" data-sidebar-toggle="">
                          <i class="fas fa-bars"></i>
                        </a>
                    </span>
                  
                  <span id="toc-menu"><i class="fas fa-list-alt"></i></span>
                  
                  <span class="links">
                 
                 
                    
          
          
            
            
          
          
            
            
          
          
            <a href='../../'>Internship Report</a> > <a href='../../3-blogstranslated/'>Translated Blogs</a> > Blog 1
          
        
          
        
          
        
                 
                  </span>
                </div>
                
                    <div class="progress">
  <div class="wrapper"><nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#generative-ai-deployment-options"><strong>Generative AI Deployment Options</strong></a></li>
        <li><a href="#architecture-overview"><strong>Architecture Overview</strong></a></li>
        <li><a href="#solution-deployment"><strong>Solution Deployment</strong></a></li>
        <li><a href="#prerequisites"><strong>Prerequisites</strong></a></li>
        <li><a href="#1-launch-gpu-instance-for-slm"><strong>1. Launch GPU instance for SLM</strong></a></li>
        <li><a href="#2-install-nvidia-drivers"><strong>2. Install NVIDIA drivers</strong></a></li>
        <li><a href="#3-download-and-install-llamacpp"><strong>3. Download and Install Llama.cpp</strong></a></li>
        <li><a href="#4-download-and-convert-slm-model"><strong>4. Download and Convert SLM model</strong></a></li>
        <li><a href="#slm-operation-and-optimization"><strong>SLM Operation and Optimization</strong></a></li>
        <li><a href="#chatbot-use-case-example"><strong>Chatbot Use Case Example</strong></a></li>
        <li><a href="#text-summarization-example"><strong>Text Summarization Example</strong></a></li>
        <li><a href="#cleaning-up"><strong>Cleaning Up</strong></a></li>
        <li><a href="#conclusion"><strong>Conclusion</strong></a></li>
      </ul>
    </li>
  </ul>
</nav></div>
</div>

                
              </div>
            </div>
            
        <div id="head-tags">
        
        </div>
        
        <div id="body-inner">
          
            <h1>
              
              Blog 1
            </h1>
          

        



	<h1 id="running-and-optimizing-small-language-models-on-premises-and-at-the-edge"><strong>Running and Optimizing Small Language Models On-Premises and at the Edge</strong></h1>
<p><em>By Chris McEvilly, Fernando Galves Guy Ben Baruchn | Date: 23/06/2025</em></p>
<p><em>| <a href="https://aws.amazon.com/blogs/compute/category/learning-levels/advanced-300/">In Advanced (300)</a>, <a href="https://aws.amazon.com/blogs/compute/category/compute/aws-outposts/">AWS Outposts</a>, <a href="https://aws.amazon.com/blogs/compute/category/post-types/technical-how-to/">Technical How-to</a></em></p>
<p>As you move your generative AI deployments from the prototype stage to production, you may find the need to run foundation models (FMs) on-premises or at the edge to meet data residency requirements, information security (InfoSec) policies, or low latency needs. For example, customers in highly regulated industries such as financial services, healthcare, and telecom may want to leverage chatbots to support customer queries, optimize internal workflows for complex reporting, and automate request approvals - while keeping data within national borders. Similarly, some organizations choose to deploy their own small language models (SLMs) to align with strict internal InfoSec requirements. In another example, manufacturers might want to deploy SLMs right on their factory floors to analyze production data and provide real-time equipment diagnostics. To meet user data residency, latency, and InfoSec needs, this article provides guidance on deploying <a href="https://aws.amazon.com/ai/generative-ai/">generative AI</a> FMs to <a href="https://aws.amazon.com/about-aws/global-infrastructure/localzones/">AWS Local Zones</a> and <a href="https://aws.amazon.com/outposts/rack/">AWS Outposts</a>. The goal is to present a framework for running various types of SLMs to satisfy data processing requirements based on customer engagements.</p>
<h3 id="generative-ai-deployment-options"><strong>Generative AI Deployment Options</strong></h3>
<p>The growth of generative AI in deployment and testing has accelerated with two main enterprise deployment options. The first option is using a <a href="https://aws.amazon.com/what-is/large-language-model/">large language model (LLM)</a> to meet business needs. LLMs have incredible versatility: a single model can perform completely different tasks, such as answering questions, coding, summarizing documents, translating languages, and content generation. LLMs have the potential to change how humans create content as well as how search engines and virtual assistants are used. The second deployment option is using small language models (SLMs), focused on a specific use case. SLMs are compact transformer models primarily using decoder-only or encoder-decoder architectures, generally having fewer than 20 billion parameters, although this definition is evolving as larger models emerge. SLMs can achieve comparable or even superior performance when fine-tuned for specific domains or tasks, making them an excellent alternative for specialized applications.</p>
<p>Additionally, SLMs offer faster inference times, lower resource requirements, and are suitable for deployment on a wider range of devices, which is particularly useful for specialized applications and edge computing where space and power are limited. Although SLMs have a more limited scope and accuracy compared to LLMs, you can enhance their performance for a specific task through <a href="https://aws.amazon.com/what-is/retrieval-augmented-generation/">Retrieval Augmented Generation (RAG)</a> and fine-tuning. This combination creates an SLM capable of answering queries related to a specific domain with an accuracy level comparable to an LLM, while minimizing hallucinations. Overall, SLMs provide effective solutions that balance user needs and cost efficiency.</p>
<h3 id="architecture-overview"><strong>Architecture Overview</strong></h3>
<p>The solution presented in this article uses Llama.cpp, an optimized framework written in C/C++ to efficiently run various types of SLMs. <a href="https://github.com/ggml-org/llama.cpp">Llama.cpp</a> can operate effectively in diverse computing environments, allowing generative AI models to function in <a href="https://aws.amazon.com/hybrid/">Local Zones or Outposts</a> without requiring massive GPU clusters often seen when running LLMs in their native frameworks. This framework expands model selection and increases operational performance when deploying SLMs to Local Zones and Outposts.</p>
<p>This architecture provides a template for deploying various types of SLMs to support use cases such as chatbots or content generation. The solution consists of a front-end application that receives user queries, formats prompts to present to the model, and returns responses from the model to the user. To support a scalable solution, application servers and Amazon EC2 G4dn GPU-enabled instances are placed behind an <a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/application/introduction.html">Application Load Balancer (ALB)</a>.</p>
<p>In cases where the volume of incoming prompts exceeds the processing capability of the SLMs, a message queue can be deployed in front of the SLMs. For example, you can deploy a <a href="https://www.rabbitmq.com/">RabbitMQ</a> cluster to act as a queue manager for the system.</p>
<p><img src="../../images/3-BlogsTranslated/3.1-Blog1/1.png" alt="Figure 1">
<em>Figure 1: Architecture overview</em></p>
<h3 id="solution-deployment"><strong>Solution Deployment</strong></h3>
<p>The following instructions describe how to launch an SLM using Llama.cpp in Local Zones or on Outposts. Although the previous architecture overview presented a complete solution with multiple components, this article focuses specifically on the steps necessary to deploy an SLM in an EC2 instance using Llama.cpp.</p>
<h3 id="prerequisites"><strong>Prerequisites</strong></h3>
<p>To deploy this solution, you need to prepare the following:</p>
<ul>
<li>An AWS account that has been allowlisted for Local Zones, or has a logical Outpost installed, configured, and operational.</li>
<li>Access to G4dn instances in your account at the selected location
<em>(check in <a href="https://console.aws.amazon.com/servicequotas/home">AWS Service Quotas</a>).</em></li>
<li>A VPC created to host the deployment environment.</li>
<li>Public and private subnets to support the environment in the VPC.</li>
<li>A security group associated with your EC2 instance.</li>
<li>An <a href="https://aws.amazon.com/iam/">AWS Identity and Access Management (IAM)</a> role with <a href="https://docs.aws.amazon.com/systems-manager/latest/userguide/getting-started-create-iam-instance-profile.html">AWS Systems Manager Session Manager permissions</a>.</li>
</ul>
<h3 id="1-launch-gpu-instance-for-slm"><strong>1. Launch GPU instance for SLM</strong></h3>
<p>Log in to the <a href="https://aws.amazon.com/console/">AWS Management Console</a>, open the Amazon EC2 console,
and launch a <strong>g4dn.12xlarge</strong> EC2 instance in your Local Zone or Outposts environment.</p>
<p>Configuration includes:</p>
<ul>
<li>Red Hat Enterprise Linux 9 (HVM), SSD Volume Type</li>
<li>Private subnet associated with the Local Zone or Outposts rack</li>
<li>30 GiB gp2 root volume and an additional 300 GiB gp2 EBS volume</li>
<li>IAM role configured with necessary permissions for Systems Manager</li>
<li>SSM Agent installed to connect to the instance
<em>(refer to instructions in <a href="https://docs.aws.amazon.com/systems-manager/latest/userguide/agent-install-rhel-8-9.html">Install SSM Agent on RHEL 8.x and 9.x</a> in the <a href="https://docs.aws.amazon.com/systems-manager/latest/userguide/what-is-systems-manager.html">Systems Manager User Guide</a>)</em></li>
</ul>
<p>For detailed instructions on launching an EC2 instance, refer to: <em>Launch an <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-launch-instance-wizard.html">EC2 instance using the launch instance wizard in the console</a></em> or <em><a href="https://docs.aws.amazon.com/outposts/latest/userguide/launch-instance.html">Launch an instance on your Outposts rack</a></em>.</p>
<p><img src="../../images/3-BlogsTranslated/3.1-Blog1/2.png" alt="Figure 2">
<em>Figure 2: SLM instance launched</em></p>
<h3 id="2-install-nvidia-drivers"><strong>2. Install NVIDIA drivers</strong></h3>
<ul>
<li>
<p>Connect to the SLM instance using Systems Manager.
You can follow the instructions at <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/connect-with-systems-manager-session-manager.html">Connect to your Amazon EC2 instance using Session Manager</a> in the <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/concepts.html">Amazon EC2 User Guide</a>.</p>
</li>
<li>
<p>Install kernel packages and necessary tools:</p>
</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span> sudo su -  
</span></span><span style="display:flex;"><span> dnf update -y  
</span></span><span style="display:flex;"><span> subscription-manager repos --enable codeready-builder-for-rhel-9-x86_64-rpms  
</span></span><span style="display:flex;"><span> dnf install -y https://dl.fedoraproject.org/pub/epel/epel-release-latest-9.noarch.rpm  
</span></span><span style="display:flex;"><span> dnf install -y ccache cmake gcc-c++ git git-lfs htop python3-pip unzip wget  
</span></span><span style="display:flex;"><span> dnf install -y dkms elfutils-libelf-devel kernel-devel kernel-modules-extra <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span> libglvnd-devel vulkan-devel xorg-x11-server-Xorg  
</span></span><span style="display:flex;"><span> systemctl enable --now dkms  
</span></span><span style="display:flex;"><span> reboot 
</span></span></code></pre></div><ul>
<li>
<p>Install <a href="https://www.anaconda.com/docs/getting-started/miniconda/install#macos-linux-installation">Miniconda3</a> in the /opt/miniconda3 directory or another compatible package manager to manage Python dependencies.</p>
</li>
<li>
<p>Install NVIDIA drivers:</p>
</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>dnf config-manager --add-repo <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>http://developer.download.nvidia.com/compute/cuda/repos/rhel9/x86_64/cuda-rhel9.repo  
</span></span><span style="display:flex;"><span>dnf module install -y nvidia-driver:latest-dkms  
</span></span><span style="display:flex;"><span>dnf install -y cuda-toolkit  
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#39;export PATH=/usr/local/cuda/bin:$PATH&#39;</span> &gt;&gt; ~/.bashrc  
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#39;export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH&#39;</span> &gt;&gt; ~/.bashrc  
</span></span><span style="display:flex;"><span>source ~/.bashrc
</span></span></code></pre></div><h3 id="3-download-and-install-llamacpp"><strong>3. Download and Install Llama.cpp</strong></h3>
<ul>
<li>
<p>Create and mount the filesystem of the Amazon EBS volume you created earlier to the /opt/slm directory. See instructions at <a href="https://docs.aws.amazon.com/ebs/latest/userguide/ebs-using-volumes.html">Make an Amazon EBS volume available for use</a> in the <a href="https://docs.aws.amazon.com/ebs/latest/userguide/what-is-ebs.html">Amazon EBS User Guide</a>.</p>
</li>
<li>
<p>Run the following commands to download and install Llama.cpp:</p>
</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cd /opt/slm
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>git clone -b b4942 https://github.com/ggerganov/llama.cpp.git
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cd llama.cpp  
</span></span><span style="display:flex;"><span>cmake -B build -DGGML_CUDA<span style="color:#f92672">=</span>ON
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cmake --build build --config Release -j<span style="color:#66d9ef">$(</span>nproc<span style="color:#66d9ef">)</span>  
</span></span><span style="display:flex;"><span>conda install python<span style="color:#f92672">=</span>3.12
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>pip install -r requirements.txt
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>pip install nvitop
</span></span></code></pre></div><h3 id="4-download-and-convert-slm-model"><strong>4. Download and Convert SLM model</strong></h3>
<p>To run SLMs efficiently with Llama.cpp, you need to convert the model to the GGUF (GPT-Generated Unified Format) format. This conversion optimizes performance and memory usage for resource-constrained edge deployments. GGUF is designed specifically to work with the Llama.cpp inference engine. The following steps illustrate how to download SmolLM2 1.7B and convert it to GGUF format:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>mkdir /opt/slm/models  
</span></span><span style="display:flex;"><span>cd /opt/slm/models  
</span></span><span style="display:flex;"><span>git lfs install  
</span></span><span style="display:flex;"><span>git clone https://huggingface.co/HuggingFaceTB/SmolLM2-1.7B-Instruct  
</span></span><span style="display:flex;"><span>cd /opt/slm/llama.cpp  
</span></span><span style="display:flex;"><span>python3 convert_hf_to_gguf.py --outtype f16 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--outfile /opt/slm/llama.cpp/models/SmolLM2-1.7B-Instruct-f16.gguf <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>/opt/slm/models/SmolLM2-1.7B-Instruct  
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#39;export PATH=/opt/slm/llama.cpp/build/bin:$PATH&#39;</span> &gt;&gt; ~/.bashrc  
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#39;export LD_LIBRARY_PATH=/opt/slm/llama.cpp/build/bin:$LD_LIBRARY_PATH&#39;</span> &gt;&gt; ~/.bashrc  
</span></span><span style="display:flex;"><span>source ~/.bashrc
</span></span></code></pre></div><p>You can also download other publicly available models from <a href="https://huggingface.co/">Hugging Face</a> if needed,
and perform a similar conversion process.</p>
<h3 id="slm-operation-and-optimization"><strong>SLM Operation and Optimization</strong></h3>
<p>Deploying SLMs via Llama.cpp offers high operational flexibility, allowing environment customization and optimization for specific use cases. With Llama.cpp, you can choose various parameters to optimize system resource usage and model operation, effectively utilizing resources without unnecessary waste or impacting performance. Common parameters when running Llama.cpp to control model behavior include:</p>
<ul>
<li><code>-ngl N, --n-gpu-layers N</code>: When compiling with GPU support, this option allows offloading some layers to the GPU for computation, increasing processing performance.</li>
<li><code>-t N, --threads N</code>: Determines the number of threads used during content generation. For optimal performance, set this value equal to the number of physical CPU cores in the system.</li>
<li><code>-n N, --n-predict N</code>: Determines the number of tokens to generate when creating text.
Adjusting this value affects the output length of the text.</li>
<li><code>-sm, --split-mode</code>: Determines how to split the model across multiple GPUs when running in a multi-GPU environment. Try the &ldquo;row&rdquo; splitting mode, as in some cases it offers better performance than the default layer-based splitting.</li>
<li><code>--temp N</code>: Temperature controls the randomness in the SLM&rsquo;s output. Lower values (e.g., 0.2-0.5) produce more consistent and deterministic responses, while higher values (e.g., 0.9-1.2) allow the model to be more creative and diverse (default: 0.88).</li>
<li><code>-s SEED, --seed SEED</code>: Provides a method to control model randomness. Setting a fixed seed helps reproduce consistent results across multiple runs (default: -1, -1 = random seed).</li>
<li><code>-c, --ctx-size N</code>: Determines the context size, the number of tokens the FM can process in a prompt. This value affects the required RAM and model accuracy. For example: with Phi-3, it is recommended to reduce context size to 8k or 16k to optimize performance. Sample command: <code>--ctx-size XXXX</code> where XXXX is the context size.</li>
</ul>
<p>This section illustrates how to optimize SLM performance for specific use cases using Llama.cpp, covering two common scenarios: Chatbot interactions and Text summarization.</p>
<h3 id="chatbot-use-case-example"><strong>Chatbot Use Case Example</strong></h3>
<h4 id="token-size-requirements"><strong>Token Size Requirements</strong></h4>
<p>For chatbot applications, typical token sizes: Input: approximately 50-150 tokens, supporting 1-2 user questions, and Output: approximately 100-300 tokens, helping the model respond concisely but with detail.</p>
<h4 id="sample-command"><strong>Sample Command</strong></h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>./build/bin/llama-cli -m ./models/SmolLM2-1.7B-Instruct-f16.gguf <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>-ngl <span style="color:#ae81ff">99</span> -n <span style="color:#ae81ff">512</span> --ctx-size <span style="color:#ae81ff">8192</span> -sm row --temp <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>--single-turn <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>-sys <span style="color:#e6db74">&#34;You are a helpful assistant&#34;</span> -p <span style="color:#e6db74">&#34;Hello&#34;</span>
</span></span></code></pre></div><p><img src="../../images/3-BlogsTranslated/3.1-Blog1/3.png" alt="Figure 3">
<em>Figure 3: Chatbot example</em></p>
<h4 id="command-explanation"><strong>Command Explanation</strong></h4>
<ul>
<li><code>-m ./models/SmolLM2-1.7B-Instruct-f16.gguf</code> : Specifies the model file to use</li>
<li><code>-ngl 99</code> : Assigns 99 GPU layers for optimal performance</li>
<li><code>-n 512</code> : Maximum 512 output tokens (sufficient for the needed 100-300 tokens)</li>
<li><code>--ctx-size 8192</code> : Sets context window size to handle complex conversations</li>
<li><code>-sm row</code> : Splits across GPUs by row</li>
<li><code>--temp 0</code> : Sets temperature to 0 to reduce creativity</li>
<li><code>--single-turn</code> : Optimized for single-turn responses</li>
<li><code>-sys &quot;You are a helpful assistant&quot;</code> : Sets system prompt defining the assistant role</li>
<li><code>-p &quot;Hello&quot;</code> : User prompt input</li>
</ul>
<h3 id="text-summarization-example"><strong>Text Summarization Example</strong></h3>
<p>The command line below shows SmolLM2-1.7B running a text summarization task:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>PROMPT_TEXT<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Summarize the following text: Amazon DynamoDB is a serverless,  
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">NoSQL database service that allows you to develop modern applications  
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">at any scale. As a serverless database, you only pay for what you use  
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">and DynamoDB scales to zero, has no cold starts, no version upgrades,  
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">no maintenance windows, no patching, and no downtime maintenance.  
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">DynamoDB offers a broad set of security controls and compliance  
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">standards. For globally distributed applications, DynamoDB global  
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">tables is a multi-Region, multi-active database with a 99.999%  
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">availability SLA and increased resilience. DynamoDB reliability is  
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">supported with managed backups, point-in-time recovery, and more.  
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">With DynamoDB streams, you can build serverless event-driven applications.&#34;</span>  
</span></span><span style="display:flex;"><span>./build/bin/llama-cli -m ./models/SmolLM2-1.7B-Instruct-f16.gguf <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>-ngl <span style="color:#ae81ff">99</span> -n <span style="color:#ae81ff">512</span> --ctx-size <span style="color:#ae81ff">8192</span> -sm row --single-turn <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>-sys <span style="color:#e6db74">&#34;You are a technical writer&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--prompt <span style="color:#e6db74">&#34;</span>$PROMPT_TEXT<span style="color:#e6db74">&#34;</span>
</span></span></code></pre></div><p><img src="../../images/3-BlogsTranslated/3.1-Blog1/4.png" alt="Figure 4">
<em>Figure 4: Summarization example</em></p>
<h3 id="cleaning-up"><strong>Cleaning Up</strong></h3>
<p>To avoid unnecessary costs, perform the following steps to delete resources after completion:</p>
<ul>
<li><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/terminating-instances.html">Terminate EC2 instance</a> to stop charges. Verify that the 300 GiB EBS volume was deleted correctly by checking the Volumes section under Elastic Block Store. If the volume remains, select it and perform: Actions &gt; Delete volume.</li>
</ul>
<h3 id="conclusion"><strong>Conclusion</strong></h3>
<p>This article has guided you step-by-step through deploying SLMs to an AWS on-premises or edge environment to meet local data processing needs. The beginning of the article discussed the business benefits of SLMs, including: Faster inference time, reduced operational costs, and improved model outputs. SLMs deployed using Llama.cpp and optimized for specific use cases can deliver efficient user services from the edge in a scalable manner. The optimization parameters described in this article provide various configuration methods to tune the model for diverse deployment scenarios. You can follow the steps and techniques presented to deploy generative AI tailored to data residency, latency, or InfoSec compliance requirements, while operating efficiently within the resource constraints of edge computing environments. To learn more, visit <a href="https://aws.amazon.com/about-aws/global-infrastructure/localzones/">AWS Local Zones</a> and <a href="https://aws.amazon.com/outposts/rack/">AWS Outposts</a>.</p>





<footer class=" footline" >
	
</footer>

        
        </div> 
        

      </div>

    <div id="navigation">
        
        
        
        
            
            
                
                    
                    
                
                

                    
                    
                        
                    
                    

                    
                        
            
            
                
                    
                        
                        
                    
                
                

                    
                    
                        
                    
                    

                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                    
                
                

                    
                    
                        
                    
                    

                    
                        
            
            
                
                    
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                        
                        
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                        
                    
                    

                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                        
                    
                    

                    
                        
            
            
                
                    
                
                

                    
                    
                        
                    
                    

                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                        
                    
                    

                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                        
                    
                    

                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
            
        
        
        


	 
	 
		
			<a class="nav nav-prev" href="../../3-blogstranslated/" title="Translated Blogs"> <i class="fa fa-chevron-left"></i></a>
		
		
			<a class="nav nav-next" href="../../3-blogstranslated/3.2-blog2/" title="Blog 2" style="margin-right: 0px;"><i class="fa fa-chevron-right"></i></a>
		
	
    </div>

    </section>
    
    <div style="left: -1000px; overflow: scroll; position: absolute; top: -1000px; border: none; box-sizing: content-box; height: 200px; margin: 0px; padding: 0px; width: 200px;">
      <div style="border: none; box-sizing: content-box; height: 200px; margin: 0px; padding: 0px; width: 200px;"></div>
    </div>
    <script src="../../js/clipboard.min.js?1765049782"></script>
    <script src="../../js/perfect-scrollbar.min.js?1765049782"></script>
    <script src="../../js/perfect-scrollbar.jquery.min.js?1765049782"></script>
    <script src="../../js/jquery.sticky.js?1765049782"></script>
    <script src="../../js/featherlight.min.js?1765049782"></script>
    <script src="../../js/highlight.pack.js?1765049782"></script>
    <script>hljs.initHighlightingOnLoad();</script>
    <script src="../../js/modernizr.custom-3.6.0.js?1765049782"></script>
    <script src="../../js/learn.js?1765049782"></script>
    <script src="../../js/hugo-learn.js?1765049782"></script>

    <link href="../../mermaid/mermaid.css?1765049782" rel="stylesheet" />
    <script src="../../mermaid/mermaid.js?1765049782"></script>
    <script>
        mermaid.initialize({ startOnLoad: true });
    </script>
    <script>
  (function (i, s, o, g, r, a, m) {
    i["GoogleAnalyticsObject"] = r;
    ((i[r] =
      i[r] ||
      function () {
        (i[r].q = i[r].q || []).push(arguments);
      }),
      (i[r].l = 1 * new Date()));
    ((a = s.createElement(o)), (m = s.getElementsByTagName(o)[0]));
    a.async = 1;
    a.src = g;
    m.parentNode.insertBefore(a, m);
  })(
    window,
    document,
    "script",
    "https://www.google-analytics.com/analytics.js",
    "ga",
  );

  ga("create", "UA-158079754-2", "auto");
  ga("send", "pageview");
</script>

  </body>
</html>
