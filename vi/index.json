[
{
	"uri": "https://tuanvu250.github.io/FCJ-Report/vi/4-eventparticipated/4.1-event1/",
	"title": "Event 1",
	"tags": [],
	"description": "",
	"content": "Bài thu hoạch “Gen AI \u0026amp; Data” Mục Đích Của Sự Kiện Cập nhật xu hướng và chiến lược GenAI trên AWS Tìm hiểu xây dựng nền tảng dữ liệu hợp nhất phục vụ AI/Analytics Giới thiệu AI-Driven Development Lifecycle (AI-DLC) trong phát triển phần mềm Học hỏi về bảo mật cho ứng dụng GenAI và AI Agent trong doanh nghiệp Danh Sách Diễn Giả Jun Kai Loke – AI/ML Specialist SA, AWS Kien Nguyen – Solutions Architect, AWS Tamelly Lim – Storage Specialist SA, AWS Binh Tran – Senior Solutions Architect, AWS Taiki Dang – Solutions Architect, AWS Michael Armentano – Principal WW GTM Specialist, AWS Nội Dung Nổi Bật 1. Xây dựng Nền tảng Dữ liệu Thống nhất trên AWS cho AI \u0026amp; Analytics Chiến lược xây dựng nền tảng dữ liệu hợp nhất, mở rộng, phục vụ AI/Analytics. Luồng dữ liệu end-to-end: ingestion → lưu trữ → xử lý → truy cập → governance. Khắc phục 3 silo (Data/People/Business); self-service + chuẩn hóa quản trị. Dịch vụ trọng tâm: S3, Glue, Redshift, Lake Formation, OpenSearch, Kinesis/MSK. 2. Xây dựng Tương lai: Chiến lược Áp dụng GenAI trên AWS Tầm nhìn \u0026amp; xu hướng GenAI; lộ trình áp dụng trong doanh nghiệp. Amazon Bedrock: chọn model, tùy chỉnh/RAG, guardrails, tối ưu chi phí/độ trễ. AgentCore: runtime độc lập framework, gateway tích hợp công cụ, identity/observability. Amazon Nova và hệ sinh thái frameworks (CrewAI, LangGraph, LlamaIndex, Strands). 3. Bảo mật Ứng dụng Trí tuệ Nhân tạo Sinh tạo với AWS Rủi ro theo OWASP LLM (LLM01/02), kiểm soát đầu ra an toàn. Bảo mật theo lớp: hạ tầng, mô hình, ứng dụng; IAM, mã hóa, zero-trust, giám sát liên tục. 5 trụ cột bảo mật: Compliance \u0026amp; Governance, Legal \u0026amp; Privacy, Controls, Risk Management, Resilience. Generative AI Security Scoping Matrix (Scope 1 → 5): từ consumer apps đến self-trained models. Bedrock Guardrails: lọc nội dung nhạy cảm với ngưỡng cấu hình. Human-in-the-loop: con người phê duyệt/can thiệp khi cần. Observability (OpenTelemetry): giám sát, log, trace minh bạch hành vi AI. 4. Vượt xa Tự động hóa: AI Agents như Công cụ Nhân Năng suất Agentic AI: từ assistant → multi-agent systems; giảm giám sát, tăng tự chủ. Ứng dụng: hỗ trợ khách hàng, BI với Amazon Q (QuickSight), tự động hóa quy trình. Amazon Q in QuickSight: Build Dashboards/Reports, Data Q\u0026amp;A, Executive Summaries. Giá trị kỳ vọng: năng suất vượt bậc; yêu cầu nền tảng dữ liệu \u0026amp; governance vững chắc. 5. Độ Tin cậy và Tính đúng đắn của GenAI Vấn đề hallucination → giảm thiểu qua: Prompt Engineering, RAG, Fine-tuning, Parameter Tuning. RAG in action: user input → embedding → context → LLM → response. 6. Vòng đời Phát triển Hướng dẫn bởi AI (AI-DLC) Vòng đời AI-centric: Inception → Construction → Operation. Tiến hóa: AI-Assisted → AI-Driven → AI-Managed; AI điều phối, con người phê duyệt. Hạ tầng triển khai: IaC, test tự động, quan sát và quản trị rủi ro. 7. Amazon SageMaker (Unified Studio – thế hệ mới) Một môi trường hợp nhất cho data, analytics, và AI: SQL analytics, data processing, model dev/training, GenAI app dev, BI, streaming, search analytics. Lakehouse + Governance: catalog/lineage, policy-based access, auditing; quản trị Data \u0026amp; AI đồng nhất. Zero-ETL integration: lõi S3 ↔ Redshift, kết nối Aurora, DynamoDB, RDS, OpenSearch, Kinesis/MSK, Salesforce, SAP, ServiceNow. MLOps đầy đủ: pipelines/experiments, model registry, deployment endpoints, Feature Store, monitoring. Tích hợp Bedrock \u0026amp; JumpStart: dùng Foundation Models (qua Bedrock), mẫu tham chiếu \u0026amp; tăng tốc triển khai trên SageMaker. Những Gì Học Được Tư Duy Thiết K Kế Business-first approach: Luôn bắt đầu từ nhu cầu kinh doanh thay vì chỉ tập trung vào công nghệ. Ubiquitous language: Tầm quan trọng của ngôn ngữ chung giữa business và kỹ thuật, đặc biệt khi trao đổi với mentor/team. Bounded contexts: Hiểu cách chia nhỏ domain, tránh phức tạp hóa khi mở rộng hệ thống. Kiến Trúc \u0026amp; Công Nghệ Xây dựng Data Foundation hợp nhất: Ingestion → Lưu trữ → Xử lý → Truy cập → Governance. GenAI trên AWS: Bedrock (model choice, guardrails, RAG), AgentCore (runtime, gateway, identity, observability), Nova LLMs. AI Agents: Từ assistant → multi-agent systems; ứng dụng thực tế như customer support, BI với Amazon Q. AI-DLC: Vòng đời phát triển có AI làm trung tâm (Inception → Construction → Operation). Security-first mindset: Guardrails, human-in-the-loop, tuân thủ \u0026amp; giám sát (OpenTelemetry). Chiến Lược \u0026amp; Ứng Dụng Phased approach: Không vội vàng, cần roadmap rõ ràng cho hiện đại hóa và áp dụng AI. Zero-ETL \u0026amp; Unified Studio (SageMaker): Giảm phức tạp trong tích hợp dữ liệu, quản lý lifecycle AI tập trung. ROI measurement: Không chỉ cost saving mà còn agility, productivity. Ứng Dụng Vào Công Việc Cá Nhân Trong dự án:\nCó thể thử áp dụng AI Agent để hỗ trợ quy trình đăng ký/đăng nhập hoặc customer support. Sử dụng validation/guardrails để tăng tính an toàn khi tích hợp GenAI vào app. Trong học tập \u0026amp; team project (Sprint 0, serverless vs containerization):\nÁp dụng kiến thức AI-DLC để chia task hợp lý: AI hỗ trợ nghiên cứu/tạo code, team review \u0026amp; approve. Hiểu khi nào nên dùng Lambda (serverless) và khi nào cần container (ECS/Fargate). Trong vai trò học việc:\nNhận ra cần business-first approach khi viết tài liệu/thu thập yêu cầu. Thấy rõ tầm quan trọng của data foundation để bất kỳ ứng dụng GenAI nào hoạt động đúng và có giá trị. Trải Nghiệm Trong Event Học hỏi trực tiếp từ các chuyên gia AWS về Data, GenAI adoption, Security, AI Agents, AI-DLC. Slide và case study giúp mình hình dung rõ AgentCore hoạt động thế nào trong thực tế. Thấy được cách AWS định hình tương lai phát triển phần mềm: AI không chỉ hỗ trợ mà trở thành một phần của lifecycle. Cảm nhận rõ ràng rằng để ứng dụng GenAI hiệu quả, phải có nền tảng dữ liệu tốt + bảo mật nghiêm ngặt + chiến lược áp dụng bài bản. Bài Học Rút Ra AI Agents và AgentCore sẽ sớm trở thành phần quan trọng trong ứng dụng doanh nghiệp → mình cần học sớm để đi trước. Data platform \u0026amp; governance là chìa khóa → không chỉ code, mà còn quản lý dữ liệu đúng cách. AI-DLC cho thấy vai trò của AI trong SDLC tương lai → có thể thử áp dụng dần trong project nhỏ. Security không chỉ là add-on, mà phải thiết kế ngay từ đầu khi làm với GenAI. Một số hình ảnh khi tham gia sự kiện "
},
{
	"uri": "https://tuanvu250.github.io/FCJ-Report/vi/4-eventparticipated/4.2-event2/",
	"title": "Event 2",
	"tags": [],
	"description": "",
	"content": "Bài thu hoạch \u0026ldquo;AI-Driven Development Life Cycle: Reimagining Software Engineering\u0026rdquo; Mục Đích Của Sự Kiện Khám phá cách AI thay đổi toàn bộ vòng đời phát triển phần mềm, từ planning đến deployment. Tìm hiểu cách tích hợp AI để tăng năng suất và tập trung vào tác vụ sáng tạo có giá trị cao.\nThông Tin Sự Kiện Thời gian: 2:00 PM - 4:30 PM, Thứ Sáu, 03/10/2025 Địa điểm: AWS Event Hall, L26 Bitexco Tower, HCMC Diễn giả: Toan Huynh, My Nguyen Nội Dung Nổi Bật 1. AI in Development - Outcomes Việc áp dụng AI mang lại:\nVelocity - Giảm time-to-market Quality - Đáp ứng usability, reliability Market Responsiveness - Phản ứng nhanh với thị trường Innovation - Thúc đẩy đổi mới Developer Engagement - Tăng sự hài lòng của developers Productivity - Tăng giá trị, giảm chi phí 2. Challenges with AI Development AI-Managed: Không đáng tin cậy, khó giải thích, thiếu linh hoạt\nAI-Assisted: Không hiệu quả thực sự, manual inefficiencies, technical debts tích lũy\n3. AI-Driven Development Lifecycle (AI-DLC) Core Concept:\nAI as Collaborator: AI hỗ trợ developers, con người kiểm soát quyết định quan trọng Human-Centric: Developers là trung tâm, AI enhance không replace Accelerated Delivery: Chu kỳ phát triển giảm từ tuần/tháng xuống giờ/ngày Hai giai đoạn:\nInception: Build Context → User Stories → Plan Construction: Domain Model → Generate code → Deploy với IaaC 4. 5-Stage Sequential Process Product Owner → 2. Architect (Design) → 3. Architect (Construction) → 4. Engineer (POC) → 5. Engineer (MVP) 5. Anti-Patterns - 7 điều cần tránh Không single-shot multi-step problems Tối ưu semantics-to-token ratio Refresh context strategically Kiểm soát AI over-reach Model biết cái cũ hơn cái mới Brownfield cần context building đặc biệt Cần độ chính xác như phẫu thuật 6. Amazon Q Developer Prompt Structure: Role → Plan (markdown với checkboxes) → Task\nExample: Xây dựng travel booking app với AI integration\nWorkflow: Tạo thư mục → User stories → Clarification → Checkbox → Review → Execute\n7. Kiro - AI-Powered Coding Assistant Kiro là AI coding assistant của AWS với 4 tính năng chính:\nAgent Hooks: Tự động trigger tasks khi events (file save), generate docs/tests/optimize VS Code Compatible: Hỗ trợ plugins, themes, settings Claude Models: Sonnet 3.7/4 với reasoning mạnh mẽ Enterprise Security: Built \u0026amp; operated by AWS Ưu điểm: Automation cao, context-aware, documentation-driven, enterprise-ready\nNhững Gì Học Được Tham gia workshop “GenAI-powered App-DB Modernization” là một trải nghiệm rất bổ ích, giúp tôi có cái nhìn toàn diện về cách hiện đại hóa ứng dụng và cơ sở dữ liệu bằng các phương pháp và công cụ hiện đại. Một số trải nghiệm nổi bật:\nHọc hỏi từ các diễn giả có chuyên môn cao Các diễn giả đến từ AWS và các tổ chức công nghệ lớn đã chia sẻ best practices trong thiết kế ứng dụng hiện đại. Qua các case study thực tế, tôi hiểu rõ hơn cách áp dụng Domain-Driven Design (DDD) và Event-Driven Architecture vào các project lớn. Trải nghiệm kỹ thuật thực tế Tham gia các phiên trình bày về event storming giúp tôi hình dung cách mô hình hóa quy trình kinh doanh thành các domain events. Học cách phân tách microservices và xác định bounded contexts để quản lý sự phức tạp của hệ thống lớn. Hiểu rõ trade-offs giữa synchronous và asynchronous communication cũng như các pattern tích hợp như pub/sub, point-to-point, streaming. Ứng dụng công cụ hiện đại Trực tiếp tìm hiểu về Amazon Q Developer, công cụ AI hỗ trợ SDLC từ lập kế hoạch đến maintenance. Học cách tự động hóa code transformation và pilot serverless với AWS Lambda, từ đó nâng cao năng suất phát triển. Bài học rút ra Việc áp dụng DDD và event-driven patterns giúp giảm coupling, tăng scalability và resilience cho hệ thống. Chiến lược hiện đại hóa cần phased approach và đo lường ROI, không nên vội vàng chuyển đổi toàn bộ hệ thống. Các công cụ AI như Amazon Q Developer có thể boost productivity nếu được tích hợp vào workflow phát triển hiện tại. Một số hình ảnh khi tham gia sự kiện "
},
{
	"uri": "https://tuanvu250.github.io/FCJ-Report/vi/4-eventparticipated/4.3-event3/",
	"title": "Event 3",
	"tags": [],
	"description": "",
	"content": "Bài thu hoạch “WORKSHOP KHOA HỌC DỮ LIỆU TRÊN AWS” Mục Đích Của Sự Kiện Chia sẻ tổng quan về hệ sinh thái các dịch vụ AI/ML trên AWS. Hướng dẫn thực hành triển khai mô hình AI sử dụng Amazon SageMaker. Minh họa quy trình đưa một mô hình AI từ phòng thí nghiệm ra ứng dụng thực tế thông qua API. Danh Sách Diễn Giả Văn Hoàng Kha - Cloud Solutions Architect, Leader AWS User Group. Bạch Doãn Vương - Cloud Developer Engineer, AWS Community Builder. Nội Dung Nổi Bật 1. Tầm Quan Trọng Của Cloud Computing Trong Data Science Mở đầu bằng sự khẳng định vai trò trụ cột của điện toán đám mây đối với ngành khoa học dữ liệu hiện đại, đặc biệt là trong khả năng xử lý và lưu trữ dữ liệu lớn. So sánh Cloud vs On-premise: Cloud: Ưu điểm vượt trội về khả năng mở rộng (Scalability), tốc độ triển khai (Agility) và mô hình chi phí linh hoạt (OPEX). On-premise: Hạn chế về chi phí đầu tư hạ tầng (CAPEX), khó khăn trong việc mở rộng tài nguyên tức thời cũng như gánh nặng bảo trì. AWS cung cấp một nền tảng \u0026ldquo;End-to-End\u0026rdquo; cho Data Science pipeline: từ thu thập, lưu trữ, xử lý dữ liệu cho đến huấn luyện và vận hành mô hình. 2. Ba Tầng Dịch Vụ (3-Layer Stack) Của AWS AI AWS thiết kế hệ sinh thái AI theo 3 tầng riêng biệt để phục vụ đa dạng nhu cầu:\nTầng 1: AI Services (Dịch vụ AI Quản Lý Sẵn)\nPhù hợp cho: App Developers không chuyên về ML.\nLà các API thông minh đã được AWS huấn luyện sẵn. Tích hợp nhanh chóng vào ứng dụng để có ngay tính năng AI. Dịch vụ nổi bật: Amazon Comprehend: Phân tích văn bản, cảm xúc. Amazon Translate: Dịch thuật tự động. Amazon Textract: Nhận diện và trích xuất dữ liệu từ văn bản/ảnh. Amazon Rekognition: Phân tích hình ảnh, video. Amazon Bedrock: Cổng kết nối đến các mô hình nền tảng (Foundation Models) mạnh mẽ. Tầng 2: ML Services (Amazon SageMaker)\nPhù hợp cho: Data Scientists \u0026amp; ML Engineers.\nMôi trường phát triển toàn diện (IDE) cho Machine Learning. Cung cấp công cụ cho mọi bước: Data Wrangler: Chuẩn bị dữ liệu. Feature Store: Kho lưu trữ đặc trưng. SageMaker Autopilot: Huấn luyện tự động (AutoML). Model Registry: Quản lý vòng đời mô hình. Tầng 3: AI Infrastructure (Hạ tầng ML)\nPhù hợp cho: Expert Practitioners cần tối ưu sâu.\nCung cấp các tài nguyên tính toán mạnh mẽ nhất: EC2 Instances (P5, G6, Trn1\u0026hellip;): Các chipset chuyên dụng cho training/inference. EKS/ECS: Chạy workload AI trên nền tảng container. 3. Các Công Cụ Hỗ Trợ Đắc Lực Cho Sinh Viên Amazon SageMaker: Nơi tốt nhất để bắt đầu học và thực hành quy trình ML chuẩn công nghiệp. Amazon Comprehend: Công cụ mạnh mẽ cho các bài toán NLP như phân tích review, phân loại văn bản. Amazon Translate: Hỗ trợ xây dựng ứng dụng đa ngôn ngữ với chi phí thấp. Amazon Textract: Giải pháp hiệu quả cho các bài toán số hóa dữ liệu từ giấy tờ. 4. Demo \u0026amp; Thực Hành Demo 1: No-code ML với SageMaker Canvas\nDiễn giả trình diễn cách tạo ra một mô hình dự đoán mà không cần viết bất kỳ dòng code nào nhờ giao diện kéo-thả trực quan. Bài học: Giúp dân không chuyên (Business Analyst) cũng có thể ứng dụng AI. Demo 2: Deploy Model thành API Service\nQuy trình đưa model đã train lên SageMaker Endpoint và expose ra ngoài qua API Gateway. Bài học: Hiểu rõ quy trình \u0026ldquo;Productionize\u0026rdquo; một mô hình AI để người dùng cuối có thể sử dụng. Trải nghiệm trong event Buổi workshop thực sự là một trải nghiệm bổ ích, giúp tôi hệ thống hóa lại kiến thức về AI/ML trên nền tảng Cloud.\nTư duy hệ thống: Hiểu rõ 3 tầng dịch vụ giúp tôi biết cách chọn đúng công cụ cho đúng bài toán, tránh việc \u0026ldquo;dùng dao mổ trâu để giết gà\u0026rdquo;. Góc nhìn thực tế: Những bài demo trực quan đã giúp tôi hình dung rõ ràng con đường từ một file notebook đến một API service hoạt động thực tế. Động lực: Thấy được sự hỗ trợ mạnh mẽ của AWS dành cho cộng đồng và sinh viên thông qua các chương trình Free Tier và tài liệu học tập. Một số hình ảnh khi tham gia sự kiện "
},
{
	"uri": "https://tuanvu250.github.io/FCJ-Report/vi/4-eventparticipated/4.4-event4/",
	"title": "Event 4",
	"tags": [],
	"description": "",
	"content": "Bài thu hoạch “AWS Cloud Mastery Series #1: GENERATIVE AI, RAG \u0026amp; AWS AGENTIC AI” Mục Đích Của Sự Kiện Làm chủ kỹ thuật Prompt Engineering để tối ưu hóa tương tác và điều khiển các mô hình ngôn ngữ lớn (LLMs). Tổng hợp các dịch vụ AI tích hợp sẵn (Pre-trained Services) mạnh mẽ trên hệ sinh thái AWS. Đi sâu vào kiến trúc RAG (Retrieval-Augmented Generation) - giải pháp cốt lõi cung cấp kiến thức riêng biệt cho AI. Cập nhật xu hướng Agentic AI và giải pháp Amazon Bedrock AgentCore giúp thu hẹp khoảng cách từ bản thử nghiệm (POC) đến môi trường thực tế (Production). Tiếp cận Pipecat Framework trong việc xây dựng các trợ lý ảo tương tác bằng giọng nói thời gian thực. Danh Sách Diễn Giả Lâm Tuấn Kiệt - Sr DevOps Engineer (FPT Software) Danh Hoàng Hiếu Nghị - AI Engineer (Renova Cloud) Đinh Lê Hoàng Anh - Cloud Engineer Trainee (First Cloud AI Journey) Nội Dung Nổi Bật 1. Prompt Engineering \u0026amp; Foundation Models Mở đầu chương trình là những chia sẻ nền tảng về cách giao tiếp hiệu quả với Generative AI:\nZero-shot / Few-shot Prompting: Các chiến lược gợi ý ngữ cảnh để mô hình trả ra kết quả mong muốn ngay từ lần đầu hoặc qua vài ví dụ mẫu. Chain of Thought (CoT): Kỹ thuật \u0026ldquo;chia nhỏ vấn đề\u0026rdquo;, yêu cầu mô hình suy luận từng bước (step-by-step) để giải quyết các bài toán logic phức tạp. 2. Hệ Sinh Thái Dịch Vụ AI AWS AWS cung cấp bộ công cụ toàn diện giúp tích hợp trí tuệ nhân tạo mà không cần build model từ đầu:\nXử lý hình ảnh: Amazon Rekognition. Xử lý ngôn ngữ: Amazon Translate, Comprehend, Textract (trích xuất văn bản thông minh). Xử lý âm thanh: Amazon Polly (chuyển văn bản thành giọng nói), Transcribe (chuyển giọng nói thành văn bản). 3. Chiến Lược RAG (Retrieval Augmented Generation) RAG được giới thiệu như giải pháp tối ưu cho hạn chế về cập nhật dữ liệu của LLM:\nCơ chế: Kết hợp khả năng sinh ngữ của LLM với khả năng tìm kiếm chính xác từ kho dữ liệu doanh nghiệp. Công cụ: Sử dụng Amazon Titan Text Embeddings V2 để vector hóa dữ liệu và Knowledge Bases for Amazon Bedrock để quản lý quy trình truy vấn một cách tự động. 4. Kỷ Nguyên Của Agentic AI Sự tiến hóa của AI được phân cấp rõ rệt:\nGenAI Assistants: Trợ lý ảo thực thi mệnh lệnh đơn lẻ. GenAI Agents: Tác nhân AI hướng mục tiêu, biết sử dụng công cụ (Tools) để hoàn thành nhiệm vụ. Agentic AI Systems: Hệ thống các Agents tự chủ phối hợp (Multi-agent orchestration). Thách thức \u0026ldquo;Prototype to Production\u0026rdquo;: Việc đưa Agent ra thị trường gặp rào cản lớn về Bảo mật (Security), Quản trị (Governance) và khả năng mở rộng (Scalability).\n5. Giải Pháp Amazon Bedrock AgentCore Nền tảng giúp đơn giản hóa việc xây dựng và vận hành Agent:\nMemory: Tự động duy trì ngữ cảnh hội thoại dài hạn. Action Group: Định nghĩa các hành động mà Agent có thể thực hiện thông qua API. Code Interpreter: Môi trường Sandbox an toàn để Agent tự viết và chạy code. Traceability: Khả năng truy vết quá trình suy luận của Agent để debug và tối ưu. 6. Pipecat - Real-time Voice AI Demo ấn tượng về Framework mã nguồn mở giúp xây dựng các ứng dụng hội thoại tự nhiên:\nƯu điểm: Độ trễ thấp (Low latency), hỗ trợ đa phương thức (Multimodal). Luồng xử lý: Kết hợp WebRTC, STT, LLM và TTS thành một pipeline mượt mà. Trải nghiệm chi tiết trong Event Buổi workshop đã mở ra cho tôi nhiều góc nhìn mới mẻ:\n1. Sự Dịch Chuyển Từ \u0026ldquo;Chat\u0026rdquo; Sang \u0026ldquo;Act\u0026rdquo; Tôi nhận thấy tương lai không chỉ dừng lại ở các Chatbot trả lời câu hỏi, mà là các Autonomous Agents có khả năng thực thi công việc thực tế (đặt lịch, tra cứu, xử lý số liệu) một cách độc lập.\n2. Tầm Quan Trọng Của Hệ Thống Để AI hoạt động hiệu quả trong doanh nghiệp, thuật toán (Model) chỉ là một phần. Các yếu tố về Hạ tầng, Bảo mật và Quản trị (được cung cấp bởi Bedrock AgentCore) mới là nền tảng quyết định thành bại của dự án.\n3. Tiềm Năng Của Giao Diện Giọng Nói Công nghệ như Pipecat đang xóa nhòa ranh giới giao tiếp giữa người và máy, hứa hẹn sự bùng nổ của các ứng dụng trợ lý ảo tổng đài hay giáo dục trong tương lai gần.\nTổng Kết Chuỗi chuyên đề \u0026ldquo;Generative AI \u0026amp; Agentic AI\u0026rdquo; là bước đệm vững chắc kiến thức:\nHiện tại: Nắm vững Prompt Engineering và RAG. Tương lai: Hướng tới xây dựng các hệ thống Agentic AI thông minh. Công cụ: Tận dụng tối đa sức mạnh của AWS Cloud để hiện thực hóa ý tưởng. Một số hình ảnh khi tham gia sự kiện "
},
{
	"uri": "https://tuanvu250.github.io/FCJ-Report/vi/4-eventparticipated/4.5-event5/",
	"title": "Event 5",
	"tags": [],
	"description": "",
	"content": "Bài thu hoạch “AWS Cloud Mastery Series #2: Từ DevOps, IaC đến Container \u0026amp; Observability” Mục Đích Của Sự Kiện Định hình Tư duy DevOps: Hiểu đúng bản chất của DevOps trong việc tối ưu hóa Vòng Đời Giá Trị (The Value Cycle) và quy trình phát triển phần mềm. Làm chủ Hạ tầng (IaC): Chuyển đổi tư duy quản trị từ thủ công sang tự động hóa hoàn toàn với các công cụ như CloudFormation, Terraform và CDK. Chiến lược Container hóa: Nắm vững các tiêu chí lựa chọn nền tảng vận hành Container hiệu quả (EKS, ECS hay App Runner). Giám sát chuyên sâu (Observability): Thiết lập hệ thống giám sát chủ động để đảm bảo tính ổn định và khả năng phục hồi của dịch vụ. Danh Sách Diễn Giả Đội ngũ chuyên gia AWS \u0026amp; Cloud Engineers: Mang đến những kiến thức thực chiến và các Best Practices (Thực hành tốt nhất) trong ngành. Nội Dung Chi Tiết 1. DevOps Mindset \u0026amp; CI/CD Pipeline DevOps được định nghĩa lại không chỉ là một vị trí công việc, mà là văn hóa cộng tác nhằm luân chuyển giá trị đến khách hàng một cách nhanh nhất và an toàn nhất.\nThe Value Cycle (Vòng Đời Giá Trị): Quy trình khép kín từ ý tưởng (Insights) đến sản phẩm (Delivery). Mục tiêu tối thượng là cân bằng giữa Tốc độ phát hành (Speed) và Sự ổn định hệ thống (Stability). Giải mã CI/CD: Continuous Integration (CI): Tự động Build \u0026amp; Test mỗi khi có code mới để phát hiện lỗi sớm (Fail fast). Continuous Delivery: Sản phẩm luôn ở trạng thái sẵn sàng deploy (cần một cú click chuột để ra Production). Continuous Deployment: Tự động hóa 100% quy trình ra Production (nơi niềm tin vào quy trình test là tuyệt đối). Nguyên tắc \u0026ldquo;Immutable Artifact\u0026rdquo;: Đóng gói ứng dụng thành một bản Build (Artifact) duy nhất và dùng nó để deploy cho mọi môi trường (Staging, Prod), đảm bảo tính nhất quán tuyệt đối. 2. Infrastructure as Code (IaC) - Kỷ Nguyên Tự Động Hóa Loại bỏ hoàn toàn thói quen thao tác thủ công (ClickOps) tiềm ẩn nhiều rủi ro và sai sót.\nAWS CloudFormation: Giải pháp Native của AWS. Ổn định, hỗ trợ \u0026ldquo;Day-1\u0026rdquo; cho mọi tính năng mới. Sử dụng YAML/JSON. Terraform: Công cụ mã nguồn mở, thế mạnh về Multi-cloud. Sử dụng ngôn ngữ HCL. Quy trình Write -\u0026gt; Plan -\u0026gt; Apply giúp kiểm soát thay đổi một cách chặt chẽ trước khi áp dụng. AWS CDK: Dành cho Developer muốn dùng ngôn ngữ lập trình quen thuộc (Python, TS, Java\u0026hellip;) để định nghĩa hạ tầng. Khả năng tùy biến và tái sử dụng code cực cao. Drift Detection: Tính năng quan trọng giúp phát hiện sự sai lệch cấu hình (Configuration Drift) khi có sự can thiệp thủ công trái phép, giúp duy trì kỷ luật vận hành.\n3. Chiến Lược Containerization Lựa chọn nền tảng phù hợp cho Container:\nVề Điều phối (Orchestration): Amazon ECS: Đơn giản, tích hợp sâu với AWS, chi phí vận hành thấp. Phù hợp cho phần lớn các ứng dụng thông thường. Amazon EKS (Kubernetes): Mạnh mẽ, chuẩn mở, hệ sinh thái rộng lớn. Phù hợp cho các hệ thống phức tạp hoặc Enterprise hybrid-cloud. Về Hạ tầng tính toán (Compute): EC2: Tự quản lý server. Linh hoạt tối đa nhưng tốn công bảo trì (patching, scaling). AWS Fargate: Serverless cho Container. AWS lo hạ tầng, bạn chỉ cần lo chạy ứng dụng. AWS App Runner: Giải pháp PaaS đơn giản nhất (\u0026ldquo;Zero-ops\u0026rdquo;) để chạy Web App từ Source code. 4. Observability - Hơn Cả Monitoring Nếu Monitoring cho biết \u0026ldquo;Hệ thống có đang sống không?\u0026rdquo;, thì Observability trả lời câu hỏi \u0026ldquo;Tại sao nó chạy chậm?\u0026rdquo;.\nAmazon CloudWatch: Trung tâm thu thập Metrics, Logs và quản lý Cảnh báo (Alarms). AWS X-Ray (Tracing): Vẽ bản đồ đường đi của request qua các Microservices để tìm điểm nghẽn (Bottlenecks) và nguyên nhân gốc rễ. 3 Trụ Cột: Metrics (Số liệu) + Logs (Nhật ký) + Traces (Vết). Trải nghiệm chi tiết trong Event Buổi chia sẻ đã giúp tôi định hình lại tư duy của một Cloud Engineer thực thụ:\n1. Từ \u0026ldquo;Thợ gõ lệnh\u0026rdquo; sang \u0026ldquo;Kỹ sư nền tảng\u0026rdquo; Tôi nhận ra vai trò của DevOps hiện đại không phải là người \u0026ldquo;ôm việc\u0026rdquo; deploy, mà là người xây dựng Platform tự động giúp Developer có thể tự phục vụ (Self-service) nhu cầu hạ tầng một cách nhanh chóng và tuân thủ quy chuẩn.\n2. Kỷ luật là sức mạnh Việc tuân thủ nghiêm ngặt các nguyên tắc như IaC và Immutable Infrastructure là yếu tố sống còn để vận hành hệ thống quy mô lớn, giúp tránh khỏi những lỗi \u0026ldquo;chết người\u0026rdquo; do sai sót của con người.\n3. Sự lựa chọn thông minh Không có công cụ tốt nhất cho mọi trường hợp. Với dự án Startup cần tốc độ, CDK + App Runner là lựa chọn tuyệt vời. Với hệ thống Enterprise cần kiểm soát chặt chẽ, Terraform + EKS là hướng đi đúng đắn.\nTổng Kết Chuyên đề \u0026ldquo;DevOps \u0026amp; IaC\u0026rdquo; là hành trang kiến thức cốt lõi:\nTư duy: Tự động hóa là ưu tiên số 1. Kỹ năng: Thành thạo quy trình CI/CD và công cụ IaC. Vận hành: Luôn đặt Observability lên hàng đầu để làm chủ sức khỏe hệ thống. Một số hình ảnh khi tham gia sự kiện "
},
{
	"uri": "https://tuanvu250.github.io/FCJ-Report/vi/4-eventparticipated/4.6-event6/",
	"title": "Event 6",
	"tags": [],
	"description": "",
	"content": "Bài thu hoạch “AWS Cloud Mastery Series #3” Mục Đích Của Chuỗi Chuyên Đề Chuỗi sự kiện khép lại với chủ đề tối quan trọng: Bảo Mật và Vận Hành. Không chỉ dừng lại ở việc giới thiệu công cụ, chuyên đề hướng đến việc xây dựng tư duy bảo mật đa lớp (Defense in Depth) và khả năng vận hành tự động hóa trong môi trường Cloud-Native hiện đại.\nCác trụ cột chính:\nIdentity: Quản lý định danh và kiểm soát truy cập. Detection: Khả năng nhìn thấu và phát hiện mối đe dọa. Network: Thiết lập vành đai an ninh mạng lưới. Data Protection: Mã hóa và bảo vệ tài sản dữ liệu cốt lõi. Response: Quy trình phản ứng sự cố tốc độ cao. Danh Sách Diễn Giả Huynh Hoang Long, Dinh Le Hoang Anh - AWS Builders Tran Duc Anh, Nguyen Tuan Thinh, Nguyen Do Thanh Dat - Cloud Engineer Trainee FCJ Kha Van - Cloud Security Engineer, AWS Community Builders Thinh Lam, Viet Nguyen - FCJer Mendel Grabski (Long) - ex Head of Security \u0026amp; DevOps Cloud Security Solution Architect Tinh Truong - AWS Builders, Platform Engineer at TymeX Nội Dung Chi Tiết Phần 1: AWS Cloud Clubs - Ươm Mầm Tài Năng Cloud Giới thiệu về mạng lưới cộng đồng sinh viên AWS (Cloud Clubs), nơi mở ra cơ hội:\nHọc tập: Tiếp cận kho tài nguyên chính hãng và voucher thi chứng chỉ giá trị. Kết nối: Mở rộng network với các chuyên gia và diễn giả đầu ngành. Phát triển: Rèn luyện kỹ năng lãnh đạo thực chiến thông qua lộ trình \u0026ldquo;The Badging Journey\u0026rdquo;. Phần 2: Định Danh \u0026amp; Quản Trị (Identity \u0026amp; Governance) Bảo mật trên Cloud bắt đầu từ câu hỏi then chốt: \u0026ldquo;Ai được phép làm gì?\u0026rdquo;.\nTriết lý Zero Trust: Không tin bất cứ ai, xác thực mọi yêu cầu. IAM Best Practices: Chuyển dịch từ Long-term Credentials (Access Key vĩnh viễn) sang Short-term Credentials (STS Token tự hết hạn). Áp dụng triệt để nguyên tắc Least Privilege (Quyền tối thiểu). AWS Organizations: Quản lý tập trung hàng trăm tài khoản AWS. Sử dụng SCPs (Service Control Policies) để thiết lập các \u0026ldquo;vùng cấm\u0026rdquo; (Guardrails) nhằm ngăn chặn các hành vi nguy hiểm (như tắt CloudTrail) trên toàn tổ chức. Phần 3: Giám Sát \u0026amp; Phát Hiện (Visibility \u0026amp; Detection) Bạn không thể bảo vệ những gì bạn không nhìn thấy.\nAmazon GuardDuty: Hệ thống trinh sát thông minh ứng dụng Machine Learning để phát hiện hành vi bất thường từ CloudTrail, VPC Flow Logs và DNS Logs. AWS Security Hub: \u0026ldquo;Trung tâm chỉ huy\u0026rdquo; bảo mật, giúp hợp nhất cảnh báo từ nhiều nguồn về một dashboard duy nhất và tự động chấm điểm tuân thủ theo chuẩn quốc tế (CIS, PCI-DSS). Phần 4: Bảo Mật Mạng (Network Security) Xây dựng pháo đài số với chiến lược phòng thủ nhiều lớp:\nVPC Security Groups: Tường lửa mức Instance. Khuyến khích sử dụng kỹ thuật tham chiếu (SG Referencing) để quản lý luồng traffic linh hoạt thay vì whitelist IP cứng. AWS Network Firewall: Tường lửa thế hệ mới, có khả năng lọc sâu gói tin (Deep Packet Inspection) và chặn truy cập đến các tên miền độc hại. Route 53 Resolver DNS Firewall: Chốt chặn đầu tiên, ngăn chặn mã độc kết nối về máy chủ điều khiển (C2) ngay từ bước phân giải tên miền. Phần 5: Bảo Vệ Dữ Liệu (Data Protection) Dữ liệu là tài sản quý giá nhất cần được bảo vệ \u0026ldquo;trong két sắt\u0026rdquo;.\nMã Hóa (Encryption): Sử dụng AWS KMS với cơ chế mã hóa bao thư (Envelope Encryption) tối ưu hiệu năng và bảo mật. Quản Lý Bí Mật: Dùng AWS Secrets Manager để lưu trữ và tự động xoay vòng (Rotate) mật khẩu database, loại bỏ hoàn toàn rủi ro lộ mật khẩu do hardcode trong source code. AWS Nitro System: Công nghệ phần cứng tiên tiến giúp mã hóa dữ liệu tốc độ cao mà không làm ảnh hưởng hiệu năng server. Phần 6: Ứng Phó Sự Cố (Incident Response) Khi phòng thủ bị xuyên thủng, tốc độ phản ứng quyết định mức độ thiệt hại.\nChiến lược: Luôn chuẩn bị sẵn sàng Playbook và kịch bản ứng phó. Tự động hóa: Tận dụng EventBridge kích hoạt Lambda để tự động cô lập tài nguyên bị nhiễm (ví dụ: gỡ quyền IAM, cách ly Security Group) chỉ trong vài giây, nhanh hơn thao tác con người gấp nhiều lần. Kết Luận 1. \u0026ldquo;Security is Day 0\u0026rdquo; Tôi thấm nhuần tư duy rằng bảo mật không phải là tính năng bổ sung, mà phải được tích hợp ngay từ khâu thiết kế (Security by Design) của mọi hệ thống.\n2. Sức mạnh của Tự động hóa Trong cuộc đua với hacker, con người luôn chậm hơn máy móc. Việc áp dụng Automated Response là chìa khóa để giảm thiểu thiệt hại xuống mức thấp nhất.\n3. Tư duy phòng thủ chiều sâu Không có bức tường nào là bất khả xâm phạm. Việc kết hợp nhiều lớp bảo vệ (Identity + Network + Data + Monitoring) tạo nên hệ thống phòng thủ vững chắc (Defense in Depth) trước các mối đe dọa ngày càng tinh vi.\nTổng Kết Chuỗi sự kiện AWS Cloud Mastery đã trang bị cho tôi một hành trang toàn diện:\nTừ làm chủ công nghệ mới (GenAI, Container, IaC). Đến tư duy quản trị và bảo mật hệ thống bài bản (Security, Governance). Đây là nền tảng vững chắc để tôi tự tin bước tiếp trên con đường chinh phục các chứng chỉ AWS và trở thành một Cloud Engineer chuyên nghiệp. "
},
{
	"uri": "https://tuanvu250.github.io/FCJ-Report/vi/1-worklog/1.1-week1/",
	"title": "Worklog Tuần 1",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 1: Onboarding \u0026amp; Setup: Làm quen văn hóa FCJ, chuẩn bị môi trường (VS Code, Git, CLI) và thiết lập tài khoản AWS bảo mật (IAM, MFA). Networking Foundations: Nắm vững VPC, Subnet, Route Table, NAT Gateway và các thành phần mạng cốt lõi. Compute Services: Triển khai EC2, kết nối SSH, tìm hiểu về Global Infrastructure và các loại VM. Hybrid DNS \u0026amp; Connectivity: Thiết lập Route 53 Resolver cho môi trường Hybrid và cấu hình Site-to-Site VPN labs. Compute Deep Dive: Tìm hiểu sâu về Auto Scaling, EFS, FSx và các dịch vụ tính toán khác. Các công việc cần triển khai trong tuần này: Ngày Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 1 - Làm quen thành viên FCJ - Đọc và lưu ý nội quy/quy định - Chuẩn bị công cụ làm workshop (VS Code, Hugo, \u0026hellip;) - Giới thiệu về AWS \u0026amp; các khái niệm cơ bản 08/09/2025 08/09/2025 https://van-hoang-kha.github.io/vi/ 2 - Tạo mới tài khoản AWS - Kích hoạt MFA cho Tài khoản AWS - Tạo Admin Group và Admin User - Hỗ trợ Xác thực Tài khoản - Khám phá và cấu hình AWS Management Console - Tạo và Quản Lý Các Trường Hợp Hỗ Trợ trong AWS 09/09/2025 09/09/2025 https://000001.awsstudygroup.com/vi/ 3 - Các dịch vụ mạng trên AWS: + VPC, Subnet, Route Table + Internet Gateway, NAT Gateway + Security Group \u0026amp; NACL + VPC Peering, Transit Gateway (khái niệm) + Elastic Load Balancing, Route 53 (DNS) 10/09/2025 10/09/2025 https://github.com/tuanvu250/AWS-FCJ/blob/main/module/module-02/note.md 4 - Thực hành EC2: + Tạo EC2 instance + Kết nối SSH + Cấu hình Site to Site VPN 11/09/2025 11/09/2025 https://000003.awsstudygroup.com/ 5 - Thiết lập Hybrid DNS với Route 53 Resolver: + Kết nối đến RDGW + Triển khai Microsoft AD + Thiết lập DNS 12/09/2025 12/09/2025 https://000010.awsstudygroup.com/ 6 - Thiết lập VPC Peering + Tạo kết nối Peering giữa VPCs + Cập nhật Route tables và kiểm thử kết nối - Dịch vụ Compute VM trên AWS - Amazon Elastic Compute Cloud (EC2) - EC2 Auto Scaling - EFS/FSx - Lightsail - MGN - Tìm hiểu AWS Global Infrastructure 13/09/2025 13/09/2025 https://000019.awsstudygroup.com/ https://github.com/tuanvu250/AWS-FCJ/blob/main/module/module-03/note.md Kết quả đạt được tuần 1: Environment Ready: Hoàn tất setup công cụ, tài khoản AWS an toàn với Admin Group và MFA. Network Deployed: Triển khai thành công VPC, Subnets, Security Groups và hiểu rõ luồng mạng. Compute Launched: Tạo và kết nối thành công EC2 instance, nắm vững các tùy chọn hình thức mua. Hybrid Connectivity: Cấu hình thành công DNS Resolver và VPN cho mô hình lai. Knowledge Base: Ghi chú đầy đủ về Global Infa, Region, AZ và các dịch vụ Compute mở rộng. "
},
{
	"uri": "https://tuanvu250.github.io/FCJ-Report/vi/1-worklog/1.2-week2/",
	"title": "Worklog Tuần 2",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 2: Advanced Networking: Triển khai AWS Transit Gateway để quản lý routing giữa nhiều VPC. Storage Solutions: Thực hành sâu với FSx for Windows và Storage Gateway cho môi trường Hybrid. Data Protection: Thiết lập chiến lược AWS Backup tự động cho các tài nguyên. S3 Mastery: Làm chủ Amazon S3 (Static Web, CloudFront, Versioning, Replication). Compute Optimization: Tối ưu chi phí và hiệu năng với EC2 Instance Types và Purchasing Options. Các công việc cần triển khai trong tuần này: Ngày Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 1 - Thực hành AWS Transit Gateway: + Tạo Transit Gateway + Tạo Transit Gateway Attachments + Tạo Transit Gateway Route Tables + Thêm Transit Gateway Routes vào VPC Route Tables 15/09/2025 15/09/2025 https://000020.awsstudygroup.com/ 2 - Thực hành triển khai FSx trên Windows: + Tạo một SSD và một HDD Multi-AZ file system + Tạo File Sharesm, kiểm tra và giám sát hiệu năng + Kích hoạt chống dữ liệu trùng lặp và shadow copies + Kích hoạt ngạch bộ nhớ và chia sẻ truy cập liên tục cùng khả năng mở rộng thông lượng và dung lượng lưu trữ; 16/09/2025 16/09/2025 https://000025.awsstudygroup.com/vi/ 3 - Thực hành triển khai AWS Backup cho hệ thống: + Tạo S3 Bucket \u0026amp; triển khai hạ tầng + Tạo Backup plan, thiết lập thông báo + Kiểm tra hoạt động 17/09/2025 17/09/2025 https://000013.awsstudygroup.com/vi/ 4 - Tham dự event Vietnam Cloud Day 2025 : Ho Chi Minh City Connect Edition for Builders (Track 1: GenAI \u0026amp; Data) - Tìm hiểu EC2 Instance Types \u0026amp; Purchasing Options 18/09/2025 18/09/2025 https://pages.awscloud.com/vietnam-cloud-day-hcmc-connect-edition https://000051.awsstudygroup.com/vi/ 5 - Thực hành triển khai AWS Storage Gateway: + Tạo S3 Bucket \u0026amp; EC2 cho Storage Gateway + Tạo Storage Gateway và File Shares + Kết nối File shares ở máy On-premise 18/09/2025 18/09/2025 https://000024.awsstudygroup.com/vi/ 6 - Thực hành Khởi Đầu Với Amazon S3: + Tạo S3 bucket và tải dữ liệu web mẫu + Bật tính năng static website và kiểm tra + Tăng tốc Static Website với Cloudfront + Bucket Versioning và chuyển S3 Object sang region khác 20/09/2025 20/09/2025 https://000057.awsstudygroup.com/vi/ Kết quả đạt được tuần 2: Network Hub: Cấu hình thành công Transit Gateway để trung chuyển lưu lượng liên VPC. Hybrid Storage: Triển khai FSx và Storage Gateway, kết nối thành công từ On-premise. Robust Backup: Hệ thống backup tự động bằng AWS Backup đã hoạt động ổn định. S3 \u0026amp; CDN: Website tĩnh trên S3 tích hợp CloudFront và Replication đã sẵn sàng. Cost Efficiency: Nắm vững chiến lược chọn EC2 instance và gói mua để tối ưu chi phí. "
},
{
	"uri": "https://tuanvu250.github.io/FCJ-Report/vi/1-worklog/1.3-week3/",
	"title": "Worklog Tuần 3",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 3: Advanced Storage: Thành thạo Amazon S3 (Classes, Lifecycle, Access Points, Glacier) và các tính năng bảo mật. Data Migration: Nắm vững giải pháp dịch chuyển dữ liệu với Snow Family và Storage Gateway. VM Import/Export: Thực hành di chuyển máy ảo On-premise lên AWS và ngược lại với VM Import/Export. Resource Optimization: Tối ưu hóa chi phí EC2 bằng Lambda và quản lý tài nguyên hiệu quả với Tags/Resource Groups. Backup Strategy: Triển khai chiến lược sao lưu toàn diện cho hệ thống với AWS Backup. Các công việc cần triển khai trong tuần này: Ngày Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 1 - Dịch vụ lưu trữ trên AWS: + Amazon Simple Storage Service ( S3 ) + Access Point + Storage Class + S3 Static Website \u0026amp; CORS 22/09/2025 22/09/2025 https://github.com/tuanvu250/AWS-FCJ/blob/main/module/module-04/note.md 2 - Dịch vụ lưu trữ trên AWS: + Control Access + Object Key \u0026amp; Performance + Glacier + Snow Family - Storage Gateway - Backup 23/09/2025 23/09/2025 https://github.com/tuanvu250/AWS-FCJ/blob/main/module/module-04/note.md 3 - Thực hành triển khai AWS Backup cho hệ thống: + Tạo S3 Bucket \u0026amp; triển khai hạ tầng + Tạo Backup plan, thiết lập thông báo + Kiểm tra hoạt động 24/09/2025 24/09/2025 https://000013.awsstudygroup.com/vi/ 4 - Thực hành về VM Import/Export: + Import máy ảo vào AWS + Triển khai EC2 Instance từ AMI + Export EC2 Instance từ AWS 24/09/2025 24/09/2025 https://000014.awsstudygroup.com/vi/ 5 - Thực hành tối ưu chi phí EC2 với Lambda: + Tạo Tag cho Instance \u0026amp; Tạo Role cho Lambda + Tạo Lambda Function \u0026amp; kiểm tra kết quả - Quản lý tài nguyên bằng Tag và Resource Groups - Quản lý truy cập vào dịch vụ EC2 Resource Tag với AWS IAM - Giới hạn quyền của user với IAM Permission Boundary - Tìm hiểu S3 Lifecycle Policies \u0026amp; Intelligent-Tiering 26/09/2025 26/09/2025 https://000022.awsstudygroup.com/vi/ https://000027.awsstudygroup.com/vi/ https://000028.awsstudygroup.com/vi/ https://000030.awsstudygroup.com/vi/ 6 - Thực hành Khởi Đầu Với Amazon S3: + Tạo S3 bucket và tải dữ liệu web mẫu + Bật tính năng static website và kiểm tra + Tăng tốc Static Website với Cloudfront + Bucket Versioning và chuyển S3 Object sang region khác 27/09/2025 27/09/2025 https://000057.awsstudygroup.com/vi/ Kết quả đạt được tuần 3: Storage Expert: Hiểu sâu về các lớp lưu trữ S3, chính sách vòng đời và Intelligent-Tiering để tối ưu chi phí. Migration Ready: Nắm rõ quy trình sử dụng Snow Family và Storage Gateway cho các kịch bản di chuyển dữ liệu lớn. VM Mobility: Thành công import/export máy ảo và triển khai EC2 từ AMI tùy chỉnh. Cost Savings: Tự động hóa việc gắn thẻ và tắt/bật instance bằng Lambda để tiết kiệm chi phí. Governance: Quản lý truy cập và tài nguyên chặt chẽ thông qua Tag, Resource Groups và IAM Permission Boundaries. "
},
{
	"uri": "https://tuanvu250.github.io/FCJ-Report/vi/1-worklog/1.4-week4/",
	"title": "Worklog Tuần 4",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 4: Security Core: Nắm vững Shared Responsibility Model và quản lý định danh với IAM, Cognito, Organizations. Database Services: Làm chủ các dịch vụ cơ sở dữ liệu RDS, Aurora, Redshift và ElastiCache. Data Encryption: Thực hành mã hóa dữ liệu toàn diện với AWS KMS tích hợp S3 và CloudTrail. App Protection: Tìm hiểu các lớp bảo vệ ứng dụng web với AWS WAF, Shield và Security Hub. Access Control: Triển khai kiểm soát truy cập mịn với IAM Role và Conditions. Các công việc cần triển khai trong tuần này: Ngày Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 1 - Dịch vụ bảo mật trên AWS: + Share Responsibility Model + AWS Identity and Access Management + Amazon Cognito + AWS Organizations + Amazon Key Management Service 29/09/2025 29/09/2025 https://github.com/tuanvu250/AWS-FCJ/blob/main/module/module-05/note.md 2 -Thực hành bắt đầu với AWS Security Hub: + Kích hoạt Security Hub \u0026amp; điểm từng bộ tiêu chuẩn - Tìm hiểu AWS Shield \u0026amp; AWS WAF 30/09/2025 30/09/2025 https://000018.awsstudygroup.com/vi/ https://000053.awsstudygroup.com/vi/ 3 - Dịch vụ cơ sở dữ liệu trên AWS: + Amazon RDS \u0026amp; Amazon Aurora + Redshift - Elasticache 01/10/2025 01/10/2025 https://github.com/tuanvu250/AWS-FCJ/blob/main/module/module-05/note.md 4 - Thực hành Mã hóa ở trạng thái lưu trữ với AWS KMS: + Tạo Key Management Service \u0026amp; Amazon S3 + Tạo AWS CloudTrail \u0026amp; Amazon Athena + Kiểm thử và chia sẻ dữ liệu mã hóa trên S3 - Thực hành IAM Role \u0026amp; Condition 02/10/2025 02/10/2025 https://000033.awsstudygroup.com/vi/ https://000044.awsstudygroup.com/vi/ 5 - Sự kiện [AWS GenAI Builder Club] AI-Driven Development Life Cycle: Reimagining Software Engineering (2pm Friday 3/10/2025) 03/10/2025 03/10/2025 6 - Thực hành Cấp quyền cho ứng dụng truy cập dịch vụ AWS với IAM Role - Dịch vụ cơ sở dữ liệu trên AWS: Database Concepts review 04/10/2025 04/10/2025 https://000048.awsstudygroup.com/ https://github.com/tuanvu250/AWS-FCJ/blob/main/module/module-06/note.md Kết quả đạt được tuần 4: Security Proficiency: Hiểu rõ mô hình chia sẻ trách nhiệm và cấu hình IAM/Cognito an toàn. Database Mastery: Phân biệt và lựa chọn đúng dịch vụ DB (SQL/NoSQL/In-memory) cho từng use case. Encryption Lab: Mã hóa dữ liệu thành công với KMS và kiểm toán truy cập qua CloudTrail/Athena. Threat Protection: Kích hoạt và đánh giá điểm bảo mật với Security Hub, hiểu rõ cơ chế của WAF/Shield. Granular Access: Cấp quyền truy cập chính xác cho ứng dụng và user thông qua các điều kiện IAM phức tạp. "
},
{
	"uri": "https://tuanvu250.github.io/FCJ-Report/vi/1-worklog/1.5-week5/",
	"title": "Worklog Tuần 5",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 5: Containerization: Nắm vững Docker, Docker Compose và triển khai ứng dụng container trên AWS ECS. Data Lake Architecture: Xây dựng Data Lake hoàn chỉnh với S3, AWS Glue (Catalog) và Athena (Analytics). NoSQL Deep Dive: Thực hành chuyên sâu với Amazon DynamoDB (Partition/Sort Key, GSI/LSI). DB Comparison: So sánh chi tiết kiến trúc và hiệu năng giữa Amazon RDS và Amazon Aurora. Analytics Optimization: Tối ưu hóa chi phí và hiệu năng truy vấn dữ liệu lớn. Các công việc cần triển khai trong tuần này: Ngày Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 1 - Tìm hiểu về docker, docker-compose - So sánh Amazon RDS vs Amazon Aurora 06/10/2025 06/10/2025 https://github.com/tuanvu250/AWS-FCJ/tree/main/bonus/docker https://docs.docker.com/get-started/ https://000054.awsstudygroup.com/vi/ 2 -Thực hành Triển khai ứng dụng trên Docker với AWS - Thực hành Triển khai ứng dụng trên Amazon Elastic Container Service - Thực hành DataLake on AWS + Thu thập và lưu trữ dữ liệu + Tạo Data Catalog (Amazon Glue)\n+ Phân tích và trực quan hóa (Amazon Athena) 07/10/2025 07/10/2025 https://000015.awsstudygroup.com/vi/ https://000016.awsstudygroup.com/vi/ https://000005.awsstudygroup.com/vi/ https://000035.awsstudygroup.com/vi/ 3 - Thực hành Amazon DynamoDB Immersion Day 08/10/2025 08/10/2025 https://000039.awsstudygroup.com/vi/ 4 - Thực hành Amazon DynamoDB Immersion Day 09/10/2025 09/10/2025 https://000039.awsstudygroup.com/vi/ 5 - Thực hành Phân tích chi phí và hiệu năng sử dụng với AWS Glue và Amazon Athena - Thực hành Làm việc với Amazon DynamoDB 10/10/2025 10/10/2025 https://000040.awsstudygroup.com/vi/ https://000060.awsstudygroup.com/vi/ 6 - Thực hành Xây dựng Datalake với dữ liệu của bạn 11/10/2025 11/10/2025 https://000070.awsstudygroup.com/vi/ Kết quả đạt được tuần 5: Container Ops: Đóng gói, quản lý Docker images trên ECR và vận hành cụm ECS thành công. Data Lake Live: Hệ thống thu thập, lưu trữ và phân tích dữ liệu serverless đã đi vào hoạt động. DynamoDB Pro: Thiết kế bảng NoSQL hiệu quả, hiểu rõ mô hình dữ liệu và các chỉ số hiệu năng. DB Architecture: Phân tích rõ ràng ưu nhược điểm của RDS vs Aurora để ra quyết định lựa chọn. Cost Effective: Áp dụng các kỹ thuật tối ưu hóa partition và query để giảm chi phí phân tích dữ liệu. "
},
{
	"uri": "https://tuanvu250.github.io/FCJ-Report/vi/1-worklog/1.6-week6/",
	"title": "Worklog Tuần 6",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 6: Tìm hiểu về Nginx (reverse proxy, load balancing) và tham gia workshop \u0026ldquo;DATA SCIENCE ON AWS\u0026rdquo;. Thực hành Serverless Architecture (API Gateway, Lambda, SAM) và Amazon Cognito (xác thực, phân quyền). Triển khai S3 Static Website với SSL, Microservices, và Single Page Application (SPA). Xây dựng CI/CD Pipeline với AWS Developer Tools, cấu hình Github Actions và tìm hiểu Container Security. Thực hành Amazon Kinesis (streaming data) và tối ưu hóa cơ cấu dữ liệu. Các công việc cần triển khai trong tuần này: Ngày Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 1 - Thực hành deploy stactic website lên AWS và cấu hình Github Actions với AWS IAM User - Thực hành cấu hình tự động phát hành ứng dụng (AWS CodeStar, AWS CodePipeline, AWS CodeBuild, AWS CodeDeploy) 13/10/2025 13/10/2025 https://www.youtube.com/watch?v=oSZ0tzlkuWo https://000051.awsstudygroup.com/vi/ 2 - Thực hành CI/CD Pipeline: tự động hóa quy trình build, test và deploy - Thực hành cơ cấu lại dữ liệu và quy trình làm việc 14/10/2025 14/10/2025 https://000051.awsstudygroup.com/vi/ https://000053.awsstudygroup.com/vi/ 3 - Tìm hiểu về Nginx - Thực hành truyền thông tin với Kinesis 15/10/2025 15/10/2025 https://github.com/tuanvu250/AWS-FCJ/tree/main/bonus/nginx https://000054.awsstudygroup.com/vi/ 4 - WORKSHOP “DATA SCIENCE ON AWS” – MỞ KHÓA SỨC MẠNH DỮ LIỆU CÙNG ĐIỆN TOÁN ĐÁM MÂY - Chuyển đổi Monolith sang Microservices \u0026amp; Tạo Microservice - Xây dựng SPA với xác thực - Container Security Best Practices 16/10/2025 16/10/2025 https://qhdn-hcmuni.fpt.edu.vn/2025/10/13/workshop-data-science-on-aws-mo-khoa-suc-manh-du-lieu-cung-dien-toan-dam-may/ https://000050.awsstudygroup.com/vi/ https://000055.awsstudygroup.com/vi/ 5 - Serverless - Hướng dẫn viết Front-end gọi API Gateway - Serverless - Triển khai ứng dụng trên SAM 17/10/2025 17/10/2025 https://000079.awsstudygroup.com/vi/ https://000080.awsstudygroup.com/vi/ 6 - Serverless - Xác thực với Amazon Cognito - Serverless - Thiết lập trang web SSL S3 Static 18/10/2025 18/10/2025 https://000081.awsstudygroup.com/vi/ https://000082.awsstudygroup.com/vi/ Kết quả đạt được tuần 6: Học thành công về Nginx (reverse proxy, load balancing) và tham gia workshop \u0026ldquo;DATA SCIENCE ON AWS\u0026rdquo; để mở rộng kiến thức dữ liệu. Thực hành thành công CI/CD Pipeline với AWS Developer Tools, tự động hóa quy trình build/test/deploy và cấu hình Github Actions. Hoàn thành các lab Serverless Architecture (API Gateway, Lambda, SAM), Amazon Cognito (Authentication) và S3 Static Website (SSL). Chuyển đổi thành công ứng dụng Monolith sang Microservices, xây dựng Single Page Application (SPA) và tìm hiểu Container Security. Thiết lập Amazon Kinesis xử lý dữ liệu realtime và hoàn thành cơ cấu lại dữ liệu để tối ưu hóa hiệu suất. "
},
{
	"uri": "https://tuanvu250.github.io/FCJ-Report/vi/1-worklog/1.7-week7/",
	"title": "Worklog Tuần 7",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 7: AWS Cloud Practitioner Study: Ôn tập kiến thức nền tảng theo lộ trình kananinirav.com. Cloud Computing \u0026amp; IAM: Nắm vững các khái niệm điện toán đám mây và quản lý truy cập (Users, Groups, Roles). Compute \u0026amp; Storage Services: Tìm hiểu sâu về EC2, EBS, S3, EFS và các mô hình lưu trữ. Networking \u0026amp; Global Infrastructure: Hiểu rõ kiến trúc VPC, Regions, AZs và Edge Locations. Databases \u0026amp; Security: Khám phá các dịch vụ CSDL (RDS, DynamoDB) và mô hình bảo mật chia sẻ (Shared Responsibility Model). Các công việc cần triển khai trong tuần này: Ngày Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 1 - Cloud Computing: Nghiên cứu sâu về các mô hình điện toán đám mây (IaaS, PaaS, SaaS) và lợi ích cốt lõi của AWS. - IAM: Thực hành tạo và quản lý Users, Groups, Roles; áp dụng chính sách bảo mật (IAM Policies) và MFA. - EC2: Phân tích chi tiết các loại Instance (General Purpose, Compute Optimized,\u0026hellip;) và các mô hình Pricing (On-Demand, Spot, Reserved). 20/10/2025 20/10/2025 Cloud Computing IAM EC2 2 - EC2 Storage: So sánh sự khác biệt giữa EBS, Instance Store và EFS; thực hành mount EFS vào nhiều instance. - ELB \u0026amp; ASG: Cấu hình Elastic Load Balancer (ELB) để phân tải và Auto Scaling Group (ASG) để tự động co giãn tài nguyên. 21/10/2025 21/10/2025 EC2 Storage ELB \u0026amp; ASG 3 - S3: Tìm hiểu các Storage Classes (Standard, IA, Glacier), cấu hình Versioning và thiết lập Lifecycle Policies để tối ưu chi phí. - Databases: Tổng quan về các dịch vụ cơ sở dữ liệu được quản lý: RDS (SQL), DynamoDB (NoSQL), ElastiCache và Redshift. 22/10/2025 22/10/2025 S3 Databases 4 - Deploying: Tìm hiểu quy trình Infrastructure as Code với CloudFormation và quản lý ứng dụng với Elastic Beanstalk. - Global Infrastructure: Nắm vững khái niệm Regions, Availability Zones (AZs) và Edge Locations để thiết kế hệ thống có tính sẵn sàng cao. 23/10/2025 23/10/2025 Deploying Global Infrastructure 5 - Cloud Integration: Tích hợp ứng dụng lỏng lẻo (loose coupling) sử dụng SQS (Message Queue) và SNS (Notification). - Cloud Monitoring: Giám sát metrics hệ thống với CloudWatch, theo dõi nhật ký hoạt động user với CloudTrail và quản lý cấu hình với AWS Config. 24/10/2025 24/10/2025 Cloud Integration Cloud Monitoring 6 - VPC: Thiết kế mạng ảo Private Cloud gồm Subnets, Route Tables, Security Groups và NACLs để kiểm soát lưu lượng mạng. - Security \u0026amp; Compliance: Hiểu rõ Mô hình Trách nhiệm Chia sẻ (Shared Responsibility Model), sử dụng Inspector để đánh giá bảo mật và Shield để chống DDoS. 25/10/2025 25/10/2025 VPC Security Compliance Kết quả đạt được tuần 7: Kiến thức nền tảng vững chắc: Hoàn thành toàn bộ lộ trình AWS Cloud Practitioner (Cloud Computing, IAM, Billing). Core Services Mastery: Hiểu sâu và vận dụng tốt các dịch vụ Compute (EC2) và Storage (S3, EBS). Networking Competence: Nắm vững kiến trúc mạng trong AWS (VPC, Subnets, Security Groups). Security \u0026amp; Compliance: Hiểu rõ mô hình chia sẻ trách nhiệm và các tiêu chuẩn bảo mật đám mây. Deployment \u0026amp; Monitoring: Làm quen với các công cụ triển khai (CloudFormation) và giám sát (CloudWatch). "
},
{
	"uri": "https://tuanvu250.github.io/FCJ-Report/vi/1-worklog/1.8-week8/",
	"title": "Worklog Tuần 8",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 8: AWS Cloud Practitioner Study: Hoàn tất các module cuối cùng và ôn tập toàn diện. Account Management \u0026amp; Security: Tìm hiểu về Billing, Cost Explorer, Organizations và các dịch vụ định danh nâng cao. Architecture \u0026amp; Ecosystem: Nắm vững Well-Architected Framework và Cloud Adoption Framework. Exam Preparation: Luyện đề, thi thử và hoàn thành kỳ thi giữa kỳ. Project Kickoff: Thống nhất yêu cầu, công nghệ và khởi động dự án chính thức. Các công việc cần triển khai trong tuần này: Ngày Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 1 - Account Management: Cấu hình AWS Organizations để quản lý đa tài khoản, thiết lập Billing dashboard và Cost Explorer để quản lý chi phí. - Advanced Identity: Tìm hiểu về Amazon Cognito cho xác thực ứng dụng và AWS SSO cho đăng nhập một lần. 27/10/2025 27/10/2025 Account Management Advanced Identity 2 - Other AWS Services: Khám phá các dịch vụ khác như Amazon WorkSpaces (VDI), Amazon Connect (Contact Center) và Amazon Chime. 28/10/2025 28/10/2025 Other AWS Services 3 - Architecting \u0026amp; Ecosystem: Nghiên cứu sâu Well-Architected Framework (6 pillars) và Cloud Adoption Framework (CAF) để chuẩn hóa quy trình thiết kế. 29/10/2025 29/10/2025 Architecting 4 - Review \u0026amp; Self-study: Hệ thống hóa lại toàn bộ kiến thức đã học, Thực hiện các bài thi thử trên AWS Skill Builder. 30/10/2025 30/10/2025 Practice Exam 5 - Practice Exam \u0026amp; Mid-term Exam: Thực hiện các bài thi thử full-test (65 câu hỏi) để quản lý thời gian và hoàn thành kỳ thi giữa kỳ bắt buộc. 31/10/2025 31/10/2025 Practice Exam 6 - Project Kickoff: Tổ chức buổi họp khởi động dự án chính thức. Thống nhất yêu cầu nghiệp vụ (SRS), lựa chọn Technology Stack và lập kế hoạch chi tiết (Gantt chart). - Tính toán chi phí của hệ thống 01/11/2025 01/11/2025 https://gitlab.com/vicobi/vicobi-docs Kết quả đạt được tuần 8: AWS Certified Cloud Practitioner: Hoàn thành toàn bộ nội dung khóa học và sẵn sàng 100% cho kỳ thi. Mid-term Exam: Hoàn thành kỳ thi giữa kỳ với kết quả tốt, nắm vững kiến thức nền tảng. Architecture Proficiency: Hiểu rõ Well-Architected Framework để thiết kế hệ thống tối ưu. Advanced Tools Mastery: Sử dụng thành thạo các công cụ quản lý tài khoản và bảo mật nâng cao. Project Readiness: Dự án chính thức khởi động với sự thống nhất cao về công nghệ và quy trình. "
},
{
	"uri": "https://tuanvu250.github.io/FCJ-Report/vi/1-worklog/1.9-week9/",
	"title": "Worklog Tuần 9",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 9: Project Initialization: Khởi tạo dự án Next.js 16, React 19, TypeScript và cấu hình ESLint, Husky. Design System Setup: Thiết lập hệ thống thiết kế Neobrutalism, cài đặt Tailwind CSS và Shadcn UI. Authentication Flow: Tích hợp AWS Cognito, xây dựng trang Login/Register với Zod validation. Dashboard Development: Xây dựng layout responsive cho User/Admin và các thành phần giao diện chính. State Management \u0026amp; API: Cấu hình Axios client, Redux/Zustand store và tích hợp React Query. Repository: https://gitlab.com/vicobi/vicobi-frontend Các công việc cần triển khai trong tuần này: Ngày Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 1 - Project Setup: Khởi tạo dự án với Next.js 16.0.1 (App Router), React 19 và TypeScript. - Dev Tools: Cấu hình quy trình Git hook với Husky, kiểm soát commit message với Commitlint và thiết lập ESLint/Prettier chuẩn. 03/11/2025 03/11/2025 Next.js 16, Husky 2 - Design System Setup: Cài đặt Tailwind CSS và cấu hình Design Tokens cho phong cách Neobrutalism (đậm nét, shadow cứng). Tùy biến Shadcn UI components và cài thêm Framer Motion cho animation. 04/11/2025 04/11/2025 Framer Motion 3 - Authentication Flow: Tích hợp AWS Cognito Identity Provider. Xây dựng form Login/Register/Forgot Password sử dụng React Hook Form kết hợp Zod validation. Kết nối authService. 05/11/2025 05/11/2025 AWS Cognito 4 - Dashboard Layout: Xây dựng Layout riêng biệt cho Group Route (member) và (admin). Implement Sidebar navigation responsive hoàn chỉnh và Widget hệ thống style Neobrutalist. 06/11/2025 06/11/2025 5 - API Client \u0026amp; Store: Thiết lập Axios Interceptor (lib/api/core.ts) để tự động gắn Token và refresh token. Cấu hình Global State với Zustand (authStore) và tích hợp React Query (apiStore). 07/11/2025 07/11/2025 Zustand 6 - Wallet Management Start: Phân tích API swagger, implement fetchWallet service và custom hook useWallet. Xây dựng UI danh sách ví và modal tạo ví mới. - Weekly Review: Review lại cấu trúc thư mục và convention code. 08/11/2025 08/11/2025 Kết quả đạt được tuần 9: Development Environment: Khởi tạo thành công dự án Next.js 16/React 19, cấu hình ESLint/Prettier chuẩn chỉ. Neobrutalism Design System: Hệ thống UI components, typography và màu sắc đã được thiết lập đồng bộ. Authentication System: Hoàn thiện luồng đăng ký/đăng nhập với AWS Cognito và form validation chặt chẽ. Dashboard UI: Giao diện Dashboard responsive cho Admin và User đã hoạt động. Foundation Layer: Cấu hình xong API Client (Axios) và State Management (Zustand/TanStack Query). "
},
{
	"uri": "https://tuanvu250.github.io/FCJ-Report/vi/1-worklog/1.10-week10/",
	"title": "Worklog Tuần 10",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 10: Wallet Management: Hoàn thiện tính năng đa ví, hiển thị biểu đồ thống kê tài sản. Jar System Implementation: Xây dựng backend/frontend cho hệ thống hũ (6 Jars System). Budget Allocation Logic: Phát triển logic phân bổ ngân sách và validate dữ liệu đầu vào. Transaction Features: Tạo form thêm giao dịch, danh sách lịch sử và bộ lọc tìm kiếm. AI Service Integration: Kết nối API AI và triển khai tính năng nhập liệu bằng giọng nói (Voice-to-Transaction). Repository: https://gitlab.com/vicobi/vicobi-frontend Các công việc cần triển khai trong tuần này: Ngày Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 1 - Wallet Management (Finish): Hoàn thiện logic tính toán tổng tài sản, xử lý loading state/skeleton và hiển thị biểu đồ phân bổ tài sản (Pie Chart). - Jar System: Tạo components/jars, xây dựng fetchJars service. Thực hiện full CRUD cho hệ thống 6 hũ tài chính. 10/11/2025 10/11/2025 2 - Budget Allocation: Xây dựng giao diện Drag \u0026amp; Drop hoặc Slider để phân bổ ngân sách vào hũ. Implement logic validate tổng 100% với Zod schema. 11/11/2025 11/11/2025 3 - Transaction Creation: Xây dựng form thêm giao dịch mới (components/transactions) phức tạp: chọn ví, chọn hũ, chọn category, ngày tháng và ghi chú. Custom Select component để tối ưu UX. 12/11/2025 12/11/2025 date-fns 4 - Transaction History \u0026amp; Filters: Hiển thị danh sách lịch sử giao dịch với tính năng Infinite Scroll hoặc Pagination (React Query). Xây dựng bộ lọc nâng cao (theo ngày, theo ví, theo loại). 13/11/2025 13/11/2025 TanStack Query 5 - Unit Testing: Viết unit tests coverage cao cho các business logic quan trọng trong useWallet và useJars hooks sử dụng Jest/Vitest. 14/11/2025 14/11/2025 6 - AI Service \u0026amp; Voice Input: Implement useAIService kết nối OpenAI/Gemini API. Xây dựng giao diện ghi âm, xử lý chuyển đổi Speech-to-Text và mapping dữ liệu vào form transaction. - Tham gia AWS Cloud Mastery Series #1: GENERATIVE AI, RAG \u0026amp; AWS AGENTIC AI 15/11/2025 15/11/2025 Kết quả đạt được tuần 10: Wallet Management Complete: Hoàn thành CRUD ví, hiển thị thông tin số dư và biểu đồ trực quan. Jar System Operational: Hệ thống 6 hũ (6 Jars) đã hoạt động với đầy đủ chức năng quản lý. Budget Logic Implemented: Thuật toán phân bổ ngân sách tự động vào các hũ hoạt động chính xác. Transaction Flow: Tạo mới, xem danh sách và lọc giao dịch đã hoàn thiện. AI Integration Live: Tính năng nhập liệu bằng giọng nói và gợi ý phân loại giao dịch đã được tích hợp. "
},
{
	"uri": "https://tuanvu250.github.io/FCJ-Report/vi/1-worklog/1.11-week11/",
	"title": "Worklog Tuần 11",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 11: Hoàn thiện các tính năng AI: Bill Scanning, Categorization, Analytics. Xây dựng Chatbot và trang Quản lý Chatbot. Tối ưu hóa Mobile-First. Repository: https://gitlab.com/vicobi/vicobi-frontend Các công việc cần triển khai trong tuần này: Ngày Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 1 - Bill Scanning (OCR): Sử dụng AI API để upload và phân tích ảnh hóa đơn. Trích xuất thông tin: Ngày, Tổng tiền, Tên sản phẩm. - Tham gia AWS Cloud Mastery Series #2: Từ DevOps, IaC đến Container \u0026amp; Observability 17/11/2025 17/11/2025 2 - AI Categorization \u0026amp; Suggestions: Xây dựng logic để tự động mapping tên giao dịch sang category tương ứng. Hiển thị UI gợi ý cho người dùng xác nhận hoặc sửa đổi. 18/11/2025 18/11/2025 3 - Statistics \u0026amp; History: Xây dựng chức năng hiển thị số liệu thống kê chi tiết (hàng ngày, tuần, tháng, năm) và lịch sử giao dịch tổng hợp cho từng Ví và Hũ. 19/11/2025 19/11/2025 4 - Chatbot Page: Xây dựng giao diện chat (/services/chatbot) với layout giống ChatGPT. Tích hợp stream response từ API askChatbot và hiển thị markdown message. 20/11/2025 20/11/2025 5 - Chatbot Management: Xây dựng module quản lý Knowledge Base (/services/chatbot-management). Cho phép Admin upload PDF/Docx để training chatbot và xóa file context cũ. 21/11/2025 21/11/2025 6 - Mobile Optimization: Tinh chỉnh lại toàn bộ CSS cho thiết bị di động (Mobile-first). Tăng kích thước nút bấm (touch targets), tối ưu layout drawer/modal và kiểm tra hiển thị trên thiết bị thật. 22/11/2025 22/11/2025 Kết quả đạt được tuần 11: AI \u0026amp; Chatbot: Hoàn thiện toàn bộ tính năng thông minh và trợ lý ảo. Mobile Ready: Ứng dụng hoạt động mượt mà trên thiết bị di động. Analytics: Báo cáo trực quan, giúp người dùng nắm bắt tình hình tài chính. "
},
{
	"uri": "https://tuanvu250.github.io/FCJ-Report/vi/1-worklog/1.12-week12/",
	"title": "Worklog Tuần 12",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 12: Production Deployment: Triển khai lên AWS S3 + CloudFront. Docker Deployment: Kiểm thử deploy với Docker. Quality Assurance: UAT, Security Audit, Documentation và Final Polish. Các công việc cần triển khai trong tuần này: Ngày Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 1 - Static Export \u0026amp; AWS Deployment: Cấu hình Next.js output: export. Upload static build lên S3 Bucket. Cấu hình CloudFront distribution trỏ về S3, thiết lập Custom Domain với Route 53 và chứng chỉ SSL ACM. 24/11/2025 24/11/2025 AWS CloudFront AWS Route 53 Vicobi Infrastructure 2 - Docker Setup: Viết Dockerfile multistage tối ưu dung lượng và docker-compose.yml cho production. Thực hiện build image và deploy thử nghiệm trên môi trường Staging EC2. 25/11/2025 25/11/2025 Docker Docs 3 - UAT \u0026amp; Hotfixes: Mở truy cập cho nhóm tester/user chạy User Acceptance Testing (UAT). Theo dõi log lỗi, fix bug phát sinh và tinh chỉnh caching policy. 26/11/2025 26/11/2025 4 - Security \u0026amp; Performance: Audit lại bảo mật API keys, cấu hình Content Security Policy (CSP). Phân tích bundle size, thực hiện code splitting và lazy loading để cải thiện chỉ số Lighthouse. 27/11/2025 27/11/2025 5 - Documentation \u0026amp; Code Quality: Hoàn thiện tài liệu API (Swagger/Postman), cập nhật README.md hướng dẫn cài đặt. Chạy full linting và type-checking lần cuối để clean code. 28/11/2025 28/11/2025 6 - Final Polish \u0026amp; Preparation: Rà soát lại toàn bộ UI/UX, đảm bảo không còn lỗi vặt. Đóng gói mã nguồn và chuẩn bị tài liệu kỹ thuật chờ bàn giao. - Tham gia AWS Cloud Mastery Series #3: Cloud Security \u0026amp; Operations Mastery 29/11/2025 29/11/2025 Kết quả đạt được tuần 12: Triển khai thành công: Website chạy ổn định trên Production (AWS) và Docker. Sản phẩm hoàn thiện: Đáp ứng mọi yêu cầu, bảo mật tốt, hiệu năng cao. Sẵn sàng bàn giao: Đã chuẩn bị đầy đủ tài liệu và mã nguồn chất lượng. "
},
{
	"uri": "https://tuanvu250.github.io/FCJ-Report/vi/",
	"title": "Báo cáo thực tập",
	"tags": [],
	"description": "",
	"content": "Báo cáo thực tập Thông tin sinh viên: Họ và tên: Uông Tuấn Vũ\nSố điện thoại: 0329 069 810\nEmail: vuutse180241@fpt.edu.vn\nTrường: Đại học FPT TP.HCM\nNgành: Kỹ thuật phầm mềm\nLớp: SE180241\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 08/09/2025 đến ngày 12/12/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "
},
{
	"uri": "https://tuanvu250.github.io/FCJ-Report/vi/3-blogstranslated/3.1-blog1/",
	"title": "Blog 1",
	"tags": [],
	"description": "",
	"content": "Chạy và tối ưu các Small Language Models tại on-premises và tại edge Bởi Chris McEvilly, Fernando Galves Guy Ben Baruchn | Ngày: 23/06/2025\n| In Advanced (300), AWS Outposts, Technical How-to\nKhi bạn chuyển các triển khai generative AI của mình từ giai đoạn prototype sang production, bạn có thể nhận thấy nhu cầu cần chạy các foundation models (FMs) on-premises hoặc at the edge để đáp ứng các yêu cầu về data residency, information security (InfoSec) policy, hoặc low latency. Ví dụ, các khách hàng trong những ngành được quản lý chặt chẽ như financial services, healthcare, và telecom có thể muốn tận dụng các chatbots để hỗ trợ customer queries, tối ưu hóa internal workflows cho các complex reporting, và tự động phê duyệt yêu cầu - đồng thời vẫn giữ dữ liệu trong phạm vi quốc gia. Tương tự, một số tổ chức chọn triển khai các small language models (SLMs) của riêng họ để phù hợp với các yêu cầu InfoSec nội bộ nghiêm ngặt. Ví dụ khác, các nhà sản xuất có thể muốn triển khai SLMs ngay trong nhà máy của họ để phân tích dữ liệu sản xuất và cung cấp chẩn đoán thiết bị theo thời gian thực. Để đáp ứng các nhu cầu về data residency, latency và InfoSec của người dùng, bài viết này cung cấp hướng dẫn về cách triển khai generative AI FMs vào AWS Local Zones và AWS Outposts. Mục tiêu là trình bày một framework giúp chạy nhiều loại SLMs khác nhau nhằm đáp ứng các yêu cầu xử lý dữ liệu tại chỗ dựa trên customer engagements.\nCác tùy chọn triển khai Generative AI Sự phát triển của generative AI trong triển khai và thử nghiệm đã tăng tốc với hai tùy chọn triển khai doanh nghiệp chính. Tùy chọn đầu tiên là sử dụng large language model (LLM) để đáp ứng các nhu cầu của doanh nghiệp. LLMs có tính linh hoạt đáng kinh ngạc: một mô hình duy nhất có thể thực hiện nhiều nhiệm vụ hoàn toàn khác nhau, chẳng hạn như trả lời câu hỏi, viết mã (coding), tóm tắt tài liệu, dịch ngôn ngữ, và tạo nội dung (content generation). LLMs có tiềm năng làm thay đổi cách con người tạo nội dung cũng như cách sử dụng công cụ tìm kiếm và trợ lý ảo. Tùy chọn triển khai thứ hai là sử dụng small language models (SLMs), tập trung vào một use case cụ thể. SLMs là các compact transformer models chủ yếu sử dụng decoder-only hoặc encoder-decoder architectures, thường có ít hơn 20 tỷ parameters, mặc dù định nghĩa này đang phát triển khi các mô hình lớn hơn ra đời. SLMs có thể đạt được hiệu suất tương đương hoặc thậm chí vượt trội khi được fine-tuned cho các domain hoặc task cụ thể, khiến chúng trở thành lựa chọn thay thế tuyệt vời cho các ứng dụng chuyên biệt.\nNgoài ra, SLMs còn mang lại thời gian suy luận (inference time) nhanh hơn, yêu cầu tài nguyên thấp hơn, và phù hợp để triển khai trên nhiều loại thiết bị hơn, đặc biệt hữu ích cho các ứng dụng chuyên biệt và edge computing, nơi không gian và nguồn điện bị giới hạn. Mặc dù SLMs có phạm vi và độ chính xác hạn chế hơn so với LLMs, bạn có thể nâng cao hiệu suất của chúng cho nhiệm vụ cụ thể thông qua Retrieval Augmented Generation (RAG) và fine-tuning. Sự kết hợp này tạo ra một SLM có khả năng trả lời các truy vấn liên quan đến một domain cụ thể với mức độ chính xác tương đương LLM, đồng thời giảm thiểu hiện tượng hallucinations. Nhìn chung, SLMs cung cấp các giải pháp hiệu quả, cân bằng giữa nhu cầu người dùng và hiệu quả chi phí.\nTổng quan kiến trúc Giải pháp được trình bày trong bài viết này sử dụng Llama.cpp, một framework được tối ưu hóa được viết bằng C/C++ nhằm chạy hiệu quả nhiều loại SLMs. Llama.cpp có thể hoạt động hiệu quả trong nhiều môi trường tính toán khác nhau, cho phép generative AI models vận hành trong Local Zones hoặc Outposts mà không cần các cụm GPU lớn (GPU clusters) như thường thấy khi chạy LLMs trong native frameworks của chúng. Framework này mở rộng lựa chọn mô hình và tăng hiệu suất hoạt động khi triển khai SLMs vào Local Zones và Outposts.\nKiến trúc này cung cấp một template cho việc triển khai nhiều loại SLMs nhằm hỗ trợ các use case như chatbot hoặc content generation. Giải pháp bao gồm một front-end application nhận user queries, định dạng các prompts để trình bày cho mô hình và trả về các phản hồi từ mô hình cho người dùng. Để hỗ trợ một giải pháp có khả năng mở rộng (scalable), application servers và Amazon EC2 G4dn GPU-enabled instances được đặt phía sau Application Load Balancer (ALB).\nTrong trường hợp số lượng prompts đến vượt quá khả năng xử lý của SLMs, có thể triển khai message queue ở phía trước SLMs. Ví dụ, bạn có thể triển khai một RabbitMQ cluster để hoạt động như queue manager cho hệ thống.\nHình 1: Architecture overview\nTriển khai giải pháp Các hướng dẫn sau đây mô tả cách khởi chạy một SLM bằng Llama.cpp trong Local Zones hoặc trên Outposts. Mặc dù phần kiến trúc tổng quan trước đó trình bày một giải pháp hoàn chỉnh với nhiều thành phần, bài viết này tập trung cụ thể vào các bước cần thiết để triển khai SLM trong EC2 instance sử dụng Llama.cpp.\nĐiều kiện tiên quyết Để triển khai giải pháp này, bạn cần chuẩn bị các điều kiện sau:\nAWS account đã được allowlisted cho Local Zones, hoặc có một logical Outpost đã được cài đặt, cấu hình và hoạt động.\nQuyền truy cập vào G4dn instances trong tài khoản của bạn tại vị trí đã chọn\n_(kiểm tra trong AWS Service Quotas).\n_\nMột VPC đã được tạo để lưu trữ môi trường triển khai.\nPublic và private subnets để hỗ trợ môi trường trong VPC.\nMột security group được liên kết với EC2 instance của bạn.\nAWS Identity and Access Management (IAM) role với quyền AWS Systems Manager Session Manager permissions.\nHình 1: Architecture overview\n1. Khởi chạy GPU instance cho SLM Đăng nhập vào AWS Management Console, mở Amazon EC2 console,\nvà khởi chạy một g4dn.12xlarge EC2 instance trong Local Zone hoặc Outposts environment của bạn.\nCấu hình bao gồm:\nRed Hat Enterprise Linux 9 (HVM), SSD Volume Type\nPrivate subnet liên kết với Local Zone hoặc Outposts rack\n30 GiB gp2 root volume và thêm 300 GiB gp2 EBS volume\nIAM role đã được cấu hình với các quyền cần thiết cho Systems Manager\nSSM Agent được cài đặt để kết nối tới instance\n(tham khảo hướng dẫn trong Install SSM Agent on RHEL 8.x and 9.x trong Systems Manager User Guide)\nĐể biết hướng dẫn chi tiết về việc khởi chạy EC2 instance, tham khảo: Launch an EC2 instance using the launch instance wizard in the console hoặc Launch an instance on your Outposts rack.\nHình 2: SLM instance launched\n2. Cài đặt NVIDIA drivers Kết nối tới SLM instance bằng Systems Manager.\nBạn có thể làm theo hướng dẫn tại Connect to your Amazon EC2 instance using Session Manager trong Amazon EC2 User Guide.\nCài đặt kernel packages và các công cụ cần thiết:\nsudo su - dnf update -y \u0026lt;br\u0026gt;subscription-manager repos --enable codeready-builder-for-rhel-9-x86_64-rpms dnf install -y \u0026lt;https://dl.fedoraproject.org/pub/epel/epel-release-latest-9.noarch.rpm\u0026gt; dnf install -y ccache cmake gcc-c++ git git-lfs htop python3-pip unzip wget dnf install -y dkms elfutils-libelf-devel kernel-devel kernel-modules-extra \\\\ libglvnd-devel vulkan-devel xorg-x11-server-Xorg \u0026lt;br\u0026gt;systemctl enable --now dkms reboot Cài đặt Miniconda3 trong thư mục /opt/miniconda3 hoặc trình quản lý package tương thích khác để quản lý Python dependencies.\nCài đặt NVIDIA drivers:\ndnf config-manager --add-repo \\\\ \u0026lt;http://developer.download.nvidia.com/compute/cuda/repos/rhel9/x86_64/cuda-rhel9.repo\u0026gt; dnf module install -y nvidia-driver:latest-dkms dnf install -y cuda-toolkit echo \u0026#39;export PATH=/usr/local/cuda/bin:\\$PATH\u0026#39; \u0026gt;\u0026gt; ~/.bashrc echo \u0026#39;export LD_LIBRARY_PATH=/usr/local/cuda/lib64:\\$LD_LIBRARY_PATH\u0026#39; \u0026gt;\u0026gt; ~/.bashrc source ~/.bashrc 3. Tải xuống và cài đặt Llama.cpp Tạo và mount filesystem của Amazon EBS volume bạn đã tạo trước đó vào thư mục /opt/slm. Xem hướng dẫn tại Make an Amazon EBS volume available for use trong Amazon EBS User Guide.\nChạy các lệnh sau để tải và cài đặt Llama.cpp:\ncd /opt/slm\rgit clone -b b4942 \\\\\u0026lt;https://github.com/ggerganov/llama.cpp.git\u0026gt;\rcd llama.cpp cmake -B build -DGGML_CUDA=ON\rcmake --build build --config Release -j\\$(nproc) conda install python=3.12\rpip install -r requirements.txt\rpip install nvitop 4. Tải xuống và chuyển đổi SLM model Để chạy SLM hiệu quả với Llama.cpp, bạn cần chuyển đổi model sang định dạng GGUF (GPT-Generated Unified Format). Việc chuyển đổi này giúp tối ưu hiệu năng và mức sử dụng bộ nhớ cho các môi trường edge deployments có tài nguyên giới hạn. GGUF được thiết kế đặc biệt để hoạt động với Llama.cpp inference engine. Các bước sau đây minh họa cách tải SmolLM2 1.7B và chuyển đổi sang định dạng GGUF:\nmkdir /opt/slm/models cd /opt/slm/models git lfs install git clone \u0026lt;https://huggingface.co/HuggingFaceTB/SmolLM2-1.7B-Instruct\u0026gt; cd /opt/slm/llama.cpp python3 convert_hf_to_gguf.py --outtype f16 \\\\ --outfile /opt/slm/llama.cpp/models/SmolLM2-1.7B-Instruct-f16.gguf \\\\ /opt/slm/models/SmolLM2-1.7B-Instruct echo \u0026#39;export PATH=/opt/slm/llama.cpp/build/bin:\\$PATH\u0026#39; \u0026gt;\u0026gt; ~/.bashrc echo \u0026#39;export LD_LIBRARY_PATH=/opt/slm/llama.cpp/build/bin:\\$LD_LIBRARY_PATH\u0026#39; \u0026gt;\u0026gt; ~/.bashrc source ~/.bashrc Bạn cũng có thể tải các models khác được công khai từ Hugging Face nếu cần,\nvà thực hiện quá trình chuyển đổi tương tự.\nSLM Operation and Optimization Việc triển khai SLMs thông qua Llama.cpp mang lại tính linh hoạt cao trong vận hành, cho phép tùy chỉnh môi trường và tối ưu hóa theo các use case cụ thể. Với Llama.cpp, bạn có thể chọn nhiều tham số khác nhau để tối ưu việc sử dụng tài nguyên hệ thống và hoạt động của mô hình, giúp tận dụng hiệu quả tài nguyên mà không tiêu tốn không cần thiết hoặc ảnh hưởng đến hiệu suất. Các tham số phổ biến khi chạy Llama.cpp giúp kiểm soát cách mô hình hoạt động bao gồm:\n-ngl N, \u0026ndash;n-gpu-layers N: Khi biên dịch với GPU support, tùy chọn này cho phép chuyển một số layer sang GPU để tính toán, giúp tăng hiệu suất xử lý. -t N, \u0026ndash;threads N: Xác định số lượng threads sử dụng trong quá trình sinh nội dung. Để đạt hiệu suất tối ưu, nên đặt giá trị này bằng số lõi CPU vật lý có trong hệ thống. -n N, \u0026ndash;n-predict N: Xác định số lượng tokens cần sinh ra khi tạo văn bản.\nĐiều chỉnh giá trị này sẽ ảnh hưởng đến độ dài đầu ra của văn bản. -sm, \u0026ndash;split-mode: Xác định cách chia mô hình giữa nhiều GPU khi chạy trong môi trường multi-GPU. Nên thử \u0026ldquo;row\u0026rdquo; splitting mode, vì trong một số trường hợp, nó mang lại hiệu suất tốt hơn so với chia theo layer-based mặc định. --temp N: Temperature điều khiển mức độ ngẫu nhiên trong đầu ra của SLM. Giá trị thấp hơn (ví dụ 0.2-0.5) tạo ra câu trả lời nhất quán và xác định hơn, giá trị cao hơn (ví dụ 0.9-1.2) giúp mô hình sáng tạo và đa dạng hơn (mặc định: 0.88) -s SEED, \u0026ndash;seed SEED: Cung cấp phương pháp kiểm soát ngẫu nhiên của mô hình. Việc đặt seed cố định giúp tái tạo kết quả nhất quán trong nhiều lần chạy (mặc định: -1, -1 = random seed). -c, \u0026ndash;ctx-size N: Xác định context size, số lượng tokens mà FM có thể xử lý trong một prompt. Giá trị này ảnh hưởng đến mức RAM cần thiết và độ chính xác của mô hình. Ví dụ: với Phi-3, khuyến nghị giảm context size còn 8k hoặc 16k để tối ưu hiệu suất. Lệnh mẫu: \u0026ndash;ctx-size XXXX trong đó XXXX là context size. Phần này minh họa cách tối ưu hóa hiệu suất SLM cho các use case cụ thể bằng Llama.cpp, gồm hai kịch bản phổ biến: Chatbot interactions và Text summarization\nChatbot Use Case Example Token Size Requirements Đối với ứng dụng chatbot, kích thước token thông thường: Input: khoảng 50-150 tokens, hỗ trợ người dùng hỏi 1-2 câu và Output: khoảng 100-300 tokens, giúp mô hình phản hồi ngắn gọn nhưng chi tiết.\nSample Command ./build/bin/llama-cli -m ./models/SmolLM2-1.7B-Instruct-f16.gguf \\\\ -ngl 99 -n 512 --ctx-size 8192 -sm row --temp 0\r--single-turn \\\\ -sys \u0026#34;You are a helpful assistant\u0026#34; -p \u0026#34;Hello\u0026#34; Hình 3: Chatbot example\nCommand Explanation -m ./models/SmolLM2-1.7B-Instruct-f16.gguf : Chỉ định file model sử dụng -ngl 99 : Gán 99 GPU layers để đạt hiệu suất tối ưu -n 512 : Tối đa 512 output tokens (đủ cho 100-300 tokens cần thiết) --ctx-size 8192 : Đặt kích thước context window để xử lý hội thoại phức tạp -sm row : Chia hàng across GPUs --temp 0 : Đặt temperature bằng 0 để giảm tính sáng tạo --single-turn : Tối ưu cho các phản hồi một lượt -sys \u0026ldquo;You are a helpful assistant\u0026rdquo; : Thiết lập system prompt định nghĩa vai trò trợ lý -p \u0026ldquo;Hello\u0026rdquo; : Nhập prompt của người dùng Text Summarization Example Dòng lệnh dưới đây cho thấy SmolLM2-1.7B chạy tác vụ tóm tắt văn bản:\nPROMPT_TEXT=\u0026#34;Summarize the following text: Amazon DynamoDB is a serverless, NoSQL database service that allows you to develop modern applications at any scale. As a serverless database, you only pay for what you use and DynamoDB scales to zero, has no cold starts, no version upgrades, no maintenance windows, no patching, and no downtime maintenance. DynamoDB offers a broad set of security controls and compliance standards. For globally distributed applications, DynamoDB global tables is a multi-Region, multi-active database with a 99.999% availability SLA and increased resilience. DynamoDB reliability is supported with managed backups, point-in-time recovery, and more. With DynamoDB streams, you can build serverless event-driven applications.\u0026#34; ./build/bin/llama-cli -m ./models/SmolLM2-1.7B-Instruct-f16.gguf \\\\ -ngl 99 -n 512 --ctx-size 8192 -sm row --single-turn \\\\ -sys \u0026#34;You are a technical writer\u0026#34; \\\\ --prompt \u0026#34;\\$PROMPT_TEXT\u0026#34; Hình 4: Summarization example\nCleaning Up Để tránh chi phí phát sinh không cần thiết, hãy thực hiện các bước sau để xóa tài nguyên sau khi hoàn tất:\nTerminate EC2 instance để ngừng tính phí. Xác minh rằng EBS volume 300 GiB đã được xóa đúng cách bằng cách kiểm tra mục Volumes trong phần Elastic Block Store.Nếu vẫn còn volume, hãy chọn và thực hiện: Actions \u0026gt; Delete volume. Kết luận Bài viết này đã hướng dẫn bạn từng bước triển khai SLMs vào môi trường AWS on-premises hoặc edge nhằm đáp ứng các nhu cầu xử lý dữ liệu cục bộ. Phần đầu bài viết đã thảo luận về lợi ích kinh doanh của SLMs, bao gồm: Thời gian suy luận (inference time) nhanh hơn, Giảm chi phí vận hành và cải thiện kết quả đầu ra của mô hình. Các SLMs được triển khai bằng Llama.cpp và tối ưu hóa cho các use case cụ thể có thể cung cấp dịch vụ người dùng hiệu quả từ edge theo cách mở rộng linh hoạt (scalable). Các tham số tối ưu hóa được mô tả trong bài viết này cung cấp nhiều phương pháp cấu hình khác nhau để điều chỉnh mô hình cho các kịch bản triển khai đa dạng. Bạn có thể làm theo các bước và kỹ thuật được trình bày trong bài để triển khai generative AI phù hợp với yêu cầu về data residency, latency, hoặc InfoSec compliance, đồng thời vận hành hiệu quả trong giới hạn tài nguyên của môi trường edge computing. Để tìm hiểu thêm, hãy truy cập AWS Local Zones và AWS Outposts.\n"
},
{
	"uri": "https://tuanvu250.github.io/FCJ-Report/vi/3-blogstranslated/3.2-blog2/",
	"title": "Blog 2",
	"tags": [],
	"description": "",
	"content": "Hội nghị AWS EUC New York Summit: EUC201 - The AI Advantage: Unlocking the full potential of your EUC Services Bởi Dave Jaskie và Matt Aylward | ngày 27/06/2025 | Amazon AppStream 2.0, Amazon Bedrock, Amazon Bedrock Agents, Amazon CloudWatch, Amazon WorkSpaces, Desktop \u0026amp; Application Streaming, End User Computing.\nBạn có đang tìm cách ứng dụng AI để tối ưu các tác vụ quản trị và nâng cao năng suất người dùng không?\nTrong bối cảnh kỹ thuật số liên tục phát triển, thành công của chiến lược End-User Computing (EUC) của doanh nghiệp phụ thuộc vào khả năng người dùng cuối tiếp cận và sử dụng dịch vụ hiệu quả.\nPhiên thảo luận tương tác này sẽ trình bày cách bạn có thể tận dụng AI agentic của Amazon Bedrock kết hợp với Amazon WorkSpaces và Amazon CloudWatch.\nNhững công cụ này giúp tự động hóa các tác vụ quản trị và cung cấp thông tin chi tiết có thể hành động (actionable insights) từ các metrics và logs quan trọng.\nTrong buổi học, người tham dự sẽ được giới thiệu các chiến lược EUC quan trọng và học cách AI có thể chuyển đổi quy trình làm việc của họ. Bạn sẽ khám phá cách Amazon Bedrock giúp đơn giản hóa các quy trình phức tạp, mang đến cho quản trị viên các công cụ cần thiết để tăng hiệu suất. Ngoài ra, các bài thực hành (hands-on) cùng Amazon CloudWatch sẽ giúp bạn học cách thu thập dữ liệu quan trọng - bao gồm user connectivity, platforms, và IP addresses. Thông qua Amazon Bedrock, bạn sẽ phân tích dữ liệu để rút ra các thông tin giúp tối ưu hoạt động người dùng cuối.\nPhiên này không chỉ mang lại kiến thức chuyên sâu, mà còn là trải nghiệm học tập thực tế. Người tham dự sẽ có hiểu biết rõ ràng về cách tích hợp AI và CloudWatch vào framework hiện có. Dù bạn là IT professional, system administrator, hay decision-maker, đây là cơ hội để nâng cao chiến lược EUC của bạn và đảm bảo cả admin lẫn người dùng đều hưởng lợi từ các công cụ và quy trình tối ưu hóa.\nBuổi builders session này diễn ra vào ngày 16 tháng 7, lúc 9:15 AM EDT, tại Javits Convention Center. Vui lòng thêm buổi này vào lịch trình của bạn qua liên kết sau khi đăng ký.\nĐừng bỏ lỡ cơ hội thay đổi cách bạn tiếp cận end-user computing. Hãy tham gia để khai phá tiềm năng của AI, tự động hóa với sự tự tin, và nắm bắt insights giúp tổ chức của bạn tiến xa hơn. Đăng ký ngay hôm nay!\nDave Jaskie có 15 năm kinh nghiệm trong lĩnh vực End User Computing. Ngoài công việc, Dave thích du lịch và leo núi cùng vợ và 4 người con. Matt Aylward là Solutions Architect tại Amazon Web Services (AWS), chuyên tạo ra các giải pháp đơn giản cho những thách thức kinh doanh phức tạp. Trước khi gia nhập AWS, Matt đã làm việc trong lĩnh vực triển khai hạ tầng, kiểm thử khôi phục sau thảm họa, và quản lý phân phối ứng dụng ảo. Ngoài giờ làm, anh thích dành thời gian cho gia đình, xem phim, và đi dã ngoại cùng chú chó năng động của mình. "
},
{
	"uri": "https://tuanvu250.github.io/FCJ-Report/vi/3-blogstranslated/3.3-blog3/",
	"title": "Blog 3",
	"tags": [],
	"description": "",
	"content": "Cách thiết lập cảnh báo tự động cho các AWS Savings Plans mới mua Bởi Syed Muhammad Tawha và Dan Johns | ngày 26/06/2025 | Amazon Simple Notification Service (SNS), AWS Cloud Financial Management, AWS CloudFormation, Cloud Cost Optimization\nKhi tổ chức phát triển, các nhóm FinOps cần một cái nhìn tổng thể về AWS Savings Plans để tối ưu hóa việc sử dụng. Giải pháp này giúp giám sát tự động và thiết lập cảnh báo nhằm phát hiện các Savings Plans sử dụng kém hiệu quả trong thời hạn hoàn trả hợp lệ.\nKhi mua Savings Plan, bạn cam kết sử dụng trong 1 hoặc 3 năm. Các Savings Plan có cam kết theo giờ ≤ $100 có thể được hoàn trả nếu được mua trong vòng 7 ngày gần nhất và trong cùng tháng dương lịch, miễn là bạn chưa vượt quá giới hạn hoàn trả. Sau khi tháng kết thúc (theo UTC), Savings Plans đó không thể hoàn trả.\nỞ bài viết này, chúng tôi cung cấp các AWS CloudFormation templates giúp tạo AWS Step Functions state machine, Amazon Simple Notification Service (SNS) topic, Amazon EventBridge scheduler, và các AWS Identity and Access Management (IAM) roles cần thiết để giám sát tự động các Savings Plans mới mua và phát hiện những gói sử dụng thấp.\nTổng quan giải pháp Giải pháp này tuân theo AWS security best practices bằng cách tách triển khai trên hai tài khoản. Một CloudFormation stack sẽ được tạo trong Management account để thiết lập các IAM roles cần thiết để truy xuất dữ liệu sử dụng của Savings Plans. Một CloudFormation stack khác sẽ được triển khai trong Member Account đã chọn trong AWS Organization của bạn.\nCloudFormation stack trong Member Account tạo một state machine thực hiện assume role trong Management Account của bạn và phân tích tất cả Savings Plans trong Management Account, bao gồm cả những gói đã được mua trong toàn bộ tổ chức của bạn. Workflow lọc các Savings Plans hoạt động theo ngày mua, tập trung vào các plan được mua trong 7 ngày gần nhất và tháng hiện tại. Sau đó, hệ thống đánh giá tỷ lệ sử dụng của chúng và xác định các plan dưới ngưỡng định sẵn.\nState machine sẽ thực thi theo tần suất bạn chỉ định và sử dụng Amazon SNS để gửi cảnh báo qua email đến các địa chỉ bạn cung cấp khi tạo CloudFormation stack. Các cảnh báo này sẽ chứa thông tin chi tiết về các Savings Plans sử dụng thấp và hướng dẫn về quy trình hoàn trả.\nHình 1: Kiến trúc AWS - Member Account nhận quyền đọc dữ liệu từ Management Account và kích hoạt Step Function để gửi cảnh báo qua SNS.\nTriển khai giải pháp Điều kiện tiên quyết Có AWS Account\nCó IAM permissions để tạo CloudFormation Stack và IAM Role trong Management Account\nCó IAM permissions để tạo Step Functions, SNS, IAM Roles, và EventBridge trong Member Account\nTriển khai giải pháp Trong phần này, chúng ta sẽ triển khai các tài nguyên cho giải pháp này trong tài khoản của bạn:\nPhần 1 - Triển khai trong Member Account Trong phần này, chúng ta sẽ triển khai các tài nguyên cho giải pháp này trong Member Account đã chọn.\nĐăng nhập vào AWS Management Console của Member Account nơi bạn muốn triển khai giải pháp.\nTriển khai CloudFormation Stack này Launch Stack\nCung cấp Stack Name là new-sp-utilization-alert-member.\nTrong tham số AlertEmails, nhập danh sách email cách nhau bởi dấu phẩy mà sẽ nhận thông báo về Savings Plans sử dụng kém.\nTrong tham số ManagementAccountId, nhập 12 chữ số AWS Account ID của Management Account.\nTrong tham số ScheduleExpression, chỉ định tần suất thực thi cho Step Functions state machine theo định dạng cron (mặc định là hàng ngày vào lúc 9 AM UTC).\nTrong tham số UtilizationThreshold, chỉ định tỷ lệ sử dụng tối thiểu cho Savings Plans của bạn. Bạn sẽ nhận thông báo khi tỷ lệ sử dụng giảm dưới ngưỡng này.\nNhấn Next, chọn ô acknowledgment, và tạo stack.\nChờ cho đến khi stack hoàn thành và hiển thị trạng thái CREATE-COMPLETE.\nBạn sẽ nhận một email để xác nhận đăng ký nhận thông báo từ SNS topic do stack này tạo. Vui lòng xác nhận đăng ký để bắt đầu nhận thông báo.\nTruy cập vào tab Outputs của stack vừa tạo và ghi lại các giá trị của ExecutionRoleArn và StateMachineArn, bạn sẽ cần chúng trong phần tiếp theo.\nPhần 2 - Triển khai trong Management Account Đăng nhập vào AWS Management Console. Lưu ý: Đây phải là tài khoản giống như tài khoản đã nhập trong tham số ManagementAccountId ở phần trước.\nTriển khai CloudFormation Stack này Launch Stack\nCung cấp Stack Name là new-sp-utilization-alert-management.\nTrong tham số ExecutionRoleArn, cung cấp giá trị đã sao chép từ stack outputs của stack đã triển khai trong Member Account.\nTrong tham số StateMachineArn, cung cấp giá trị đã sao chép từ stack outputs của stack đã triển khai trong Member Account.\nNhấn Next, chọn ô acknowledgment, và tạo stack.\nChờ cho đến khi stack hoàn thành và hiển thị trạng thái CREATE-COMPLETE.\nKiểm thử giải pháp Bây giờ mà Step Functions state machine và các tài nguyên liên quan đã được triển khai trong Member Account, chúng ta sẽ kiểm tra việc triển khai:\nĐăng nhập lại vào AWS Management Console của Member Account nơi bạn đã triển khai phần 1 của giải pháp này.\nTruy cập vào tab Resources trong CloudFormation stack và tìm SavingsPlansAlerts Step Functions state machine. Nhấp vào hyperlink màu xanh dương.\nBạn sẽ được chuyển hướng đến Step Functions console. Nhấn Start execution ở bên phải.\nXem chi tiết execution trong mục Events để theo dõi tiến trình của state machine. Nếu có Savings Plans được mua trong vòng 7 ngày gần nhất và tháng hiện tại, bạn sẽ nhận email thông báo.\nMột execution thành công được hiển thị bằng ô màu xanh lá trong Graph view. Nếu bất kỳ Savings Plans nào rơi dưới ngưỡng tỷ lệ sử dụng đã chỉ định, bạn sẽ nhận email tại địa chỉ đã cung cấp.\nDọn dẹp tài nguyên Tất cả các tài nguyên đã triển khai cho giải pháp này có thể được xóa bằng cách xóa CloudFormation stacks. Bạn có thể xóa stack thông qua AWS Management Console hoặc AWS CLI.\nĐể xóa stack trong Management Account (CLI):\naws cloudformation delete-stack --stack-name new-sp-utilization-alert_management Để xóa stack trong Member Account (CLI):\naws cloudformation delete-stack --stack-name new-sp-utilization-alert_member Hiểu và xử lý cảnh báo Khi bạn nhận được cảnh báo về Savings Plans sử dụng thấp, bạn nên xem lại chi tiết sử dụng được cung cấp trong thông báo email. Phân tích các chỉ số sử dụng của bạn so với cam kết ban đầu khi mua Savings Plan, và điều tra xem tỷ lệ sử dụng thấp có phải là điều đã dự kiến hay do các yếu tố khác như di chuyển khối lượng công việc, thay đổi kiến trúc, hoặc ước tính sai nhu cầu công suất. Hãy cân nhắc hoàn trả Savings Plan nếu tỷ lệ sử dụng vẫn duy trì dưới ngưỡng của bạn, plan được mua trong vòng 7 ngày gần nhất, mua trong tháng hiện tại, và cam kết mỗi giờ ≤ $100. Ghi lại lý do hoàn trả để tham khảo và lập kế hoạch cho tương lai.\nKết luận Bài viết đã hướng dẫn cách sử dụng Savings Plan và Cost Explorer APIs để xác định Savings Plans sử dụng thấp trong tổ chức của bạn. Sau đó, chúng tôi đã minh họa cách sử dụng Step Functions State Machine để lọc các Savings Plans được mua trong 7 ngày gần nhất và tháng hiện tại, điều này rất quan trọng vì bạn có thể hoàn trả Savings Plans trong thời gian hoàn trả hợp lệ nếu chúng không được sử dụng hiệu quả. Để biết thêm chi tiết về việc hoàn trả Savings Plan, tham khảo tài liệu Returning a Purchased Savings Plan\nSyed Muhammad Tawha Syed Muhammad Tawha là Principal Technical Account Manager tại AWS, có trụ sở tại Dublin, Ireland. Tawha chuyên môn về Storage, Resilience và Cloud Cost Optimization. Anh đam mê giúp đỡ khách hàng của AWS tối ưu hóa chi phí và cải thiện hiệu suất. Ngoài công việc, Tawha còn yêu thích dành thời gian với bạn bè và gia đình Dan Johns Dan Johns là Senior Solutions Architect Engineer, hỗ trợ khách hàng xây dựng trên AWS và đáp ứng các yêu cầu kinh doanh. Ngoài công việc, anh thích đọc sách, dành thời gian với gia đình và tự động hóa các tác vụ trong nhà. "
},
{
	"uri": "https://tuanvu250.github.io/FCJ-Report/vi/5-workshop/5.1-workshop-overview/5.1.1-whatisrag/",
	"title": "Giải thích RAG",
	"tags": [],
	"description": "",
	"content": "Định nghĩa ngắn gọn RAG (viết tắt của Retrieval-Augmented Generation) là một kỹ thuật hoặc kiến trúc phần mềm trong lĩnh vực Trí tuệ nhân tạo (AI), được thiết kế để tối ưu hóa đầu ra của một Mô hình Ngôn ngữ Lớn (LLM).\nVề mặt bản chất, RAG là sự kết hợp giữa hai cơ chế:\nCơ chế truy xuất thông tin (Information Retrieval): Tìm kiếm dữ liệu từ một nguồn kiến thức bên ngoài (External Knowledge Base) có độ tin cậy cao. Cơ chế tạo sinh văn bản (Text Generation): Sử dụng khả năng hiểu và tổng hợp ngôn ngữ của LLM để tạo ra câu trả lời tự nhiên. Mục tiêu của RAG là cung cấp cho LLM thêm ngữ cảnh (context) chính xác, cập nhật và cụ thể, giúp mô hình vượt qua giới hạn của dữ liệu huấn luyện tĩnh (static training data).\nVì sao cần RAG? Các mô hình LLM truyền thống thường gặp 3 vấn đề lớn mà RAG có thể giải quyết:\nCập nhật thông tin (Freshness): LLM không cần huấn luyện lại (Re-training) hay tinh chỉnh (Fine-tuning) mà vẫn trả lời được các thông tin mới nhất, chỉ cần cập nhật vào cơ sở dữ liệu tìm kiếm. Sở hữu dữ liệu (Proprietary Data): Cho phép AI trả lời các câu hỏi về dữ liệu riêng tư của doanh nghiệp (tài liệu nội bộ, code base, thông tin khách hàng) mà mô hình gốc không hề biết. Tính xác thực (Grounding): Giảm thiểu \u0026ldquo;ảo giác\u0026rdquo; (Hallucination - AI bịa thông tin) bằng cách buộc AI phải trích dẫn hoặc dựa trên đoạn văn bản thực tế được tìm thấy. Kiến trúc hoạt động Quy trình xử lý một câu hỏi của RAG diễn ra như sau:\nBước Tên gọi Mô tả hành động 1 Retrieval (Truy xuất) Hệ thống tìm kiếm các đoạn văn bản liên quan nhất đến câu hỏi trong kho dữ liệu (thường dùng Vector Database). 2 Augmentation (Tăng cường) Ghép câu hỏi của người dùng + Dữ liệu vừa tìm được thành một \u0026ldquo;lời nhắc\u0026rdquo; (prompt) hoàn chỉnh. 3 Generation (Tạo sinh) Gửi prompt đó cho AI (LLM) để nó tổng hợp và viết ra câu trả lời cuối cùng cho người dùng. "
},
{
	"uri": "https://tuanvu250.github.io/FCJ-Report/vi/5-workshop/5.1-workshop-overview/",
	"title": "Giới thiệu",
	"tags": [],
	"description": "",
	"content": "Giới thiệu tổng quan Trong bài thực hành này, chúng ta sẽ tập trung xây dựng một trợ lý AI thông minh có khả năng \u0026ldquo;đọc hiểu\u0026rdquo; và trả lời câu hỏi dựa trên dữ liệu riêng của doanh nghiệp (kỹ thuật RAG).\nMục tiêu chính là thiết lập một quy trình xử lý dữ liệu hoàn toàn tự động và không máy chủ (Serverless), bao gồm các bước:\nIngestion (Nhập liệu): Đưa tài liệu gốc vào hệ thống. Indexing (Tạo chỉ mục): Chuyển đổi văn bản thành vector và lưu trữ để tra cứu. Retrieval \u0026amp; Generation (Truy xuất \u0026amp; Tạo sinh): Cấu hình mô hình AI để tìm kiếm thông tin liên quan và trả lời câu hỏi của người dùng. 💡 Điểm nổi bật: Giải pháp này giúp bạn không cần quản lý bất kỳ hạ tầng máy chủ nào, tối ưu hóa chi phí và thời gian vận hành.\nCác Bước Thực hiện Giải thích RAG Giới thiệu các dịch vụ "
},
{
	"uri": "https://tuanvu250.github.io/FCJ-Report/vi/5-workshop/5.1-workshop-overview/5.1.2-services/",
	"title": "Giới thiệu các dịch vụ",
	"tags": [],
	"description": "",
	"content": "Kiến trúc giải pháp được xây dựng dựa trên sự phối hợp của 4 thành phần dịch vụ chính sau đây:\nKnowledge Bases for Amazon Bedrock Đây là một khả năng được quản lý toàn diện (fully managed capability) giúp kết nối các Mô hình Nền tảng (Foundation Models) với nguồn dữ liệu nội bộ của doanh nghiệp.\nTự động hóa quy trình RAG: Quản lý toàn bộ luồng công việc từ đầu đến cuối (end-to-end), bao gồm nhập dữ liệu (ingestion), chia nhỏ văn bản (chunking), tạo vector (embedding) và truy xuất thông tin (retrieval). Kết nối ngữ cảnh: Giúp các ứng dụng AI trả lời câu hỏi dựa trên dữ liệu riêng tư thay vì chỉ dựa vào dữ liệu huấn luyện chung chung. Không cần quản lý hạ tầng: Loại bỏ nhu cầu tự xây dựng và duy trì các đường ống dữ liệu (data pipelines) phức tạp. Amazon Simple Storage Service (Amazon S3) Là dịch vụ lưu trữ đối tượng (object storage) với khả năng mở rộng, độ bền dữ liệu 99,999999999% (11 số 9) và bảo mật hàng đầu.\nVai trò nguồn dữ liệu (Data Source): Đóng vai trò là kho chứa \u0026ldquo;sự thật\u0026rdquo; (source of truth). Lưu trữ tài liệu: Chứa các tệp phi cấu trúc như PDF, Word, hoặc Text mà doanh nghiệp muốn AI học. Đồng bộ hóa: Knowledge Base sẽ định kỳ quét bucket S3 này để đồng bộ hóa và cập nhật kiến thức mới nhất. Amazon OpenSearch Serverless Là tùy chọn triển khai không máy chủ (serverless) của Amazon OpenSearch Service, giúp chạy khối lượng công việc tìm kiếm và phân tích mà không cần quản lý cụm (cluster).\nVai trò kho lưu trữ Vector (Vector Store): Lưu trữ các chỉ mục vector (vector embeddings) được tạo ra từ tài liệu gốc. Tìm kiếm ngữ nghĩa (Semantic Search): Thực hiện thuật toán tìm kiếm tương đồng (similarity search/k-NN) để xác định các đoạn văn bản có ý nghĩa gần nhất với câu hỏi của người dùng. Tự động mở rộng: Tự động điều chỉnh tài nguyên tính toán và lưu trữ dựa trên nhu cầu thực tế. Amazon Bedrock Foundation Models (FMs) Cung cấp quyền truy cập vào các mô hình AI hàng đầu thông qua API thống nhất. Trong kiến trúc này, chúng ta sử dụng hai loại mô hình với vai trò riêng biệt:\nEmbedding Model (Amazon Titan Embeddings v2): Chuyển đổi văn bản (tài liệu từ S3 và câu hỏi của người dùng) thành các vector số học. Giúp máy tính có thể so sánh mức độ tương đồng về ý nghĩa giữa các đoạn văn. Text Generation Model (Anthropic Claude 3): Đóng vai trò là \u0026ldquo;bộ não\u0026rdquo; suy luận. Nhận câu hỏi kèm theo thông tin ngữ cảnh đã được truy xuất từ Vector Store. Tổng hợp thông tin và sinh ra câu trả lời tự nhiên, chính xác, có kèm trích dẫn nguồn. "
},
{
	"uri": "https://tuanvu250.github.io/FCJ-Report/vi/5-workshop/5.3-knowledge-base/5.3.1-create-kb/",
	"title": "Khởi tạo Knowledge Base",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Chúng ta sẽ sử dụng Amazon Bedrock Wizard để thiết lập toàn bộ kiến trúc RAG. Quá trình này sẽ kết nối nguồn dữ liệu S3, mô hình Embedding và tự động khởi tạo kho lưu trữ Vector (OpenSearch Serverless).\nCác Bước Thực hiện Đăng nhập vào AWS Management Console và truy cập dịch vụ Amazon Bedrock. Trong menu bên trái, chọn Knowledge bases. Nhấp vào nút Create knowledge base ở góc trên bên phải của màn hình. Chọn Knowledge Base with vector store Bước 1: Cấu hình Knowledge Base\nTrên màn hình cấu hình đầu tiên:\nKnowledge base name: Nhập tên knowledge-base-demo Knowledge Base description - optional: Nhập Knowledge Base from AWS Overview (Phần này bạn cần mô tả dữ liệu bạn đã upload lên S3 trước đó). IAM permissions: Chọn tùy chọn Create and use a new service role. Service role name: Giữ giá trị mặc định do AWS đề xuất (bắt đầu bằng AmazonBedrockExecutionRoleForKnowledgeBase_...). Nhấp Next. Bước 2: Cấu hình Nguồn Dữ liệu\nKết nối đến S3 Bucket chứa các tài liệu:\nData source name: Nhập knowledge-base-demo S3 URI: Nhấp vào nút Browse S3. Trong cửa sổ pop-up, chọn bucket rag-workshop-demo mà bạn đã tạo trong phần trước. Nhấp Choose. Giữ lại các cấu hình Default. Nhấp Next. Bước 3: Lưu trữ \u0026amp; Xử lý Đây là bước quan trọng nhất để xác định mô hình AI và vị trí lưu trữ vector:\nEmbeddings model:\nNhấp Select model. Chọn model: Titan Embeddings G1 - Text v2. Vector Store:\nVector store creation method: Chọn Quick create a new vector store - Recommended Vector store type - new: Chọn Amazon OpenSearch Serverless Lưu ý: Tùy chọn này cho phép AWS tự động tạo một cluster Amazon OpenSearch Serverless để lưu trữ dữ liệu, giúp bạn không phải quản lý cơ sở hạ tầng thủ công. Nhấp Next. Bước 4: Kiểm tra và Tạo Knowledge Base\nKiểm tra tất cả thông tin cấu hình trên trang Review. Đảm bảo các mục S3 URI và Model đều chính xác. Cuộn xuống cuối trang và nhấp vào nút Create knowledge base. Bước 5: Chờ Khởi tạo\nSau khi nhấp Create, hệ thống sẽ bắt đầu quá trình khởi tạo cơ sở hạ tầng nền cho Vector Store.\nThời gian chờ: Khoảng 2 - 5 phút. Lưu ý: Vui lòng không đóng trình duyệt trong thời gian này. Thành công: Khi màn hình hiển thị thông báo màu xanh \u0026ldquo;Knowledge base created successfully\u0026rdquo;, bạn đã hoàn thành bước này và sẵn sàng cho phần tiếp theo. "
},
{
	"uri": "https://tuanvu250.github.io/FCJ-Report/vi/5-workshop/5.2-prerequiste/5.2.1-model-access/",
	"title": "Kiểm tra truy cập Model",
	"tags": [],
	"description": "",
	"content": "Tổng quan Theo chính sách mới của AWS, các mô hình nền tảng (Foundation Models) thường được tự động kích hoạt. Tuy nhiên, đối với các mô hình của đối tác thứ ba như Anthropic (Claude), người dùng lần đầu tiên sử dụng tại một Region mới bắt buộc phải khai báo thông tin sử dụng (Use Case) mới có thể gọi được mô hình.\nĐảm bảo tài khoản AWS của bạn có quyền truy cập và sử dụng mô hình Anthropic Claude 3 Sonnet. Đây là bước bắt buộc để tránh lỗi AccessDenied khi Chatbot hoạt động sau này. Nếu đây là lần đầu tiên bạn sử dụng model này tại Region mới, bạn cần thực hiện khai báo mục đích sử dụng (Use Case).\nKiểm tra truy cập Chúng ta sẽ thực hiện một bài kiểm tra nhanh (Test Run) để đảm bảo tài khoản của bạn đã sẵn sàng.\nĐầu tiên ở thanh tìm kiếm, truy cập vào Amazon Bedrock.\nBước 1. Truy cập Chat Playground\nTại menu bên trái Bedrock Console, tìm mục Playgrounds. Click Chat. Bước 2. Chọn Model kiểm thử\nClick Select model (phía trên khung chat). Category: Chọn Anthropic. Model: Chọn Claude 3 Sonnet (hoặc Claude 3.5 Sonnet). Throughput: Chọn On-demand. Click Apply. Bước 3. Gửi tin nhắn kích hoạt\nTrong khung chat: Nhập Hello.\nClick Run.\nQuan sát kết quả:\nNếu AI trả lời: Thành công (Chuyển ngay sang phần 5.2.2). Nếu hiện lỗi màu đỏ hoặc popup \u0026ldquo;Submit use case details\u0026rdquo;: Cần khai báo thông tin (Làm tiếp bước 4 bên dưới).\nBước 4. Khai báo Use Case (Chỉ thực hiện nếu gặp lỗi ở bước 3)\nClick Submit use case details (trong thông báo lỗi). Điền biểu mẫu: Company Name: Nhập Personal Learning. Industry: Chọn Technology. Intended Use: Chọn Research \u0026amp; Development. Click Submit. Đợi 1 phút, quay lại khung chat, Click Run lại tin nhắn Hello để xác nhận thành công. "
},
{
	"uri": "https://tuanvu250.github.io/FCJ-Report/vi/1-worklog/",
	"title": "Nhật ký công việc",
	"tags": [],
	"description": "",
	"content": "Trong trang này bạn sẽ cần giới thiệu worklog của bạn như thế nào? Bạn hoàn thành chương trình trong vòng bao nhiêu tuần? Bạn đã làm gì trong các tuần đó?\nThông thường và cũng là tiêu chuẩn, một worklog được thực hiện trong khoảng 3 tháng (trong suốt thời gian thực tập) với nội dung các tuần như sau:\nTuần 1: Làm quen với AWS, Networking và Compute Services\nTuần 2: Mạng nâng cao, Lưu trữ lai (Hybrid Storage) và Chiến lược Backup\nTuần 3: Lưu trữ nâng cao, Di chuyển dữ liệu và Tối ưu hóa chi phí\nTuần 4: Bảo mật cốt lõi, Dịch vụ Cơ sở dữ liệu và Mã hóa\nTuần 5: Containerization, Data Lake và Chuyên sâu về NoSQL\nTuần 6: Nginx, Serverless, Microservices và Tự động hóa CI/CD\nTuần 7: Ôn tập AWS Cloud Practitioner và các dịch vụ cốt lõi\nTuần 8: Chuẩn bị thi giữa kì, Dịch vụ nâng cao và Khởi động dự án\nTuần 9: Khởi tạo dự án: Next.js, Design System và Xác thực\nTuần 10: Tính năng cốt lõi: Ví, Hệ thống Hũ và Logic Ngân sách\nTuần 11: Tích hợp AI, Chatbot và Phân tích nâng cao\nTuần 12: Triển khai Production (AWS/Docker) và Hoàn thiện sản phẩm\n"
},
{
	"uri": "https://tuanvu250.github.io/FCJ-Report/vi/2-proposal/",
	"title": "Bản đề xuất",
	"tags": [],
	"description": "",
	"content": "Ứng dụng quản lý tài chính cá nhân (Vicobi) Bạn có thể đọc toàn bộ proposal ở đây: Vicobi Proposal 1. Tóm tắt điều hành Dự án Vicobi (Personal Finance Management App) hướng đến việc cung cấp một nền tảng quản lý tài chính cá nhân thông minh, hiện đại và mang tính tự động hóa cao. Vicobi đơn giản hóa việc quản lý tài chính qua 4 trụ cột chính:\nGhi chép thông minh (Smart Recording): Nhập liệu bằng giọng nói và quét hóa đơn, loại bỏ rào cản nhập liệu thủ công. Lập ngân sách theo mục tiêu (Goal-based Budgeting): Tự động hóa tạo và quản lý các hũ tiền (money jars) linh hoạt. Phân tích \u0026amp; Kiểm soát: Cung cấp báo cáo trực quan và hệ thống cảnh báo thông minh. Trợ lý tài chính (AI Chatbot): Tích hợp Chatbot AI đóng vai trò tư vấn viên, hỗ trợ giải đáp và nâng cao kiến thức tài chính. Về mặt công nghệ, Vicobi được xây dựng trên kiến trúc Microservices sử dụng .NET Aspire và FastAPI, triển khai trên AWS Cloud, đảm bảo tính linh hoạt và an toàn dữ liệu. Quy trình phát triển tuân theo mô hình Agile/Scrum (2 tuần/sprint trong giai đoạn phát triển chính), với mục tiêu hoàn thành MVP trong 2 tháng thực thi.\n2. Tuyên bố vấn đề Vấn đề hiện tại Trong thị trường năng động hiện nay, người dùng gặp khó khăn trong việc kiểm soát tài chính do \u0026ldquo;sức ỳ hành vi\u0026rdquo; — ngại ghi chép thủ công từng giao dịch. Các ứng dụng hiện có (như Money Lover, Misa Money Keeper) vẫn dựa nhiều vào nhập liệu bằng tay, gây ra tình trạng \u0026ldquo;mệt mỏi khi nhập liệu\u0026rdquo; (input fatigue) và tỷ lệ bỏ cuộc cao.\nGiải pháp Vicobi giải quyết vấn đề bằng cách tự động hóa cao độ quy trình nhập liệu thông qua AWS Cloud và Microservices:\nCông nghệ lõi: Tích hợp AI xử lý giọng nói tiếng Việt (Voice-to-Text) và nhận diện hóa đơn (OCR) chi tiết. Kiến trúc tối ưu: Sử dụng AWS ECS Fargate chạy mô hình Multi-container Task (gộp Backend .NET và AI Service) để giảm chi phí hạ tầng nhưng vẫn đảm bảo giao tiếp liền mạch. Frontend hiện đại: Sử dụng Next.js được lưu trữ trên Amazon S3 và phân phối toàn cầu qua Amazon CloudFront. Lợi ích và hoàn vốn đầu tư (ROI) Giải pháp mang lại lợi thế cạnh tranh rõ rệt:\nGiá trị người dùng: Giảm hơn 70% thao tác thủ công. Độ chính xác nhận diện giọng nói đạt 90% và trích xuất hóa đơn đạt 80%. Hiệu quả kinh tế: Tận dụng tối đa AWS Free Tier (S3, CloudFront, Cognito). Ngân sách vận hành tinh gọn khoảng ~$60/tháng cho hạ tầng và ~$15/tháng cho AI compute. Hoàn vốn: Dự kiến đạt ROI trong 6–12 tháng nhờ tiết kiệm thời gian và tăng hiệu suất. Khả năng mở rộng: Kiến trúc Microservices sẵn sàng cho việc tích hợp Mobile App hoặc Open Banking. 3. Kiến trúc giải pháp Hệ thống được thiết kế theo mô hình Microservices phân tán, sử dụng API Gateway làm điểm nhập duy nhất.\nChi tiết Tech Stack: Thành phần Công nghệ Chi tiết Frontend Next.js 16 App Router, TypeScript, Tailwind CSS, Zustand, React Query. Backend Core .NET Aspire Điều phối Microservices (User, Wallet, Transaction, Report, Notification). AI Service FastAPI (Python) Xử lý Voice (PhoWhisper), OCR (Bedrock), Chatbot (RAG). Database Polyglot PostgreSQL, MongoDB, Elasticsearch, Qdrant (Vector DB). Messaging RabbitMQ Giao tiếp bất đồng bộ giữa các service. Luồng hoạt động trên AWS: Truy cập: Người dùng truy cập qua Route 53, được bảo vệ bởi AWS WAF và tăng tốc bởi CloudFront. Xác thực: Amazon Cognito quản lý định danh và cấp phát JWT Token. Xử lý API: Request đi qua API Gateway, kết nối an toàn qua AWS PrivateLink tới Application Load Balancer (ALB). Compute: ALB phân phối tải tới các container trong ECS Fargate (nằm trong Private Subnet). DevOps: Quy trình CI/CD tự động hóa hoàn toàn bằng GitLab, build image đẩy lên Amazon ECR và update task trên ECS. 4. Triển khai kỹ thuật Các giai đoạn triển khai Dự án kéo dài 4 tháng (bao gồm thực tập):\nTháng 0 (Pre-internship): Lên ý tưởng và kế hoạch tổng thể. Tháng 1 (Foundation): Học AWS, nâng cấp kỹ năng .NET/Next.js/AI. Thiết lập VPC, IAM. Tháng 2 (Design): Thiết kế kiến trúc High-level \u0026amp; Detailed trên AWS. Tháng 3-4 (Realization): Coding, Integration Testing, Deploy lên AWS Production, thiết lập Monitoring. Sau tháng 5: Nghiên cứu phát triển Mobile App. Yêu cầu kỹ thuật chi tiết: Frontend: Triển khai Next.js 16 trên S3 + CloudFront. Sử dụng Origin Access Control (OAC) để bảo mật bucket. Backend: Sử dụng .NET Aspire để quản lý cấu hình Cloud-native. Database-per-service: PostgreSQL \u0026amp; MongoDB. Elasticsearch cho tìm kiếm giao dịch phức tạp. Background Jobs: Sử dụng Hangfire. AI Service Pipelines: Voice: Tiền xử lý bằng Pydub, Model PhoWhisper-small (VinAI) cho tiếng Việt. OCR: Amazon Bedrock (Claude 3.5 Sonnet Multimodal) để trích xuất thông tin hóa đơn chính xác. Chatbot (RAG): Knowledge Base lưu trong Qdrant, sinh câu trả lời qua Amazon Bedrock (Claude 3.5 Sonnet). Bảo mật: Mã hóa dữ liệu đường truyền (HTTPS/TLS 1.2+) và lưu trữ (AES-256). Quản lý bí mật (Secrets) chưa tích hợp sâu (đang ở mức MVP), sẽ nâng cấp lên AWS Secrets Manager trong tương lai. 5. Lộ trình \u0026amp; Mốc triển khai (Sprints) Giai đoạn thực thi chính được chia thành 4 Sprint:\nSprint 1: Core Foundation Xác thực (Cognito), Quản lý Ví (Wallets), Hũ chi tiêu (Spending Jars). Sprint 2: Core Features Giao dịch (CRUD), Xử lý giọng nói AI (Voice Processing). Sprint 3: Analytics Báo cáo/Biểu đồ, Hệ thống thông báo (SES), Message Broker. Sprint 4: Stabilization Kiểm thử tích hợp (Integration Testing), Tinh chỉnh UI, Deploy lên AWS ECS \u0026amp; CloudFront. Testing \u0026amp; Go-live: Cấu hình Domain, SSL, Monitoring Dashboard, UAT và bảo vệ đồ án. 6. Ước tính ngân sách Dựa trên bảng dự toán chi tiết cho giai đoạn MVP.\nBạn có thể xem chi tiết bảng dự toán chi phí bằng cách tải về các tệp sau: 📊 Tệp định dạng CSV 💾 Tệp định dạng JSON\nDịch vụ AWS Thành phần / Sử dụng Chi Phí (USD/tháng) Elastic Load Balancing Application Load Balancer $18.98 Amazon ECS Fargate (vCPU \u0026amp; Memory) $17.30 Amazon VPC VPC Endpoints \u0026amp; NAT $10.49 AWS WAF Web ACL \u0026amp; Requests $7.20 Amazon API Gateway API Calls \u0026amp; Data Transfer $2.50 Amazon CloudFront Data Transfer Out $2.00 Amazon ECR Storage $1.00 Amazon Route 53 Hosted Zones $0.54 Amazon S3 Standard Storage $0.34 TỔNG CHI PHÍ AWS ~$60.35 Chi phí khác:\nHạng mục Chi tiết Chi Phí (USD/tháng) AI Compute / Tooling Gemini API, Amazon Bedrock ~$15.00 TỔNG CỘNG DỰ ÁN ~$75.35 / tháng (Dựa trên giá On-Demand khu vực Singapore - ap-southeast-1)\n7. Đánh giá rủi ro Rủi ro chính: Lộ thông tin người dùng (Impact: High), Mất kết nối AWS Region (Impact: High), AI nhận diện sai (Impact: Medium). Chiến lược giảm thiểu: Bảo mật: Mã hóa AES-256, HTTPS, IAM Least Privilege, AWS WAF. High Availability: Triển khai Multi-AZ cho ECS và ALB. AI: Cải thiện model liên tục với dữ liệu thực tế. Resilience: Sử dụng RabbitMQ nội bộ để xử lý bất đồng bộ và retry. Kế hoạch dự phòng (Disaster Recovery): Sử dụng IaC (Infrastructure as Code) để khôi phục nhanh hạ tầng. 8. Kết quả kỳ vọng \u0026amp; Đội ngũ Kết quả mong đợi của dự án Nhập liệu tài chính tự động: Ứng dụng giúp người dùng tránh nhập liệu thủ công, chỉ cần chụp ảnh hóa đơn hoặc ghi âm giọng nói để hệ thống tự động phân loại chi tiêu. Quản lý tài chính trực quan: Người dùng có thể xem biểu đồ chi tiêu, báo cáo hàng tháng và nhận đề xuất tiết kiệm dựa trên hành vi tiêu dùng. Trải nghiệm người dùng tối thiểu: Giao diện web thân thiện, thiết kế hiện đại, được tối ưu hóa cho thiết bị di động và phù hợp với người mới bắt đầu quản lý tài chính. Hệ thống ổn định, có khả năng mở rộng: Kiến trúc microservices giúp dễ dàng thêm các tính năng mới như nhắc nhở chi tiêu, phân tích dự đoán AI hoặc mở rộng sang ứng dụng di động. Nâng cao kỹ năng nhóm phát triển: Các thành viên dự án có quyền truy cập thực tế vào các quy trình DevOps, triển khai CI/CD và tối ưu hóa ứng dụng trên nền tảng đám mây. Hạn chế của dự án Mô hình AI Việt Nam còn hạn chế: Khả năng nhận dạng giọng nói vùng miền hoặc hóa đơn viết tay vẫn chưa đạt độ chính xác cao.\nKhông có ứng dụng di động riêng biệt: Phiên bản MVP chỉ hỗ trợ nền tảng web, không có ứng dụng di động gốc.\nĐội ngũ thực hiện (Team): Họ tên Vai trò Email Lê Vũ Phương Hòa Backend Developer (Leader) hoalvpse181951@fpt.edu.vn Nguyễn Văn Anh Duy AI Developer (Member) duynvase181823@fpt.edu.vn Uông Tuấn Vũ Frontend Developer (Member) vuutse180241@fpt.edu.vn Trần Nguyễn Bảo Minh AI Developer (Member) baominhbrthcs@gmail.com Mentor Support:\nNguyễn Gia Hưng - Head of Solution Architects Văn Hoàng Kha - Cloud Security Engineer "
},
{
	"uri": "https://tuanvu250.github.io/FCJ-Report/vi/5-workshop/5.2-prerequiste/5.2.2-prepare-data/",
	"title": "Chuẩn bị dữ liệu nguồn",
	"tags": [],
	"description": "",
	"content": "Tổng quan Khởi tạo một kho lưu trữ đối tượng (S3 Bucket) để chứa các tài liệu gốc (PDF, Word, Text). Đây đóng vai trò là \u0026ldquo;nguồn sự thật\u0026rdquo; (Source of Truth) mà Knowledge Base sẽ truy cập để đọc hiểu, phân tích và đồng bộ hóa kiến thức cho AI. Bạn có thể lưu trữ kiến thức liên quan đến lĩnh vực của bạn sử dụng trong việc tạo trợ lý cá nhân hoặc Chatbot cho riêng bạn.\nChuẩn bị dữ liệu Chúng ta sẽ tạo một S3 Bucket để lưu trữ tài liệu gốc, đóng vai trò là nguồn tri thức cho Chatbot.\nBước 1. Tạo S3 Bucket\nTruy cập dịch vụ S3 từ thanh tìm kiếm. AWS Region: Chọn United States (N. Virginia us-east-1). Click Create bucket. Cấu hình thông tin Bucket: Bucket Type: Chọn General purpose Bucket name: Nhập rag-workshop-demo Object Ownership: Giữ mặc định ACLs disabled. Block Public Access settings: Giữ mặc định (Đã chọn Block all public access). Kéo xuống cuối trang, Click Create bucket. Kiểm tra tạo S3 Bucket thành công. Bước 2. Tải lên tài liệu mẫu\nĐây tài liệu mẫu, liên quan để tổng quan về kiến thức điện toán đám mây của AWS. Bạn có thể sử dụng để chạy demo hoặc upload dữ liệu của bạn. Tệp định dạng PDF\nTại danh sách Buckets, Click vào tên bucket bạn vừa tạo. Click Upload. Tại giao diện Upload: Click Add files. Chọn file tài liệu mẫu đính kèm ở phần trên hoặc file từ máy tính của bạn (Khuyên dùng file PDF hoặc Word có nhiều nội dung văn bản). Khi upload file xong, chọn file vừa upload, kéo xuống cuối trang, Click Upload. Khi thấy thông báo màu xanh \u0026ldquo;Upload succeeded\u0026rdquo;, Click Close. "
},
{
	"uri": "https://tuanvu250.github.io/FCJ-Report/vi/5-workshop/5.2-prerequiste/",
	"title": "Chuẩn bị môi trường",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Trước khi bắt tay vào xây dựng ứng dụng, chúng ta cần thiết lập một nền tảng vững chắc. Giống như việc chuẩn bị nguyên liệu trước khi nấu ăn, phần này đảm bảo rằng tài khoản AWS của bạn đã sẵn sàng với đầy đủ quyền hạn và dữ liệu cần thiết.\nTrong phần này, chúng ta sẽ hoàn thành 3 mục tiêu khởi tạo quan trọng:\nChọn Region (Vùng): Thiết lập môi trường làm việc tại vùng United States N. Virginia (us-east-1) để tối ưu hóa tốc độ kết nối và đảm bảo tính sẵn sàng của dịch vụ. Kích hoạt Model (Model Access): Kiểm tra và đảm bảo tài khoản có quyền gọi model Anthropic Claude 3 – \u0026ldquo;bộ não\u0026rdquo; ngôn ngữ chính của hệ thống. Chuẩn bị Dữ liệu (Data Setup): Khởi tạo kho lưu trữ (S3 Bucket) và tải lên tài liệu nguồn để phục vụ cho quá trình nạp kiến thức (Ingestion) sau này. Các thành phần chính Trong phần chuẩn bị này, chúng ta sẽ tương tác với các thành phần sau:\nAWS Management Console (Region Selector): Giao diện quản lý chung để chuyển đổi Region làm việc sang United States N. Virginia. Amazon Bedrock (Model Access \u0026amp; Playground): Nơi quản lý quyền truy cập các mô hình nền tảng (Foundation Models) và công cụ chat để kiểm tra nhanh khả năng phản hồi của AI. Amazon S3 (Simple Storage Service): Dịch vụ lưu trữ đối tượng, nơi chúng ta sẽ tạo Bucket để chứa các file tài liệu gốc (PDF, Word, Text). Các Bước Thực hiện Kiểm tra truy cập Model Chuẩn bị dữ liệu nguồn "
},
{
	"uri": "https://tuanvu250.github.io/FCJ-Report/vi/5-workshop/5.3-knowledge-base/5.3.2-sync-data/",
	"title": "Kiểm tra Vector Store và Đồng bộ Dữ liệu",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Trước khi AI có thể trả lời, dữ liệu phải được nhập vào kho lưu trữ vector (Vector Store). Chúng ta sẽ thực hiện kiểm tra \u0026ldquo;Trước và Sau\u0026rdquo; để thấy rõ cách Bedrock tự động mã hóa và lưu trữ dữ liệu vào OpenSearch.\nCác Bước Thực hiện Bước 1: Kiểm tra Vector Store (Trạng thái Rỗng)\nChúng ta sẽ truy cập trực tiếp vào Amazon OpenSearch Serverless để xác nhận rằng chưa có dữ liệu nào tồn tại.\nTrong thanh tìm kiếm AWS Console, gõ Amazon OpenSearch Service và chọn Amazon OpenSearch Service. Trong menu bên trái, ở phần Serverless, chọn Collections. Nhấp vào tên Collection mới được tạo bởi Bedrock (thường có tên dạng bedrock-knowledge-data...). Trên trang chi tiết Collection, nhấp vào nút Open Dashboard (nằm ở góc trên bên phải màn hình).\nLưu ý: Nếu được yêu cầu đăng nhập, hãy sử dụng thông tin đăng nhập AWS hiện tại của bạn. Trong giao diện OpenSearch Dashboard: Nhấp vào biểu tượng Menu (3 đường ngang) ở góc trên bên trái. Chọn Dev Tools (thường nằm ở cuối danh sách menu). Trong ngăn Console (bên trái), nhập lệnh sau để kiểm tra dữ liệu: GET _search\r{\r\u0026#34;query\u0026#34;: {\r\u0026#34;match_all\u0026#34;: {}\r}\r} Nhấp vào nút Play (Run) (tam giác nhỏ bên cạnh dòng lệnh). Kết quả: Quan sát ngăn bên phải, hits -\u0026gt; total -\u0026gt; value là 0. Bước 2: Đồng bộ Dữ liệu\nBây giờ chúng ta sẽ kích hoạt Bedrock để đọc các file từ S3 và tải chúng vào OpenSearch.\nQuay lại tab Amazon Bedrock trên trình duyệt. Chọn Knowledge bases trong menu bên trái và nhấp vào tên KB bạn vừa tạo. Cuộn xuống phần Data source, đánh dấu vào ô (tick) bên cạnh tên nguồn dữ liệu (s3-datasource). Nhấp vào nút Sync (Màu cam). Chờ đợi: Quá trình này sẽ mất 5 - 10 phút tùy thuộc vào kích thước tài liệu mẫu. Chờ cho đến khi cột Sync status chuyển từ Syncing sang Available. Bước 3: Kiểm tra lại Vector Store (Đã có Dữ liệu)\nSau khi Bedrock báo hoàn tất Sync, chúng ta quay lại kho lưu trữ để xác minh dữ liệu đã được nhập thành công.\nChuyển sang tab OpenSearch Dashboard (vẫn còn mở từ Bước 1). Trong Dev Tools, nhấp lại nút Play (Run) với lệnh cũ: GET _search\r{\r\u0026#34;query\u0026#34;: {\r\u0026#34;match_all\u0026#34;: {}\r}\r} Kết quả: Phần hits -\u0026gt; total -\u0026gt; value sẽ lớn hơn 0 (ví dụ: 10, 20\u0026hellip; tùy thuộc vào số lượng đoạn văn bản). Bạn sẽ thấy chi tiết các vector (mảng số) và nội dung văn bản được lưu trữ trong trường _source. Chúc mừng! Bạn đã hoàn thành việc xây dựng \u0026ldquo;bộ não\u0026rdquo; cho AI. Dữ liệu đã được mã hóa và nằm an toàn trong Vector Database, sẵn sàng cho việc truy xuất.\n"
},
{
	"uri": "https://tuanvu250.github.io/FCJ-Report/vi/3-blogstranslated/",
	"title": "Các bài blogs đã dịch",
	"tags": [],
	"description": "",
	"content": "Blog 1 - Chạy và tối ưu các Small Language Models tại on-premises và tại edge Bài viết hướng dẫn cách triển khai Small Language Models (SLMs) vào môi trường AWS on-premises hoặc edge (AWS Local Zones và AWS Outposts) để đáp ứng các yêu cầu về data residency, information security policy, và low latency. Nội dung bao gồm: sự khác biệt giữa LLMs và SLMs, lợi ích của SLMs (thời gian suy luận nhanh hơn, yêu cầu tài nguyên thấp hơn, phù hợp edge computing), kiến trúc triển khai sử dụng Llama.cpp framework, các bước cụ thể để cài đặt và cấu hình (khởi chạy GPU instance, cài đặt NVIDIA drivers, cài đặt Llama.cpp, tải và chuyển đổi model sang định dạng GGUF), và các ví dụ tối ưu hóa cho chatbot và text summarization.\nBlog 2 - Hội nghị AWS EUC New York Summit: The AI Advantage: Unlocking the full potential of your EUC Services Bài viết giới thiệu về phiên thảo luận tại AWS EUC New York Summit, tập trung vào cách ứng dụng AI để tối ưu các tác vụ quản trị End-User Computing (EUC) và nâng cao năng suất người dùng. Nội dung chính: tận dụng AI agentic của Amazon Bedrock kết hợp với Amazon WorkSpaces và Amazon CloudWatch để tự động hóa các tác vụ quản trị, cung cấp thông tin chi tiết có thể hành động (actionable insights) từ metrics và logs quan trọng, thu thập dữ liệu về user connectivity, platforms và IP addresses, phân tích dữ liệu để tối ưu hoạt động người dùng cuối. Phiên builders session cung cấp kiến thức chuyên sâu và trải nghiệm học tập thực tế về cách tích hợp AI vào framework EUC hiện có.\nBlog 3 - Cách thiết lập cảnh báo tự động cho các AWS Savings Plans mới mua Bài viết hướng dẫn cách thiết lập hệ thống giám sát và cảnh báo tự động để phát hiện AWS Savings Plans sử dụng kém hiệu quả trong thời hạn hoàn trả hợp lệ (7 ngày đầu và trong cùng tháng mua). Nội dung bao gồm: giải thích về AWS Savings Plans và chính sách hoàn trả (cam kết ≤ $100/giờ), kiến trúc giải pháp sử dụng AWS CloudFormation, Step Functions, SNS, EventBridge và IAM roles, triển khai trên hai tài khoản (Management Account và Member Account) theo AWS security best practices, quy trình tự động phân tích tỷ lệ sử dụng Savings Plans và gửi cảnh báo qua email khi phát hiện plan sử dụng thấp dưới ngưỡng định sẵn, hướng dẫn triển khai chi tiết từng bước và cách kiểm thử giải pháp.\n"
},
{
	"uri": "https://tuanvu250.github.io/FCJ-Report/vi/5-workshop/5.3-knowledge-base/",
	"title": "Tạo và Cấu hình Knowledge Base",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Sau khi hoàn thành việc chuẩn bị môi trường và dữ liệu, bước tiếp theo là thiết lập thành phần cốt lõi của kiến trúc RAG. Trong phần này, chúng ta sẽ khởi tạo Knowledge Base, đóng vai trò là cơ chế trung gian thông minh kết nối các nguồn dữ liệu phi cấu trúc với khả năng suy luận của các foundation models.\nChúng ta sẽ thực hiện 3 mục tiêu kỹ thuật chính:\nThiết lập Pipeline Tự động: Cấu hình Knowledge Base để tự động hóa toàn bộ quy trình xử lý dữ liệu RAG (bao gồm trích xuất, phân đoạn văn bản và tạo vector) nhằm loại bỏ các tác vụ xử lý thủ công. Khởi tạo Vector Store: Triển khai một collection trên Amazon OpenSearch Serverless để lưu trữ các vector ngữ nghĩa, phục vụ việc truy xuất thông tin chính xác và hiệu quả. Đồng bộ hóa Dữ liệu (Data Ingestion): Thực hiện quy trình nhập dữ liệu ban đầu, chuyển đổi các tài liệu tĩnh từ S3 thành các vector có thể tìm kiếm trong hệ thống. Các Thành phần Chính Trong quá trình cấu hình này, chúng ta sẽ tương tác và kết nối các dịch vụ sau:\nKnowledge Bases for Amazon Bedrock: Dịch vụ được quản lý đóng vai trò là bộ điều phối luồng dữ liệu, kết nối các nguồn thông tin và thực thi các truy vấn ngữ nghĩa. Amazon Titan Embeddings G1 - Text v2: Mô hình chuyên dụng để chuyển đổi dữ liệu văn bản thành các vector số (Embeddings) với độ chính xác cao và hỗ trợ đa ngôn ngữ. Amazon OpenSearch Serverless: Cơ sở dữ liệu vector được quản lý hoàn toàn, chịu trách nhiệm lưu trữ và thực thi các thuật toán tìm kiếm tương đồng (k-NN). Các Bước Thực hiện Khởi tạo Knowledge Base Kiểm tra Vector Store và Đồng bộ Dữ liệu "
},
{
	"uri": "https://tuanvu250.github.io/FCJ-Report/vi/4-eventparticipated/",
	"title": "Các events đã tham gia",
	"tags": [],
	"description": "",
	"content": "Trong quá trình thực tập, em đã tham gia 6 events, với mỗi event là một trải nghiệm đáng nhớ với những kiến thức mới, hay và bổ ích, cùng với đó là nhứng món quà và những khoảnh khắc rất tuyệt vời.\nEvent 1 Tên sự kiện: Vietnam Cloud Day 2025 : Ho Chi Minh City Connect Edition for Builders (Track 1: GenAI \u0026amp; Data)\nThời gian: 09:00 ngày 18/09/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 2 Tên sự kiện: GenAI-powered App-DB Modernization workshop\nThời gian: 09:00 ngày 13/08/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 3 Tên sự kiện: Workshop Data Science on AWS\nThời gian: 09:00 ngày 16/10/2025\nĐịa điểm: Trường Đại học FPT TP.HCM\nVai trò trong sự kiện: Người tham dự\nEvent 4 Tên sự kiện: AWS Cloud Mastery Series #1: GENERATIVE AI, RAG \u0026amp; AWS AGENTIC AI\nThời gian: 08:30 ngày 15/11/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 5 Tên sự kiện: AWS Cloud Mastery Series #2: Từ DevOps, IaC đến Container \u0026amp; Observability\nThời gian: 08:30 ngày 17/11/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 6 Tên sự kiện: AWS Cloud Mastery Series #3: Cloud Security \u0026amp; Operations Mastery\nThời gian: 08:30 ngày 29/11/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\n"
},
{
	"uri": "https://tuanvu250.github.io/FCJ-Report/vi/5-workshop/5.4-test-chatbox/",
	"title": "Kiểm thử Chatbot (RAG)",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Sau khi đã nhập dữ liệu thành công vào Vector Store, đã đến lúc xác minh kết quả. Trong phần này, bạn sẽ đóng vai trò là người dùng cuối, đặt câu hỏi cho Chatbot trực tiếp trong giao diện AWS Console để quan sát cách hệ thống RAG hoạt động.\nChúng ta sẽ tập trung vào 2 yếu tố:\nĐộ chính xác: AI có trả lời đúng dựa trên tài liệu không? Tính minh bạch: AI có thể trích dẫn nguồn (Citation) của thông tin không? Các Bước Thực hiện Bước 1: Cấu hình cửa sổ kiểm thử\nĐể bắt đầu trò chuyện, chúng ta cần chọn một Foundation Model sẽ đóng vai trò là \u0026ldquo;người trả lời\u0026rdquo;.\nTrong giao diện chi tiết Knowledge Base của bạn, hãy xem bảng điều khiển bên phải có tiêu đề Test knowledge base. Nhấp vào nút Select model.\nTrong bảng điều khiển lựa chọn xuất hiện: Category: Chọn Anthropic. Model: Chọn Claude 3 Sonnet (hoặc Claude 3.5 Sonnet / Haiku tùy thuộc vào model bạn đã kích hoạt). Throughput: Giữ nguyên On-demand. Nhấp Apply. Bước 2: Tiến hành hội thoại (Chat)\nBây giờ, hãy thử đặt một câu hỏi liên quan đến nội dung tài liệu bạn đã tải lên.\nTrong ô nhập liệu (Message input), gõ câu hỏi của bạn. Ví dụ: Nếu bạn đã tải lên tài liệu \u0026ldquo;Tổng quan về AWS\u0026rdquo;, hãy hỏi: \u0026ldquo;Bạn có thể giải thích cho tôi EC2 là gì không?\u0026rdquo;. Nhấp Run. Quan sát kết quả: AI sẽ suy nghĩ trong vài giây (truy vấn Vector Store). Sau đó, nó sẽ trả lời bằng ngôn ngữ tự nhiên, tóm tắt thông tin tìm được. Bước 3: Xác minh nguồn dữ liệu\nĐây là tính năng quan trọng nhất của RAG giúp phân biệt với ChatGPT thông thường: khả năng chứng minh nguồn thông tin.\nTrong câu trả lời của AI, hãy chú ý đến các số nhỏ (chú thích) hoặc văn bản Show source details. Nhấp vào các số đó hoặc nút chi tiết. Một cửa sổ Source details sẽ xuất hiện, hiển thị: Source chunk: Đoạn văn bản gốc chính xác mà AI tìm thấy trong tài liệu. Score: Điểm tương đồng (mức độ liên quan). S3 Location: Đường dẫn đến file gốc. Việc nhìn thấy đoạn văn bản gốc này chứng minh rằng AI không \u0026ldquo;ảo tưởng\u0026rdquo; mà đang thực sự đọc tài liệu của bạn.\nBước 4: Kiểm thử với câu hỏi không liên quan (Tùy chọn)\nĐể xem hệ thống phản ứng như thế nào khi không tìm thấy thông tin.\nĐặt một câu hỏi hoàn toàn không liên quan đến tài liệu. Ví dụ: \u0026ldquo;Hãy giải thích cho tôi một số kiến thức về tài chính cá nhân?\u0026rdquo; (Trong khi tài liệu của bạn là về Điện toán đám mây). Kết quả mong đợi: AI có thể trả lời dựa trên kiến thức tổng quát của nó (nếu không bị hạn chế). HOẶC AI sẽ trả lời \u0026ldquo;Xin lỗi, tôi không thể trả lời câu hỏi của bạn dựa trên dữ liệu truy xuất được\u0026rdquo; - Đây là hành vi lý tưởng cho một ứng dụng RAG doanh nghiệp. "
},
{
	"uri": "https://tuanvu250.github.io/FCJ-Report/vi/5-workshop/5.5-client-integration/",
	"title": "Tích hợp ứng dụng Client (Tùy chọn)",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Bạn sẽ biến dòng code Python thành một Giao diện Web Chatbot (GUI) chuyên nghiệp, thân thiện với người dùng cuối (tương tự như giao diện ChatGPT) chỉ trong vài phút.\nChúng ta sử dụng:\nBackend: Python. Frontend: Streamlit. AI Model: Claude 3.5 Sonnet. Các Bước Thực hiện Phần I: Cấu hình AWS Credentials\nBước 1: Cài đặt AWS CLI\nMở Terminal trên máy tính của bạn.\n# macOS brew install awscli # Linux curl \u0026#34;https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\u0026#34; -o \u0026#34;awscliv2.zip\u0026#34; unzip awscliv2.zip sudo ./aws/install Bước 2: Cấu hình credentials\naws configure Nhập thông tin khi được hỏi:\nAWS Access Key ID: YOUR_ACCESS_KEY AWS Secret Access Key: YOUR_SECRET_KEY Default region name: us-east-1 Default output format: json Bước 3: Kiểm tra cấu hình\n# Kiểm tra credentials aws sts get-caller-identity # Kiểm tra kết nối Bedrock aws bedrock-agent-runtime list-knowledge-bases --region ap-southeast-1 Lưu ý bảo mật:\nKHÔNG commit credentials vào Git KHÔNG share credentials với người khác Sử dụng IAM roles khi có thể Rotate credentials định kỳ Permissions cần thiết:\nIAM User cần có các quyền sau:\nbedrock:InvokeModel bedrock:RetrieveAndGenerate bedrock:Retrieve s3:GetObject (cho Knowledge Base) Troubleshooting:\nLỗi \u0026ldquo;Unable to locate credentials\u0026rdquo;:\nKiểm tra file ~/.aws/credentials tồn tại Kiểm tra format file đúng Thử chạy aws configure lại Lỗi \u0026ldquo;AccessDeniedException\u0026rdquo;:\nKiểm tra IAM permissions Đảm bảo region đúng (ap-southeast-1) Kiểm tra Knowledge Base ID đúng Lỗi \u0026ldquo;ExpiredToken\u0026rdquo;:\nCredentials đã hết hạn Cần tạo credentials mới từ AWS Console Phần II: Clone Project từ GitHub đã tạo sẵn\nBước 1: Truy cập vào link GitHub sau\nBạn hãy tải về và mở folder trên bằng Visual Studio Code:\nhttps://github.com/DazielNguyen/chatbot_with_bedrock.git\nBước 2: Tải các thư viện và môi trường Python\nTải môi trường:\nMacOS: python3 -m venv .venv Win: python -m venv .venv Kích hoạt môi trường:\nMacOS: source .venv/bin/activate Win: .venv\\Scripts\\activate Tải thư viện:\nMacOS/ Win: pip install -r requirements.txt Bước 3: Lấy ID của Knowledge Base đã tạo\nTruy cập Amazon Bedrock -\u0026gt; Knowledge Base -\u0026gt; knowledge-base-demo Cập nhật \u0026ldquo;KB_ID=\u0026ldquo;YOUR_KNOWLEDGE_BASE_ID\u0026rdquo;\u0026rdquo; Bước 4: Chạy Streamlit - UI của Chatbot và Trải nghiệm\nRun Terminal: streamlit run start.py Khi chạy xong lệnh sẽ xuất hiện trang sau: Hãy thử hỏi một số câu hỏi bạn đã upload lên Knowledge Base trước đó. Kết quả Chabot đã trả về kết quả dựa trên file dữ liệu mà bạn đã cung cấp, có trích nguồn của dữ liệu của bạn. Kết luận Chúc mừng bạn đã xây dựng thành công một Web Chatbot được xây dựng từ Amazon Bedrock\n"
},
{
	"uri": "https://tuanvu250.github.io/FCJ-Report/vi/5-workshop/",
	"title": "Workshop",
	"tags": [],
	"description": "",
	"content": "Xây dựng ứng dụng RAG sử dụng Knowledge Bases cho Amazon Bedrock Tổng quan Knowledge Bases for Amazon Bedrock là một tính năng được quản lý hoàn toàn giúp bạn triển khai kỹ thuật RAG (Retrieval-Augmented Generation) bằng cách kết nối các Foundation Models với nguồn dữ liệu nội bộ của bạn để cung cấp các phản hồi chính xác, có trích dẫn và phù hợp với ngữ cảnh.\nRAG là một kỹ thuật để tối ưu hóa đầu ra của Large Language Model (LLM) bằng cách truy xuất thông tin từ cơ sở dữ liệu bên ngoài đáng tin cậy (Retrieval) và thêm nó vào ngữ cảnh (Augmentation) trước khi tạo ra câu trả lời (Generation). Phương pháp này giúp khắc phục những hạn chế về dữ liệu huấn luyện lỗi thời và đảm bảo AI trả lời dựa trên thông tin thực tế được cung cấp.\nTrong bài lab này, chúng ta sẽ học cách xây dựng một trợ lý AI có khả năng \u0026ldquo;đọc và hiểu\u0026rdquo; các tài liệu doanh nghiệp độc quyền. Bạn sẽ thực hiện quy trình từ việc nhập dữ liệu và tạo chỉ mục vector đến cấu hình mô hình để trả lời câu hỏi dựa trên những tài liệu đó mà không cần quản lý bất kỳ máy chủ nào.\nChúng ta sẽ sử dụng ba thành phần chính để thiết lập quy trình xử lý RAG hoàn chỉnh:\nNguồn dữ liệu (Amazon S3) - Đóng vai trò là kho lưu trữ \u0026ldquo;sự thật\u0026rdquo;. Bạn sẽ tải các tài liệu (PDF, Word, Text) lên một S3 bucket. Knowledge Base sẽ sử dụng nguồn này để đồng bộ hóa dữ liệu. Vector Store (OpenSearch Serverless) - Nơi lưu trữ các embeddings vector (dữ liệu được mã hóa bằng số). Khi người dùng đặt câu hỏi, hệ thống sẽ thực hiện tìm kiếm ngữ nghĩa tại đây để trích xuất các đoạn văn bản liên quan nhất thay vì tìm kiếm từ khóa tiêu chuẩn. Foundation Model (Claude 3) - Large Language Model đóng vai trò là bộ não xử lý. Nó nhận câu hỏi của người dùng cùng với thông tin tìm thấy từ Vector Store, sau đó tổng hợp và tạo ra câu trả lời tự nhiên, chính xác kèm theo trích dẫn nguồn. Kết quả đạt được Khi kết thúc workshop, bạn sẽ có một hệ thống Chatbot thực tế, hoạt động với các tính năng sau:\nTrò chuyện hỏi đáp về nội dung tài liệu độc quyền. Câu trả lời chính xác, không có ảo giác (hallucinations). Trích dẫn nguồn (biết chính xác câu trả lời đến từ trang nào). Triển khai nhanh chóng mà không cần viết mã xử lý dữ liệu phức tạp. Nội dung Tổng quan về Workshop Chuẩn bị môi trường Tạo và cấu hình Knowledge Base Kiểm tra Chatbot (RAG) Tích hợp ứng dụng Client (Tùy chọn) Cập nhật dữ liệu Dọn dẹp tài nguyên "
},
{
	"uri": "https://tuanvu250.github.io/FCJ-Report/vi/5-workshop/5.6-update-data/",
	"title": "Cập nhật dữ liệu",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Một trong những lợi thế lớn nhất của RAG so với Fine-tuning (huấn luyện lại) mô hình là khả năng cập nhật dữ liệu nhanh chóng. Khi doanh nghiệp có quy định mới, bạn chỉ cần nhập chúng vào Knowledge Base, và AI sẽ \u0026ldquo;học\u0026rdquo; chúng ngay lập tức.\nTrong phần này, chúng ta sẽ mô phỏng kịch bản sau:\nHỏi AI về một thông tin không tồn tại (AI sẽ trả lời là không biết). Cung cấp thông tin đó cho hệ thống bằng cách tải lên file mới. Hỏi lại câu hỏi tương tự để chứng kiến AI trả lời đúng ngay lập tức. Các Bước Thực hiện Bước 1: Xác minh \u0026ldquo;thiếu kiến thức\u0026rdquo; ban đầu\nChúng ta cần xác nhận rằng AI hiện tại không biết gì về thông tin bí mật mà chúng ta sắp tạo.\nQuay lại giao diện Streamlit Chatbot (được tạo trong Phần 5) hoặc sử dụng cửa sổ Test Knowledge Base trên Console. Đặt một câu hỏi về thông tin giả định không có thật. Ví dụ: \u0026ldquo;Mã kích hoạt cho Dự án Omega là gì?\u0026rdquo; Quan sát kết quả: AI sẽ trả lời rằng không thể tìm thấy thông tin trong các tài liệu được cung cấp hoặc sẽ cố gắng đưa ra câu trả lời chung chung (nếu không bị hạn chế). Bước 2: Tạo dữ liệu mới\nChúng ta sẽ tạo một file văn bản chứa \u0026ldquo;bí mật\u0026rdquo; này để nhập vào hệ thống.\nTrên máy tính của bạn, mở Notepad (Windows) hoặc TextEdit (Mac). Sao chép và dán nội dung sau vào file: THÔNG BÁO MẬT: Dự án Omega bí mật chính thức khởi động vào ngày 01/12/2025. Mã kích hoạt là: \u0026#34;AWS-ROCKS-2025-SINGAPORE\u0026#34;. Người Quản lý Dự án là Ông Robot. Vui lòng giữ thông tin này tuyệt đối bí mật. Lưu file với tên: secret-project.txt. Bạn có thể tải file tại đây: Tệp định dạng TXT\nBước 3: Tải lên và Đồng bộ\nBây giờ, chúng ta sẽ cung cấp kiến thức mới này vào \u0026ldquo;bộ não\u0026rdquo; của AI.\nTruy cập S3 Console, điều hướng đến bucket cũ của bạn (rag-workshop-demo).\nNhấp Upload -\u0026gt; Add files -\u0026gt; Chọn file secret-project.txt -\u0026gt; Upload.\nChuyển sang Amazon Bedrock Console -\u0026gt; Chọn Knowledge bases từ menu bên trái. Nhấp vào tên Knowledge Base của bạn. Cuộn xuống phần Data source, chọn nguồn dữ liệu (s3-datasource). Nhấp vào nút Sync (Màu cam). Chờ đợi: Chờ khoảng 30 giây đến 1 phút cho đến khi cột Status chuyển từ Syncing sang Available. Bước 4: Xác minh lại (Khoảnh khắc \u0026ldquo;Wow\u0026rdquo;)\nHệ thống hiện đã có kiến thức mới. Hãy thách thức AI một lần nữa.\nQuay lại giao diện Streamlit Chatbot (Không cần tải lại trang hoặc khởi động lại server). Hỏi chính xác câu hỏi tương tự như trước: \u0026ldquo;Mã kích hoạt cho Dự án Omega là gì?\u0026rdquo; Kết quả mong đợi: AI trả lời chính xác: \u0026ldquo;Mã kích hoạt là AWS-ROCKS-2025-SINGAPORE\u0026rdquo;. AI trích dẫn nguồn là file secret-project.txt. Kết luận Bạn vừa chứng kiến sức mạnh thực sự của RAG!\nKhông cần chỉnh sửa code. Không cần huấn luyện lại mô hình. Chỉ cần Sync dữ liệu. Chatbot của bạn đã trở nên thông minh hơn và cập nhật với thông tin mới nhất chỉ trong vài bước đơn giản. Đây chính là lý do tại sao các doanh nghiệp chọn giải pháp này để xây dựng trợ lý ảo nội bộ.\n"
},
{
	"uri": "https://tuanvu250.github.io/FCJ-Report/vi/6-self-evaluation/",
	"title": "Tự đánh giá",
	"tags": [],
	"description": "",
	"content": "Trong suốt thời gian thực tập tại AWS/First cloud journey program từ 08/09/2025 đến 12/12/2025, tôi đã có cơ hội học hỏi, rèn luyện và áp dụng kiến thức đã được trang bị tại trường vào môi trường làm việc thực tế.\nTôi đã tham gia vào việc học tập dịch vụ của AWS, cũng như áp dụng các kiến thức đã được học vào dự án nhóm với chủ đề FinTech, qua đó cải thiện kỹ năng làm việc nhóm và đặc biệt đã đạt được các kĩ năng mong muốn như Docker, Devops, và áp dụng các dịch vụ AWS hỗ trợ công việc lập trình triển khai dự án thực tế.\nVề tác phong, tôi luôn cố gắng hoàn thành tốt nhiệm vụ, tuân thủ nội quy, và tích cực trao đổi với đồng nghiệp để nâng cao hiệu quả công việc.\nĐể phản ánh một cách khách quan quá trình thực tập, tôi xin tự đánh giá bản thân dựa trên các tiêu chí dưới đây:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Hiểu biết về ngành, áp dụng kiến thức vào thực tế, kỹ năng sử dụng công cụ, chất lượng công việc ✅ ☐ ☐ 2 Khả năng học hỏi Tiếp thu kiến thức mới, học hỏi nhanh ☐ ✅ ☐ 3 Chủ động Tự tìm hiểu, nhận nhiệm vụ mà không chờ chỉ dẫn ✅ ☐ ☐ 4 Tinh thần trách nhiệm Hoàn thành công việc đúng hạn, đảm bảo chất lượng ✅ ☐ ☐ 5 Kỷ luật Tuân thủ giờ giấc, nội quy, quy trình làm việc ✅ ☐ ☐ 6 Tính cầu tiến Sẵn sàng nhận feedback và cải thiện bản thân ✅ ☐ ☐ 7 Giao tiếp Trình bày ý tưởng, báo cáo công việc rõ ràng ✅ ☐ ☐ 8 Hợp tác nhóm Làm việc hiệu quả với đồng nghiệp, tham gia nhóm ✅ ☐ ☐ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, đối tác, môi trường làm việc ✅ ☐ ☐ 10 Tư duy giải quyết vấn đề Nhận diện vấn đề, đề xuất giải pháp, sáng tạo ☐ ✅ ☐ 11 Đóng góp vào dự án/tổ chức Hiệu quả công việc, sáng kiến cải tiến, ghi nhận từ team ☐ ✅ ☐ 12 Tổng thể Đánh giá chung về toàn bộ quá trình thực tập ✅ ☐ ☐ Cần cải thiện Nâng cao tính kỹ luật, chấp hành nghiêm chỉnh nội quy của công ty hoặc bất kỳ trong một tổ chức nào Cải thiện trong cách tư duy giải quyết vấn đề Học cách giao tiếp tốt hơn trong giao tiếp hằng ngày và trong công việc, xử lý tình huống Khả năng học hỏi chuyên sâu: Cần dành thời gian đào sâu hơn vào nguyên lý hoạt động (Deep Dive) của các dịch vụ AWS thay vì chỉ dừng lại ở mức độ biết cách sử dụng (How-to), để có thể debug và tối ưu hóa hệ thống tốt hơn. Sự chủ động đóng góp: Cần mạnh dạn hơn trong việc đề xuất các ý tưởng cải tiến hoặc áp dụng công nghệ mới (như Serverless, Automation) cho dự án, thay vì chỉ tập trung hoàn thành các task được giao. "
},
{
	"uri": "https://tuanvu250.github.io/FCJ-Report/vi/7-feedback/",
	"title": "Chia sẻ, đóng góp ý kiến",
	"tags": [],
	"description": "",
	"content": " Tại đây bạn có thể tự do đóng góp ý kiến cá nhân về những trải nghiệm khi tham gia chương trình First Cloud Journey, giúp team FCJ cải thiện những vấn đề còn thiếu sót dựa trên các hạng mục sau:\nĐánh giá chung 1. Môi trường làm việc\nMôi trường làm việc rất thân thiện và cởi mở. Các thành viên trong FCJ luôn sẵn sàng hỗ trợ khi mình gặp khó khăn, kể cả ngoài giờ làm việc. Không gian làm việc gọn gàng, thoải mái, giúp mình tập trung tốt hơn. Tuy nhiên, mình có một góp ý nhỏ về việc sắp xếp lịch làm việc. Hiện tại việc đăng ký slot lên văn phòng đôi khi còn gặp khó khăn do số lượng giới hạn, dẫn đến việc các thành viên trong cùng một nhóm khó có cơ hội gặp mặt trực tiếp để trao đổi. Mình hy vọng trong tương lai chương trình có thể cân nhắc thiết lập một lịch trình cố định hơn cho từng nhóm, giúp bọn mình có không gian và thời gian để tương tác, bonding và làm việc nhóm hiệu quả hơn thay vì phải \u0026ldquo;tranh giành\u0026rdquo; slot như hiện tại.\n2. Sự hỗ trợ của mentor / team admin\nMentor hướng dẫn rất chi tiết, giải thích rõ ràng khi mình chưa hiểu và luôn khuyến khích mình đặt câu hỏi. Điều mình ấn tượng nhất là sự nhiệt tình và tâm huyết của các anh chị Mentor. Bất cứ khi nào mình hay các bạn khác gặp thắc mắc, các anh chị luôn phản hồi cực kỳ nhanh chóng với những giải thích cặn kẽ, chuyên sâu nhưng vẫn rất dễ hiểu. Sự hỗ trợ \u0026ldquo;kịp thời\u0026rdquo; và \u0026ldquo;đúng trọng tâm\u0026rdquo; này không chỉ giúp tụi mình gỡ rối vấn đề kỹ thuật mà còn tiếp thêm động lực rất lớn để tụi mình tự tin hơn trong quá trình thực hiện dự án. Team admin hỗ trợ các thủ tục, tài liệu và tạo điều kiện để mình làm việc thuận lợi. Mình đánh giá cao việc mentor cho phép mình thử và tự xử lý vấn đề thay vì chỉ đưa đáp án.\n3. Sự phù hợp giữa công việc và chuyên ngành học\nCông việc mình được giao phù hợp với kiến thức mình đã học ở trường, đồng thời mở rộng thêm những mảng mới mà mình chưa từng được tiếp cận. Nhờ vậy, mình vừa củng cố kiến thức nền tảng, vừa học thêm kỹ năng thực tế. Đặc biệt, giá trị lớn nhất mà mình nhận được chính là cơ hội được \u0026ldquo;thực chiến\u0026rdquo; với một dự án cụ thể từ đầu đến cuối. Đây là một điểm cộng cực lớn cho hồ sơ năng lực (portfolio) của mình sau này, vì những kinh nghiệm triển khai thực tế này là hành trang quý giá mà mình khó có thể tìm thấy chỉ qua sách vở hay các đồ án môn học thông thường.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng\nKhoảng thời gian thực tập tại FCJ thực sự là một \u0026ldquo;khóa học cấp tốc\u0026rdquo; vô cùng giá trị đối với mình. Mình không chỉ thành thạo hơn các công cụ quản lý dự án và quy trình Git Flow, mà còn rèn luyện được tư duy làm việc nhóm (teamwork) bài bản. Hơn thế nữa, những buổi chia sẻ từ các Mentor về lộ trình nghề nghiệp và xu hướng công nghệ đã giúp mình có cái nhìn rõ ràng hơn và định hướng tốt hơn cho con đường phát triển tương lai.\n5. Văn hóa \u0026amp; tinh thần đồng đội Văn hóa công ty rất tích cực: mọi người tôn trọng lẫn nhau, làm việc nghiêm túc nhưng vẫn vui vẻ. Khi có dự án gấp, mọi người cùng nhau cố gắng, hỗ trợ không phân biệt vị trí. Điều này giúp mình cảm thấy mình là một phần của tập thể, dù chỉ là thực tập sinh.\n6. Chính sách / phúc lợi cho thực tập sinh\nCông ty có hỗ trợ phụ cấp thực tập và tạo điều kiện về thời gian linh hoạt khi cần thiết. Ngoài ra, việc được tham gia các buổi đào tạo nội bộ là một điểm cộng lớn.\nMột số câu hỏi khác Điều bạn hài lòng nhất trong thời gian thực tập? Không chỉ là kiến thức chuyên môn, điều khiến mình hài lòng nhất chính là sự đồng hành sát sao và supportive hết mình từ các Mentors. Bên cạnh đó, việc được apply các kiến thức vào dự án thực tế giúp mình trưởng thành hơn rất nhiều. Điều bạn nghĩ công ty cần cải thiện cho các thực tập sinh sau? Mình mong muốn hệ thống đăng ký lịch làm việc tại văn phòng được cải thiện linh hoạt hơn, hoặc có cơ chế ưu tiên cho các nhóm dự án để đảm bảo mọi người có không gian thảo luận trực tiếp, tăng tính kết nối cho team. Nếu giới thiệu cho bạn bè, bạn có khuyên họ thực tập ở đây không? Vì sao? Chắc chắn là có 100%. Đây là môi trường lý tưởng để các bạn sinh viên \u0026ldquo;bước ra khỏi vùng an toàn\u0026rdquo;, rèn luyện tư duy giải quyết vấn đề thực tế và làm quen với tác phong làm việc chuyên nghiệp ngay từ khi còn ngồi trên ghế nhà trường. "
},
{
	"uri": "https://tuanvu250.github.io/FCJ-Report/vi/5-workshop/5.7-cleanup/",
	"title": "Dọn dẹp Tài nguyên",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Để tránh phát sinh chi phí không mong muốn sau khi hoàn thành bài thực hành, chúng ta cần xóa các tài nguyên đã tạo.\n⚠️ CẢNH BÁO: Xóa Knowledge Base KHÔNG tự động xóa Vector Store (OpenSearch Serverless). Bạn phải xóa thủ công OpenSearch Serverless Collection vì đây là dịch vụ tốn chi phí nhất trong Lab này.\nCác Bước Thực hiện Bước 1: Xóa Knowledge Base\nTruy cập Amazon Bedrock Console -\u0026gt; Knowledge bases.\nChọn nút radio bên cạnh tên Knowledge Base của bạn.\nNhấp vào nút Delete.\nHộp thoại xuất hiện, nhập tên Knowledge Base để xác nhận (hoặc gõ delete).\nNhấp Delete. Quá trình này mất 10-15 phút mới xóa thành công. Nên bạn thư giản nhé\nBước 2: Xóa Vector Store\nTruy cập Amazon OpenSearch Service. Trong menu bên trái, ở phần Serverless, chọn Collections. Bạn sẽ thấy một Collection có tên dạng bedrock-knowledge-base-.... Chọn nút radio bên cạnh tên Collection đó. Nhấp vào nút Delete. Gõ confirm hoặc tên collection để xác nhận xóa. Nhấp Delete. Bước 3: Xóa Dữ liệu trên S3\nTruy cập dịch vụ Amazon S3. Chọn bucket rag-workshop-demo. Nhấp vào nút Empty trước tiên. Gõ permanently delete để xác nhận xóa tất cả các file bên trong. Sau khi bucket rỗng, quay lại danh sách Buckets. Chọn lại bucket đó và nhấp vào nút Delete. Nhập tên bucket để xác nhận. Hoàn thành Chúc mừng bạn đã hoàn thành đầy đủ Workshop \u0026ldquo;Xây dựng Ứng dụng RAG với Amazon Bedrock\u0026rdquo;. Hệ thống của bạn đã được dọn dẹp và an toàn!\n"
},
{
	"uri": "https://tuanvu250.github.io/FCJ-Report/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://tuanvu250.github.io/FCJ-Report/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]